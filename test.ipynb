{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e92d0c-5fb7-47cf-8ccf-61ef0e6f0016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2961429969450005\n",
      "=== epoch:1, train acc:0.12, test acc:0.121 ===\n",
      "train loss:2.2895834643365958\n",
      "train loss:2.2748557741446804\n",
      "train loss:2.2522516569712465\n",
      "train loss:2.2352022480323406\n",
      "train loss:2.203025924052828\n",
      "train loss:2.15852135650828\n",
      "train loss:2.07897537808246\n",
      "train loss:2.0833186631723613\n",
      "train loss:1.9219133183660588\n",
      "train loss:1.9216386950197974\n",
      "train loss:1.8253114683316793\n",
      "train loss:1.69812208749136\n",
      "train loss:1.5862524543997045\n",
      "train loss:1.5246268217442804\n",
      "train loss:1.3922021262687576\n",
      "train loss:1.2875602931932835\n",
      "train loss:1.2844341847649523\n",
      "train loss:1.2853812853092388\n",
      "train loss:1.164266419685882\n",
      "train loss:1.111264036563556\n",
      "train loss:1.0690096625618077\n",
      "train loss:1.086480067875274\n",
      "train loss:0.9802404071440718\n",
      "train loss:0.9849964008118275\n",
      "train loss:1.0299267099238072\n",
      "train loss:0.9095094826891328\n",
      "train loss:0.9774035405392343\n",
      "train loss:1.0040551407067326\n",
      "train loss:0.9117889057140797\n",
      "train loss:0.9783118400618295\n",
      "train loss:0.7245118743787224\n",
      "train loss:0.842467884160363\n",
      "train loss:0.9052129882672848\n",
      "train loss:0.9332564140139832\n",
      "train loss:0.8909749488701487\n",
      "train loss:0.9051605622656537\n",
      "train loss:1.0468339816196441\n",
      "train loss:0.9216660955277489\n",
      "train loss:0.7566101164643354\n",
      "train loss:0.9676689066455885\n",
      "train loss:0.8324905143241419\n",
      "train loss:0.9002935071649277\n",
      "train loss:0.931323775358659\n",
      "train loss:0.8834789068829524\n",
      "train loss:0.69451647442177\n",
      "train loss:0.8526136102036284\n",
      "train loss:0.9362983318251313\n",
      "train loss:0.7192031567315722\n",
      "train loss:0.9102126792116181\n",
      "train loss:0.9347422361221441\n",
      "train loss:0.7444178222578298\n",
      "train loss:0.7598025933911621\n",
      "train loss:0.7627885841572674\n",
      "train loss:0.6616115359591018\n",
      "train loss:0.6215668087264146\n",
      "train loss:0.822837215756645\n",
      "train loss:0.6885906667973551\n",
      "train loss:0.9693383397024001\n",
      "train loss:0.6884256584290204\n",
      "train loss:0.5987436243488411\n",
      "train loss:0.8022023891917784\n",
      "train loss:0.8223387160661644\n",
      "train loss:0.7128650683613778\n",
      "train loss:0.7252215305113239\n",
      "train loss:0.6261615841571757\n",
      "train loss:0.7966090603082783\n",
      "train loss:0.731291663079177\n",
      "train loss:0.6725466885277781\n",
      "train loss:0.6505395097898821\n",
      "train loss:0.788818786907844\n",
      "train loss:0.6264664610418135\n",
      "train loss:0.6077785525833013\n",
      "train loss:0.6609072317644046\n",
      "train loss:0.5347795429805405\n",
      "train loss:0.6516382380028896\n",
      "train loss:0.6981254092039595\n",
      "train loss:0.7432269779706995\n",
      "train loss:0.7645725602252419\n",
      "train loss:0.6570146900957057\n",
      "train loss:0.5309381358797601\n",
      "train loss:0.5636960419064235\n",
      "train loss:0.5648297377570531\n",
      "train loss:0.9311921195411236\n",
      "train loss:0.7303068310508409\n",
      "train loss:0.7424288112373264\n",
      "train loss:0.6856524914074895\n",
      "train loss:0.7254912291713286\n",
      "train loss:0.6225930562097848\n",
      "train loss:0.7003624437594884\n",
      "train loss:0.6078419100190149\n",
      "train loss:0.7019512169219212\n",
      "train loss:0.8831698876188621\n",
      "train loss:0.5857743577643694\n",
      "train loss:0.580928617406695\n",
      "train loss:0.7373619262696828\n",
      "train loss:0.5209106200073053\n",
      "train loss:0.7289855206198221\n",
      "train loss:0.7443250617470685\n",
      "train loss:0.7302610114058322\n",
      "train loss:0.5780730315912213\n",
      "train loss:0.6223103668388089\n",
      "train loss:0.6046886096408927\n",
      "train loss:0.6992133822611477\n",
      "train loss:0.6882994581432126\n",
      "train loss:0.6446320858646206\n",
      "train loss:0.6337054089493048\n",
      "train loss:0.8179839014350953\n",
      "train loss:0.6629765249958389\n",
      "train loss:0.6915847087106914\n",
      "train loss:0.614382216547713\n",
      "train loss:0.7752580004792068\n",
      "train loss:0.6831742889606197\n",
      "train loss:0.8610898931941547\n",
      "train loss:0.6028020874237217\n",
      "train loss:0.6323261355828927\n",
      "train loss:0.7085766792702703\n",
      "train loss:0.6760905565543566\n",
      "train loss:0.5341075764734537\n",
      "train loss:0.6633644762760577\n",
      "train loss:0.5755508935367588\n",
      "train loss:0.5227909939412212\n",
      "train loss:0.41851006635621457\n",
      "train loss:0.6790396713625857\n",
      "train loss:0.5714359839539019\n",
      "train loss:0.6856442779440195\n",
      "train loss:0.6859254985795395\n",
      "train loss:0.5161751872880052\n",
      "train loss:0.5968047053334741\n",
      "train loss:0.7183796946396316\n",
      "train loss:0.48005949215515853\n",
      "train loss:0.6869373114276324\n",
      "train loss:0.5542722704356163\n",
      "train loss:0.591833150679291\n",
      "train loss:0.49032534832029173\n",
      "train loss:0.6381323404777712\n",
      "train loss:0.5350278140594962\n",
      "train loss:0.5410222290442204\n",
      "train loss:0.599746417096112\n",
      "train loss:0.6467279171254635\n",
      "train loss:0.6407033338961576\n",
      "train loss:0.6607858023010796\n",
      "train loss:0.5236758787025939\n",
      "train loss:0.6336373077133177\n",
      "train loss:0.5471806146384575\n",
      "train loss:0.637696542172337\n",
      "train loss:0.6841817706026496\n",
      "train loss:0.5968853005047147\n",
      "train loss:0.4067013502089874\n",
      "train loss:0.4017731521629071\n",
      "train loss:0.6485161824643149\n",
      "train loss:0.5122546587192809\n",
      "train loss:0.7599633569135544\n",
      "train loss:0.5660467240876745\n",
      "train loss:0.6422680892870375\n",
      "train loss:0.5621583510393692\n",
      "train loss:0.4877931970009674\n",
      "train loss:0.5727546078934149\n",
      "train loss:0.5005404511289544\n",
      "train loss:0.48449563272506874\n",
      "train loss:0.47695650017405955\n",
      "train loss:0.5606617457921407\n",
      "train loss:0.5435191022121648\n",
      "train loss:0.4665940670592784\n",
      "train loss:0.5084271505784861\n",
      "train loss:0.5484095378306922\n",
      "train loss:0.5820932355548919\n",
      "train loss:0.5125498631375729\n",
      "train loss:0.6966134372756316\n",
      "train loss:0.6030375890167314\n",
      "train loss:0.5648944430306371\n",
      "train loss:0.6128264848824646\n",
      "train loss:0.5910976561269538\n",
      "train loss:0.6828187796693395\n",
      "train loss:0.5781155068599755\n",
      "train loss:0.4806304500144832\n",
      "train loss:0.5442105677356984\n",
      "train loss:0.5126740083140668\n",
      "train loss:0.5326720951927748\n",
      "train loss:0.6032946837302109\n",
      "train loss:0.6749585269381885\n",
      "train loss:0.485393222947842\n",
      "train loss:0.5550014174143958\n",
      "train loss:0.35589394887566184\n",
      "train loss:0.6708048954282911\n",
      "train loss:0.6375082066251242\n",
      "train loss:0.48012211565230895\n",
      "train loss:0.49721251714270215\n",
      "train loss:0.5842500447535611\n",
      "train loss:0.4399665664358048\n",
      "train loss:0.43663000843771554\n",
      "train loss:0.7136383884710304\n",
      "train loss:0.44382851584466154\n",
      "train loss:0.44535390366805067\n",
      "train loss:0.5500732643445304\n",
      "train loss:0.44750656374906583\n",
      "train loss:0.4551781971793829\n",
      "train loss:0.4999816658150706\n",
      "train loss:0.5293431386290621\n",
      "train loss:0.6517276197087115\n",
      "train loss:0.6421661843069902\n",
      "train loss:0.5957498544263866\n",
      "train loss:0.4670931389824935\n",
      "train loss:0.6255576570103707\n",
      "train loss:0.4934020318714118\n",
      "train loss:0.47217722051596406\n",
      "train loss:0.4593170406421866\n",
      "train loss:0.6142123625675527\n",
      "train loss:0.5106194353328722\n",
      "train loss:0.593035007814919\n",
      "train loss:0.4995481269037262\n",
      "train loss:0.5145671953130107\n",
      "train loss:0.5731531395202094\n",
      "train loss:0.6140626924767484\n",
      "train loss:0.4862453821917734\n",
      "train loss:0.5305325916639697\n",
      "train loss:0.4358238115470155\n",
      "train loss:0.5133448333162636\n",
      "train loss:0.58616580631732\n",
      "train loss:0.5065136141462824\n",
      "train loss:0.44297733550215257\n",
      "train loss:0.4077176080291319\n",
      "train loss:0.414904274309579\n",
      "train loss:0.34394247277654755\n",
      "train loss:0.4507958843693183\n",
      "train loss:0.495406201493415\n",
      "train loss:0.5292626328243876\n",
      "train loss:0.4455002003341418\n",
      "train loss:0.5757261523012641\n",
      "train loss:0.5197309113603722\n",
      "train loss:0.4632945295627152\n",
      "train loss:0.5270468957071313\n",
      "train loss:0.5983219541115933\n",
      "train loss:0.41485788231972776\n",
      "train loss:0.3942395844162704\n",
      "train loss:0.3843553762286244\n",
      "train loss:0.48348869532819116\n",
      "train loss:0.403942768922689\n",
      "train loss:0.4775996245363524\n",
      "train loss:0.3881111971611533\n",
      "train loss:0.4629305626065148\n",
      "train loss:0.4963426339812072\n",
      "train loss:0.5003478390585644\n",
      "train loss:0.6191333530189779\n",
      "train loss:0.4232582502754451\n",
      "train loss:0.4510899249370071\n",
      "train loss:0.4652862340924606\n",
      "train loss:0.45742458838115796\n",
      "train loss:0.380760962452673\n",
      "train loss:0.687686336495736\n",
      "train loss:0.4960948611465814\n",
      "train loss:0.5825983407196665\n",
      "train loss:0.49045768324307587\n",
      "train loss:0.5277275151775033\n",
      "train loss:0.7430120611264829\n",
      "train loss:0.4958524745533336\n",
      "train loss:0.6785165001658392\n",
      "train loss:0.4815936156208386\n",
      "train loss:0.45922882745144905\n",
      "train loss:0.43973421291711956\n",
      "train loss:0.48335326890307323\n",
      "train loss:0.550229172836343\n",
      "train loss:0.45576477192580006\n",
      "train loss:0.4610393569434549\n",
      "train loss:0.6264370120306133\n",
      "train loss:0.46256071527179776\n",
      "train loss:0.5733844253475536\n",
      "train loss:0.3272413318977654\n",
      "train loss:0.7075385031124365\n",
      "train loss:0.4896322266208601\n",
      "train loss:0.44201961460102246\n",
      "train loss:0.4081320471254412\n",
      "train loss:0.48084031557889245\n",
      "train loss:0.5910309150807401\n",
      "train loss:0.47243334210029353\n",
      "train loss:0.6093379389211102\n",
      "train loss:0.4561964590129145\n",
      "train loss:0.5289917879194243\n",
      "train loss:0.4605715489705004\n",
      "train loss:0.33425728906836566\n",
      "train loss:0.5723490463725819\n",
      "train loss:0.4696489931742559\n",
      "train loss:0.4222415439178541\n",
      "train loss:0.3710514902119649\n",
      "train loss:0.3766404836338318\n",
      "train loss:0.6039252475914647\n",
      "train loss:0.4647060296021499\n",
      "train loss:0.48848645142082475\n",
      "train loss:0.4688742446246223\n",
      "train loss:0.41588094927470814\n",
      "train loss:0.4381452790319978\n",
      "train loss:0.4578700739993418\n",
      "train loss:0.49982160436110795\n",
      "train loss:0.5939637830968008\n",
      "train loss:0.3543571218172837\n",
      "train loss:0.5208539737222193\n",
      "train loss:0.5985263966004762\n",
      "train loss:0.45822954833395\n",
      "train loss:0.4164441087822649\n",
      "train loss:0.6244511803889888\n",
      "train loss:0.47387547249358797\n",
      "train loss:0.5449639584170849\n",
      "train loss:0.43915984442369177\n",
      "train loss:0.4496800892946981\n",
      "train loss:0.3207156497823275\n",
      "train loss:0.4000473039027158\n",
      "train loss:0.33284169418599546\n",
      "train loss:0.5012798639299111\n",
      "train loss:0.43012421063507467\n",
      "train loss:0.4113453934000394\n",
      "train loss:0.4514462913298678\n",
      "train loss:0.35766672838846214\n",
      "train loss:0.35822487447690626\n",
      "train loss:0.384732693293725\n",
      "train loss:0.4933008554948241\n",
      "train loss:0.4816472672131369\n",
      "train loss:0.39627471839520245\n",
      "train loss:0.4987401769826861\n",
      "train loss:0.4323871219896683\n",
      "train loss:0.5222918720167025\n",
      "train loss:0.5338948283701282\n",
      "train loss:0.450628967826595\n",
      "train loss:0.4363586148025344\n",
      "train loss:0.3802177669789087\n",
      "train loss:0.5053314028310393\n",
      "train loss:0.5634612379886867\n",
      "train loss:0.5979205579231298\n",
      "train loss:0.5536575634356246\n",
      "train loss:0.49705788411498264\n",
      "train loss:0.4998958868404979\n",
      "train loss:0.5074980847910351\n",
      "train loss:0.44508839911210607\n",
      "train loss:0.43186719377673705\n",
      "train loss:0.40049481952212057\n",
      "train loss:0.46543886119742867\n",
      "train loss:0.612188190190362\n",
      "train loss:0.5061066373664239\n",
      "train loss:0.42607422508230997\n",
      "train loss:0.33817824136152097\n",
      "train loss:0.645762431618648\n",
      "train loss:0.497878311769629\n",
      "train loss:0.3321212484936833\n",
      "train loss:0.5022375070173595\n",
      "train loss:0.4378383488596737\n",
      "train loss:0.3306148021401848\n",
      "train loss:0.3875968679846362\n",
      "train loss:0.3271763050822636\n",
      "train loss:0.43553851017756506\n",
      "train loss:0.6045766693866699\n",
      "train loss:0.5807264223861582\n",
      "train loss:0.37165690836717824\n",
      "train loss:0.5100054126193926\n",
      "train loss:0.27804853914477323\n",
      "train loss:0.4657536584706189\n",
      "train loss:0.4622138582800311\n",
      "train loss:0.3532558807900287\n",
      "train loss:0.46645328334575564\n",
      "train loss:0.5134472155535631\n",
      "train loss:0.3265436597625692\n",
      "train loss:0.38582381110455105\n",
      "train loss:0.5533532545579446\n",
      "train loss:0.5651035075757226\n",
      "train loss:0.5808699071293649\n",
      "train loss:0.5448793821080067\n",
      "train loss:0.45327764247858815\n",
      "train loss:0.4713537787125347\n",
      "train loss:0.5163293128326233\n",
      "train loss:0.4374409912534307\n",
      "train loss:0.4318385670644016\n",
      "train loss:0.5820408460466945\n",
      "train loss:0.342560198131625\n",
      "train loss:0.45224318316762874\n",
      "train loss:0.6310088376770036\n",
      "train loss:0.44171133627805\n",
      "train loss:0.4214387820414291\n",
      "train loss:0.3293813822969876\n",
      "train loss:0.3430539276500412\n",
      "train loss:0.46381394499892714\n",
      "train loss:0.4602968159765888\n",
      "train loss:0.2923960089431409\n",
      "train loss:0.3318569088474671\n",
      "train loss:0.44633374019998046\n",
      "train loss:0.34980243251438614\n",
      "train loss:0.31714474253409025\n",
      "train loss:0.3702912257013564\n",
      "train loss:0.406919639744291\n",
      "train loss:0.39653606349037956\n",
      "train loss:0.424075253641898\n",
      "train loss:0.4118986796961335\n",
      "train loss:0.46632131961840356\n",
      "train loss:0.3510925993469688\n",
      "train loss:0.3830441081776798\n",
      "train loss:0.4508361682800669\n",
      "train loss:0.402280610627076\n",
      "train loss:0.4617041409647953\n",
      "train loss:0.5444869914071908\n",
      "train loss:0.3589192181346077\n",
      "train loss:0.6355849560920336\n",
      "train loss:0.4564977563490817\n",
      "train loss:0.4493955018972967\n",
      "train loss:0.48995440997620776\n",
      "train loss:0.3904103648031625\n",
      "train loss:0.4470366000660367\n",
      "train loss:0.3747935712635936\n",
      "train loss:0.416971288143418\n",
      "train loss:0.42657224912883346\n",
      "train loss:0.5873470067544154\n",
      "train loss:0.5487323138127157\n",
      "train loss:0.4010452064928339\n",
      "train loss:0.5065231813517818\n",
      "train loss:0.45810834992470445\n",
      "train loss:0.43708133853077447\n",
      "train loss:0.4122166130067294\n",
      "train loss:0.315195413355715\n",
      "train loss:0.3066048479431631\n",
      "train loss:0.3487234858190905\n",
      "train loss:0.3426536178491233\n",
      "train loss:0.3745038905673045\n",
      "train loss:0.4932697387989273\n",
      "train loss:0.44391120131299544\n",
      "train loss:0.39076622466755123\n",
      "train loss:0.4272694247061413\n",
      "train loss:0.38338755289223847\n",
      "train loss:0.30097834908893584\n",
      "train loss:0.47410159641384547\n",
      "train loss:0.36658679683427553\n",
      "train loss:0.40548378074055125\n",
      "train loss:0.5586331775451606\n",
      "train loss:0.3617965424963982\n",
      "train loss:0.2963275118402687\n",
      "train loss:0.4120251095316487\n",
      "train loss:0.44259952111002543\n",
      "train loss:0.48763404571290386\n",
      "train loss:0.3686922029494342\n",
      "train loss:0.43310754014257546\n",
      "train loss:0.4033564690922246\n",
      "train loss:0.561016345849744\n",
      "train loss:0.3790385314069966\n",
      "train loss:0.4360653695069921\n",
      "train loss:0.42290250222065495\n",
      "train loss:0.46991534481966757\n",
      "train loss:0.4033730471276607\n",
      "train loss:0.39293884728587886\n",
      "train loss:0.574281312223958\n",
      "train loss:0.36789536308461007\n",
      "train loss:0.4501028385637105\n",
      "train loss:0.5809169491750192\n",
      "train loss:0.32251608837920565\n",
      "train loss:0.4708436907595942\n",
      "train loss:0.4322541594885141\n",
      "train loss:0.560075224508562\n",
      "train loss:0.29704850451949516\n",
      "train loss:0.4227769877552159\n",
      "train loss:0.31108283682956306\n",
      "train loss:0.33509423302607627\n",
      "train loss:0.33334979812862026\n",
      "train loss:0.4761680482819874\n",
      "train loss:0.33495605515431737\n",
      "train loss:0.4494201172932574\n",
      "train loss:0.3676686058801859\n",
      "train loss:0.418854966305837\n",
      "train loss:0.3505783019570621\n",
      "train loss:0.5689841549685096\n",
      "train loss:0.40484275028528366\n",
      "train loss:0.4952579983820846\n",
      "train loss:0.3373288801021932\n",
      "train loss:0.32200260499464756\n",
      "train loss:0.42040194421299537\n",
      "train loss:0.3310453642039943\n",
      "train loss:0.2858246781840409\n",
      "train loss:0.4599030235972176\n",
      "train loss:0.35933558412857614\n",
      "train loss:0.30119331557286183\n",
      "train loss:0.3395135877549771\n",
      "train loss:0.3532760208178254\n",
      "train loss:0.3834418455412489\n",
      "train loss:0.3733145846057726\n",
      "train loss:0.4893953921037252\n",
      "train loss:0.5084347307392783\n",
      "train loss:0.38417989205574316\n",
      "train loss:0.2858415629177396\n",
      "train loss:0.41380734672774117\n",
      "train loss:0.3882378328213968\n",
      "train loss:0.3325155003980921\n",
      "train loss:0.359104667974423\n",
      "train loss:0.48680923077369187\n",
      "train loss:0.4040640049355663\n",
      "train loss:0.400116340998444\n",
      "train loss:0.3599645704093718\n",
      "train loss:0.3789802121658755\n",
      "train loss:0.3072005618043786\n",
      "train loss:0.3646020531661224\n",
      "train loss:0.37444383646504553\n",
      "train loss:0.40485494282687073\n",
      "train loss:0.47082244647652716\n",
      "train loss:0.347101684923854\n",
      "train loss:0.21161524939899287\n",
      "train loss:0.4202846993226006\n",
      "train loss:0.3262437729555707\n",
      "train loss:0.4150456759785128\n",
      "train loss:0.5068866833642511\n",
      "train loss:0.4228378576379329\n",
      "train loss:0.48125553964073453\n",
      "train loss:0.4284333094862902\n",
      "train loss:0.4124745650460543\n",
      "train loss:0.3731363220569676\n",
      "train loss:0.3573789332212045\n",
      "train loss:0.4134833278365299\n",
      "train loss:0.461823043581483\n",
      "train loss:0.33849983840721154\n",
      "train loss:0.5091930791132336\n",
      "train loss:0.35191620465255896\n",
      "train loss:0.3294492724437902\n",
      "train loss:0.4540858525627126\n",
      "train loss:0.33482352209616695\n",
      "train loss:0.4274744566422202\n",
      "train loss:0.402448460775114\n",
      "train loss:0.42970775265334027\n",
      "train loss:0.4392365391322782\n",
      "train loss:0.28972999065963584\n",
      "train loss:0.41145689345784303\n",
      "train loss:0.4540634922623379\n",
      "train loss:0.34313094775484293\n",
      "train loss:0.4661668485204797\n",
      "train loss:0.35906161933042535\n",
      "train loss:0.432489334201405\n",
      "train loss:0.41696388950399876\n",
      "train loss:0.3759456672263785\n",
      "train loss:0.5177552031097885\n",
      "train loss:0.3873496660277754\n",
      "train loss:0.27074618069361944\n",
      "train loss:0.5343022632470761\n",
      "train loss:0.40408224656006986\n",
      "train loss:0.3920745608622873\n",
      "train loss:0.38197672565057483\n",
      "train loss:0.3509576374993336\n",
      "train loss:0.5038644293847555\n",
      "train loss:0.3781525682861194\n",
      "train loss:0.4330405783901117\n",
      "train loss:0.39198352182100427\n",
      "train loss:0.3441484861405065\n",
      "train loss:0.5302289892006014\n",
      "train loss:0.46818567477995393\n",
      "train loss:0.5006419021125237\n",
      "train loss:0.4913649628267499\n",
      "train loss:0.3570109881132783\n",
      "train loss:0.5195642904510956\n",
      "train loss:0.4066814261428554\n",
      "train loss:0.44361939065354056\n",
      "train loss:0.3458640611439505\n",
      "train loss:0.37681384368003906\n",
      "train loss:0.4242241871033692\n",
      "train loss:0.25478790971379556\n",
      "train loss:0.41634314199789907\n",
      "train loss:0.46354807285911176\n",
      "train loss:0.37473989902078875\n",
      "train loss:0.4567463806603477\n",
      "train loss:0.43926334829547997\n",
      "train loss:0.4961561845457246\n",
      "train loss:0.384960873554021\n",
      "train loss:0.287871571336063\n",
      "train loss:0.3749999253355555\n",
      "train loss:0.36023518213436007\n",
      "train loss:0.39004779266467965\n",
      "train loss:0.5115069900249348\n",
      "train loss:0.40161496703336214\n",
      "train loss:0.43348500101568144\n",
      "train loss:0.3391464138142187\n",
      "train loss:0.4123136983021159\n",
      "train loss:0.33849085722040984\n",
      "train loss:0.34843052735840807\n",
      "train loss:0.40085721996947904\n",
      "train loss:0.3484617771334162\n",
      "train loss:0.39123166327653164\n",
      "train loss:0.2807262779961299\n",
      "train loss:0.47421749744512576\n",
      "train loss:0.33624805947247566\n",
      "train loss:0.5414689033403643\n",
      "train loss:0.3908880392408571\n",
      "train loss:0.3936294801835431\n",
      "train loss:0.48190278132178915\n",
      "train loss:0.33738420904574085\n",
      "train loss:0.2586130822899402\n",
      "train loss:0.43997367823365147\n",
      "train loss:0.48924472406913855\n",
      "train loss:0.33912804705092614\n",
      "train loss:0.4049483010986932\n",
      "train loss:0.4535338682961912\n",
      "train loss:0.4718618602703291\n",
      "train loss:0.330587896959349\n",
      "train loss:0.34075459236667116\n",
      "train loss:0.3573319740499473\n",
      "train loss:0.3948944553059037\n",
      "train loss:0.5008900527874427\n",
      "train loss:0.3651926609123548\n",
      "train loss:0.31909686766416995\n",
      "train loss:0.28458569094128094\n",
      "train loss:0.4532998805540503\n",
      "train loss:0.27972998437146235\n",
      "train loss:0.4265223390133773\n",
      "train loss:0.4154366637576107\n",
      "=== epoch:2, train acc:0.872, test acc:0.844 ===\n",
      "train loss:0.2872701477771664\n",
      "train loss:0.28710316319220147\n",
      "train loss:0.31964164062307754\n",
      "train loss:0.2537644252123152\n",
      "train loss:0.3481956565120095\n",
      "train loss:0.44817797231469975\n",
      "train loss:0.2941451768310289\n",
      "train loss:0.4636215882399554\n",
      "train loss:0.36658193260769323\n",
      "train loss:0.4921496037361339\n",
      "train loss:0.3253748082883432\n",
      "train loss:0.3222052454822248\n",
      "train loss:0.33361007437368756\n",
      "train loss:0.486942413908688\n",
      "train loss:0.28689102716839276\n",
      "train loss:0.5648038255057448\n",
      "train loss:0.29059067919212556\n",
      "train loss:0.43355533386498485\n",
      "train loss:0.18984874288353665\n",
      "train loss:0.4023184064714998\n",
      "train loss:0.2899984386668814\n",
      "train loss:0.34935948259336863\n",
      "train loss:0.358969008232517\n",
      "train loss:0.26877818891788396\n",
      "train loss:0.31667074876948836\n",
      "train loss:0.28992123483579885\n",
      "train loss:0.42073800679121165\n",
      "train loss:0.2670629837448623\n",
      "train loss:0.4398387330645502\n",
      "train loss:0.34662175224944425\n",
      "train loss:0.3483512160426618\n",
      "train loss:0.37269944857116216\n",
      "train loss:0.455643340679481\n",
      "train loss:0.5156866840173691\n",
      "train loss:0.33955432399272056\n",
      "train loss:0.5252815437340373\n",
      "train loss:0.42012435194298375\n",
      "train loss:0.43935341621267227\n",
      "train loss:0.39325773406318126\n",
      "train loss:0.37217897618732787\n",
      "train loss:0.39004471054310824\n",
      "train loss:0.37949487535038323\n",
      "train loss:0.42085984982408803\n",
      "train loss:0.3492669130213048\n",
      "train loss:0.4502108810445533\n",
      "train loss:0.34962145053263927\n",
      "train loss:0.3037865013090523\n",
      "train loss:0.33614292513548377\n",
      "train loss:0.39940219882646055\n",
      "train loss:0.5190684295260322\n",
      "train loss:0.4159627459785973\n",
      "train loss:0.2436823911095654\n",
      "train loss:0.3688455274130022\n",
      "train loss:0.32090644728324863\n",
      "train loss:0.3546541200707164\n",
      "train loss:0.35969835708039993\n",
      "train loss:0.45441858101132176\n",
      "train loss:0.4078600223014639\n",
      "train loss:0.374365370282169\n",
      "train loss:0.425553816157146\n",
      "train loss:0.28259502465491426\n",
      "train loss:0.42756896466473726\n",
      "train loss:0.32208468040837696\n",
      "train loss:0.3370520152984416\n",
      "train loss:0.46044980374905314\n",
      "train loss:0.3086809506924808\n",
      "train loss:0.3166018395138035\n",
      "train loss:0.37917517262108275\n",
      "train loss:0.3600019204517046\n",
      "train loss:0.27230160539139503\n",
      "train loss:0.40893884977053124\n",
      "train loss:0.47521593923784117\n",
      "train loss:0.41029194690545806\n",
      "train loss:0.35973118322225367\n",
      "train loss:0.39306219282151816\n",
      "train loss:0.4541577949575256\n",
      "train loss:0.5854565115039607\n",
      "train loss:0.4088457421288455\n",
      "train loss:0.425956258621576\n",
      "train loss:0.3381436283668164\n",
      "train loss:0.3986531729287293\n",
      "train loss:0.5599546909627351\n",
      "train loss:0.3212509755218946\n",
      "train loss:0.32856606622107004\n",
      "train loss:0.5204775062720423\n",
      "train loss:0.36528756385142797\n",
      "train loss:0.4982677555954817\n",
      "train loss:0.412790102949755\n",
      "train loss:0.3569226074460885\n",
      "train loss:0.2796941533814312\n",
      "train loss:0.22871529324532552\n",
      "train loss:0.29589764107827454\n",
      "train loss:0.3631289549110537\n",
      "train loss:0.5350656401892833\n",
      "train loss:0.3574790525415546\n",
      "train loss:0.35316687335440855\n",
      "train loss:0.3152481084857084\n",
      "train loss:0.2574960749761813\n",
      "train loss:0.33908645696246514\n",
      "train loss:0.4204566963862315\n",
      "train loss:0.38389804153204193\n",
      "train loss:0.46569938699089586\n",
      "train loss:0.38998049063368323\n",
      "train loss:0.39807760526546426\n",
      "train loss:0.4534704176482516\n",
      "train loss:0.3160792868822682\n",
      "train loss:0.21885775925253256\n",
      "train loss:0.4077454966422971\n",
      "train loss:0.2570782235513797\n",
      "train loss:0.4479692076683105\n",
      "train loss:0.3883789379164771\n",
      "train loss:0.27449358376249355\n",
      "train loss:0.3611770245410827\n",
      "train loss:0.4065683964712386\n",
      "train loss:0.2944732447829945\n",
      "train loss:0.31062597452227175\n",
      "train loss:0.5336124212703401\n",
      "train loss:0.26627413857303317\n",
      "train loss:0.35428052608558214\n",
      "train loss:0.27389648284790963\n",
      "train loss:0.32966108996389926\n",
      "train loss:0.43126808916864257\n",
      "train loss:0.41625440927537355\n",
      "train loss:0.22607585018035486\n",
      "train loss:0.32614720177733325\n",
      "train loss:0.4189523750505137\n",
      "train loss:0.29886965257835174\n",
      "train loss:0.401996566929075\n",
      "train loss:0.3354567807844485\n",
      "train loss:0.37341408670021586\n",
      "train loss:0.33761387401666637\n",
      "train loss:0.3592109057811097\n",
      "train loss:0.29510868184641353\n",
      "train loss:0.4636377955206604\n",
      "train loss:0.35129464691603574\n",
      "train loss:0.26119802960995214\n",
      "train loss:0.28814058611273596\n",
      "train loss:0.2627759462103537\n",
      "train loss:0.4282453556144169\n",
      "train loss:0.2521260637183863\n",
      "train loss:0.44020995895127707\n",
      "train loss:0.3155817248141912\n",
      "train loss:0.34274122623152303\n",
      "train loss:0.4371987607960304\n",
      "train loss:0.33605294998511437\n",
      "train loss:0.3946618059558892\n",
      "train loss:0.2953368709310912\n",
      "train loss:0.36892427904651387\n",
      "train loss:0.18116224924249796\n",
      "train loss:0.327169291998199\n",
      "train loss:0.25578244393753624\n",
      "train loss:0.4274174636686515\n",
      "train loss:0.4043150989894881\n",
      "train loss:0.34405019272765125\n",
      "train loss:0.3218429775645098\n",
      "train loss:0.23860103121745588\n",
      "train loss:0.3911443969884923\n",
      "train loss:0.49620344681328094\n",
      "train loss:0.35371601144778964\n",
      "train loss:0.37823968045962103\n",
      "train loss:0.49080395050985964\n",
      "train loss:0.3196838042443913\n",
      "train loss:0.4787003110858721\n",
      "train loss:0.5413043248996895\n",
      "train loss:0.435168029865687\n",
      "train loss:0.5340836082222783\n",
      "train loss:0.2514843485763263\n",
      "train loss:0.35802113888710674\n",
      "train loss:0.3088862855849996\n",
      "train loss:0.3906918099997445\n",
      "train loss:0.41656917951526096\n",
      "train loss:0.2580444631599439\n",
      "train loss:0.3575983774861586\n",
      "train loss:0.3806261707617316\n",
      "train loss:0.2776947741774013\n",
      "train loss:0.42652969461941237\n",
      "train loss:0.36266823299772705\n",
      "train loss:0.3814152694358524\n",
      "train loss:0.2803699000453397\n",
      "train loss:0.3546553804000307\n",
      "train loss:0.3980178631524469\n",
      "train loss:0.4079580268042973\n",
      "train loss:0.3956088929708613\n",
      "train loss:0.4106285909397795\n",
      "train loss:0.41985927008815915\n",
      "train loss:0.3699330501525759\n",
      "train loss:0.20898628039696018\n",
      "train loss:0.41638947047651237\n",
      "train loss:0.2752817173013604\n",
      "train loss:0.4376929595648536\n",
      "train loss:0.3624170124980145\n",
      "train loss:0.24124789145893072\n",
      "train loss:0.360390523240586\n",
      "train loss:0.5291485180814866\n",
      "train loss:0.33590177367936414\n",
      "train loss:0.3398481700461556\n",
      "train loss:0.3843709283192556\n",
      "train loss:0.377920804343895\n",
      "train loss:0.2480568327260031\n",
      "train loss:0.3433542996831991\n",
      "train loss:0.2690005931403022\n",
      "train loss:0.3402404928464783\n",
      "train loss:0.2494873424971783\n",
      "train loss:0.2456677097391606\n",
      "train loss:0.31569132840246467\n",
      "train loss:0.4096240388526254\n",
      "train loss:0.41080146850294397\n",
      "train loss:0.3483399903970827\n",
      "train loss:0.424622907699871\n",
      "train loss:0.4008905406727027\n",
      "train loss:0.3857922153909208\n",
      "train loss:0.3252309625958041\n",
      "train loss:0.3201323156236014\n",
      "train loss:0.596461901635211\n",
      "train loss:0.2713996708621025\n",
      "train loss:0.2674844080870522\n",
      "train loss:0.3955859851403855\n",
      "train loss:0.36029373519311503\n",
      "train loss:0.353850808709415\n",
      "train loss:0.373324552211903\n",
      "train loss:0.42233161071579195\n",
      "train loss:0.39746973128214386\n",
      "train loss:0.31179072391938695\n",
      "train loss:0.28010889492650415\n",
      "train loss:0.33298195201085096\n",
      "train loss:0.2536888579108508\n",
      "train loss:0.32968171074363917\n",
      "train loss:0.3886466309625451\n",
      "train loss:0.31275046972207315\n",
      "train loss:0.35612041720031884\n",
      "train loss:0.231006395029434\n",
      "train loss:0.38915553966474403\n",
      "train loss:0.3250185521748144\n",
      "train loss:0.3998252556794071\n",
      "train loss:0.233355648445542\n",
      "train loss:0.2696932323832085\n",
      "train loss:0.32582436983599955\n",
      "train loss:0.1990904239619481\n",
      "train loss:0.37330207933168735\n",
      "train loss:0.1918161172581356\n",
      "train loss:0.3613693816305697\n",
      "train loss:0.24974208992938954\n",
      "train loss:0.3361639232690816\n",
      "train loss:0.3634558845622854\n",
      "train loss:0.21001114339322866\n",
      "train loss:0.4621212308646518\n",
      "train loss:0.3987983564260542\n",
      "train loss:0.3328508155321986\n",
      "train loss:0.2999254998739655\n",
      "train loss:0.28065152060938003\n",
      "train loss:0.5083231648398585\n",
      "train loss:0.29974929077674217\n",
      "train loss:0.49458215426697033\n",
      "train loss:0.3249577625688098\n",
      "train loss:0.31361138562891006\n",
      "train loss:0.34040833908472345\n",
      "train loss:0.3629599994206745\n",
      "train loss:0.36662470445813916\n",
      "train loss:0.3588881991855842\n",
      "train loss:0.37909792403640014\n",
      "train loss:0.320338565974354\n",
      "train loss:0.35775578714025164\n",
      "train loss:0.282627883334216\n",
      "train loss:0.27465465903395136\n",
      "train loss:0.3442191204901643\n",
      "train loss:0.22273698454467872\n",
      "train loss:0.3219905497973232\n",
      "train loss:0.2752027158621954\n",
      "train loss:0.357486051755308\n",
      "train loss:0.33279842045880487\n",
      "train loss:0.27076573690992334\n",
      "train loss:0.2632329951018801\n",
      "train loss:0.30952959330111446\n",
      "train loss:0.2553326934186884\n",
      "train loss:0.3800954691773714\n",
      "train loss:0.48082838810568057\n",
      "train loss:0.2985588260023064\n",
      "train loss:0.23955096175808446\n",
      "train loss:0.3393371346095167\n",
      "train loss:0.4077240906479893\n",
      "train loss:0.3822007990067262\n",
      "train loss:0.27556653794405206\n",
      "train loss:0.2549555765285896\n",
      "train loss:0.3218254916130086\n",
      "train loss:0.45809727022254587\n",
      "train loss:0.37081067197102047\n",
      "train loss:0.35243984028206754\n",
      "train loss:0.3918799871503145\n",
      "train loss:0.4566739829590417\n",
      "train loss:0.45525654347471084\n",
      "train loss:0.27994381653967043\n",
      "train loss:0.29746208133590246\n",
      "train loss:0.36028594823664956\n",
      "train loss:0.3113080738498359\n",
      "train loss:0.3251859361612974\n",
      "train loss:0.3136712420482402\n",
      "train loss:0.4287205880963593\n",
      "train loss:0.3121537163036958\n",
      "train loss:0.29681687919742994\n",
      "train loss:0.2800507564889562\n",
      "train loss:0.3388824312491008\n",
      "train loss:0.32907147388922253\n",
      "train loss:0.36643102661550964\n",
      "train loss:0.23003727367319649\n",
      "train loss:0.3511115913887317\n",
      "train loss:0.2422738807354492\n",
      "train loss:0.32107002395464074\n",
      "train loss:0.2538589392244962\n",
      "train loss:0.3469749321485416\n",
      "train loss:0.21705290426897916\n",
      "train loss:0.36827389181570125\n",
      "train loss:0.26901911698618763\n",
      "train loss:0.380597535960835\n",
      "train loss:0.2871795127100551\n",
      "train loss:0.2316518647222844\n",
      "train loss:0.3666634705018158\n",
      "train loss:0.3820189776639993\n",
      "train loss:0.33911533469781374\n",
      "train loss:0.3018716908404795\n",
      "train loss:0.32968658116188626\n",
      "train loss:0.3610893585449441\n",
      "train loss:0.3609950019152553\n",
      "train loss:0.23410869155737582\n",
      "train loss:0.26522166157455385\n",
      "train loss:0.3215476567895058\n",
      "train loss:0.23975682020222577\n",
      "train loss:0.48622798171595377\n",
      "train loss:0.29998603702388843\n",
      "train loss:0.41385430688058705\n",
      "train loss:0.3886841165643927\n",
      "train loss:0.4983637363732511\n",
      "train loss:0.3465216564625214\n",
      "train loss:0.38286485855909624\n",
      "train loss:0.42741620392281626\n",
      "train loss:0.31325105774824785\n",
      "train loss:0.36680736414803994\n",
      "train loss:0.35145358642950514\n",
      "train loss:0.34808180049935794\n",
      "train loss:0.34957262202329686\n",
      "train loss:0.426195563942839\n",
      "train loss:0.3403896918178053\n",
      "train loss:0.321728567226673\n",
      "train loss:0.2994345584293805\n",
      "train loss:0.4149980835105465\n",
      "train loss:0.25301063330489787\n",
      "train loss:0.19359487502412928\n",
      "train loss:0.26272481154733207\n",
      "train loss:0.5552104761847948\n",
      "train loss:0.28982537848489776\n",
      "train loss:0.47193135674436215\n",
      "train loss:0.44210456607566884\n",
      "train loss:0.37404547944411964\n",
      "train loss:0.39896258055060535\n",
      "train loss:0.33033443890270214\n",
      "train loss:0.34902581668735944\n",
      "train loss:0.3487851833022899\n",
      "train loss:0.3871948576129368\n",
      "train loss:0.3216233521606023\n",
      "train loss:0.34232886620109054\n",
      "train loss:0.3094823680722424\n",
      "train loss:0.3428954799520912\n",
      "train loss:0.24386133404938545\n",
      "train loss:0.3954021416777205\n",
      "train loss:0.23658982545023768\n",
      "train loss:0.3383002931226158\n",
      "train loss:0.3025043731419238\n",
      "train loss:0.3717210465481427\n",
      "train loss:0.34232047052520287\n",
      "train loss:0.3994617344876207\n",
      "train loss:0.4223052450392915\n",
      "train loss:0.345802812846416\n",
      "train loss:0.24315310352973982\n",
      "train loss:0.516564166359148\n",
      "train loss:0.2977827956179544\n",
      "train loss:0.40081997373099315\n",
      "train loss:0.2752976454100626\n",
      "train loss:0.4572261229350614\n",
      "train loss:0.4510777314784486\n",
      "train loss:0.3463173902941342\n",
      "train loss:0.22620651610445414\n",
      "train loss:0.2164230836304123\n",
      "train loss:0.3291182555090338\n",
      "train loss:0.3823187357032509\n",
      "train loss:0.2634644088476392\n",
      "train loss:0.36951527946774104\n",
      "train loss:0.4448782949692906\n",
      "train loss:0.5283258322343424\n",
      "train loss:0.33847911078735116\n",
      "train loss:0.40468635034924966\n",
      "train loss:0.260092735035318\n",
      "train loss:0.2850870090490996\n",
      "train loss:0.32325340821699305\n",
      "train loss:0.3076867113791319\n",
      "train loss:0.635778458131563\n",
      "train loss:0.37475161383980043\n",
      "train loss:0.44513304748392274\n",
      "train loss:0.2515246693027583\n",
      "train loss:0.37726384073872377\n",
      "train loss:0.2863781705081248\n",
      "train loss:0.32887050782834243\n",
      "train loss:0.3041600982423553\n",
      "train loss:0.41925272398789476\n",
      "train loss:0.3947181737426773\n",
      "train loss:0.23735291823391738\n",
      "train loss:0.2515926703637979\n",
      "train loss:0.2780830433461597\n",
      "train loss:0.31530265219308495\n",
      "train loss:0.3560020946895904\n",
      "train loss:0.46022137843641453\n",
      "train loss:0.2185883617978189\n",
      "train loss:0.3531339680012791\n",
      "train loss:0.3164746111823312\n",
      "train loss:0.22364043042303478\n",
      "train loss:0.2806834112877124\n",
      "train loss:0.36606885540974815\n",
      "train loss:0.5011175625925229\n",
      "train loss:0.27651837561643416\n",
      "train loss:0.3612361365151916\n",
      "train loss:0.3058813165452535\n",
      "train loss:0.3250044529809918\n",
      "train loss:0.4543176373046364\n",
      "train loss:0.3945037000891577\n",
      "train loss:0.23603361840262074\n",
      "train loss:0.330476024632834\n",
      "train loss:0.31452787861239295\n",
      "train loss:0.3881831323913911\n",
      "train loss:0.28247883741293855\n",
      "train loss:0.24732587455614738\n",
      "train loss:0.2553866943547143\n",
      "train loss:0.2920027422834265\n",
      "train loss:0.28812506232446095\n",
      "train loss:0.252946225516674\n",
      "train loss:0.2925998596047703\n",
      "train loss:0.384090465739527\n",
      "train loss:0.28554384722348536\n",
      "train loss:0.30333577538831785\n",
      "train loss:0.3301104867622224\n",
      "train loss:0.3291301565481668\n",
      "train loss:0.21348819177250225\n",
      "train loss:0.4387154838180779\n",
      "train loss:0.2774466328128718\n",
      "train loss:0.307406238469478\n",
      "train loss:0.2955921710662784\n",
      "train loss:0.15674222335472127\n",
      "train loss:0.2936290186585243\n",
      "train loss:0.2448116261579685\n",
      "train loss:0.15006701245039195\n",
      "train loss:0.28051223033571693\n",
      "train loss:0.32942376163379306\n",
      "train loss:0.3637225286439581\n",
      "train loss:0.35380216401535897\n",
      "train loss:0.31699738369182234\n",
      "train loss:0.248880720223935\n",
      "train loss:0.22849460649866685\n",
      "train loss:0.3504573120519145\n",
      "train loss:0.434515145403487\n",
      "train loss:0.3024435128578267\n",
      "train loss:0.35266354302697445\n",
      "train loss:0.35293723221750256\n",
      "train loss:0.3038165352119732\n",
      "train loss:0.3289999740518747\n",
      "train loss:0.394074203084455\n",
      "train loss:0.37073834002804096\n",
      "train loss:0.36180208251665724\n",
      "train loss:0.38534324404745446\n",
      "train loss:0.37706060754636345\n",
      "train loss:0.31431658446983013\n",
      "train loss:0.38375926630181717\n",
      "train loss:0.4345011850805417\n",
      "train loss:0.3103004911134863\n",
      "train loss:0.4087280025813626\n",
      "train loss:0.25734258325076914\n",
      "train loss:0.2594089263878358\n",
      "train loss:0.25043429185409954\n",
      "train loss:0.2318114750638811\n",
      "train loss:0.2998690934713402\n",
      "train loss:0.3454140533131541\n",
      "train loss:0.39424272195584686\n",
      "train loss:0.35779786231575506\n",
      "train loss:0.33741208932498135\n",
      "train loss:0.32425081881674145\n",
      "train loss:0.3063216538124786\n",
      "train loss:0.2760001164785336\n",
      "train loss:0.5005293892696152\n",
      "train loss:0.182018744952264\n",
      "train loss:0.2605452532163152\n",
      "train loss:0.3926954764018468\n",
      "train loss:0.30212370364513735\n",
      "train loss:0.3413744788526234\n",
      "train loss:0.42355194063428947\n",
      "train loss:0.3596662431121462\n",
      "train loss:0.29717212412397365\n",
      "train loss:0.4013337427211161\n",
      "train loss:0.24931319150639655\n",
      "train loss:0.30631172585502753\n",
      "train loss:0.23765233267990074\n",
      "train loss:0.34140086016065235\n",
      "train loss:0.3795831206065563\n",
      "train loss:0.38884412376760447\n",
      "train loss:0.3511910171703621\n",
      "train loss:0.25079717380112926\n",
      "train loss:0.23191167659931097\n",
      "train loss:0.3267856221084415\n",
      "train loss:0.2315871454483713\n",
      "train loss:0.2730297841874281\n",
      "train loss:0.28624860699194615\n",
      "train loss:0.41208109586301284\n",
      "train loss:0.3083557103351769\n",
      "train loss:0.3202771560085002\n",
      "train loss:0.31578249549076937\n",
      "train loss:0.31537951973381845\n",
      "train loss:0.2880393757146549\n",
      "train loss:0.3276805904362648\n",
      "train loss:0.29701352939695713\n",
      "train loss:0.43178618821541775\n",
      "train loss:0.24696429758063337\n",
      "train loss:0.3177628541927041\n",
      "train loss:0.2641620050291647\n",
      "train loss:0.40302434096465434\n",
      "train loss:0.37485405248553805\n",
      "train loss:0.3331681968389256\n",
      "train loss:0.28142362478283883\n",
      "train loss:0.2634646116663606\n",
      "train loss:0.4052154642380287\n",
      "train loss:0.2655900548574721\n",
      "train loss:0.3247196179506327\n",
      "train loss:0.4582927713694391\n",
      "train loss:0.3479326092313386\n",
      "train loss:0.27753200225860813\n",
      "train loss:0.31712563005047245\n",
      "train loss:0.3010742923500183\n",
      "train loss:0.3267115085826997\n",
      "train loss:0.32545983866265543\n",
      "train loss:0.30819480530307175\n",
      "train loss:0.2522655522289737\n",
      "train loss:0.3106961484753052\n",
      "train loss:0.3444697747498208\n",
      "train loss:0.3820823472654065\n",
      "train loss:0.3321344544988009\n",
      "train loss:0.30689911543778914\n",
      "train loss:0.2693718900128112\n",
      "train loss:0.3752152254386226\n",
      "train loss:0.246210775330565\n",
      "train loss:0.2940433616850157\n",
      "train loss:0.31682563710913453\n",
      "train loss:0.27447773624561583\n",
      "train loss:0.2929360898954306\n",
      "train loss:0.3914193387493107\n",
      "train loss:0.3675524297441622\n",
      "train loss:0.31592047423861325\n",
      "train loss:0.3952430277416289\n",
      "train loss:0.290551379763718\n",
      "train loss:0.4269384518906294\n",
      "train loss:0.46458658248676804\n",
      "train loss:0.2083837779092412\n",
      "train loss:0.33943818572386747\n",
      "train loss:0.265385482625198\n",
      "train loss:0.3066813391954262\n",
      "train loss:0.3533376392557045\n",
      "train loss:0.3333715727053698\n",
      "train loss:0.31696848242292797\n",
      "train loss:0.4723502527876392\n",
      "train loss:0.2949228359097035\n",
      "train loss:0.28175898073613004\n",
      "train loss:0.2839633662003026\n",
      "train loss:0.37601681501292605\n",
      "train loss:0.2277889049098247\n",
      "train loss:0.3016317362360184\n",
      "train loss:0.3161655379685326\n",
      "train loss:0.18351663556807232\n",
      "train loss:0.26290152388249927\n",
      "train loss:0.2896005901614596\n",
      "train loss:0.421192677925632\n",
      "train loss:0.3067176834055557\n",
      "train loss:0.2077933405446243\n",
      "train loss:0.309119130486619\n",
      "train loss:0.28905942793356154\n",
      "train loss:0.1956746633885847\n",
      "train loss:0.45043820083483566\n",
      "train loss:0.3561023077336478\n",
      "train loss:0.2563889682484743\n",
      "train loss:0.3609660349702508\n",
      "train loss:0.4181868277244203\n",
      "train loss:0.2737363375215485\n",
      "train loss:0.25677822416831986\n",
      "train loss:0.33154541965915785\n",
      "train loss:0.4407579017109956\n",
      "train loss:0.18826432499191828\n",
      "train loss:0.27526931006412614\n",
      "train loss:0.23611534025041103\n",
      "train loss:0.22086388932983758\n",
      "train loss:0.3868337562460455\n",
      "train loss:0.22971799799894657\n",
      "train loss:0.3518536383359233\n",
      "train loss:0.3649205598717061\n",
      "train loss:0.3470168252469276\n",
      "train loss:0.2920260911148852\n",
      "train loss:0.2518351536961775\n",
      "train loss:0.20883958697966448\n",
      "train loss:0.21777936282378618\n",
      "=== epoch:3, train acc:0.909, test acc:0.881 ===\n",
      "train loss:0.34127257932111843\n",
      "train loss:0.23670441752379984\n",
      "train loss:0.2759473686078999\n",
      "train loss:0.29825296590994826\n",
      "train loss:0.38301044843755405\n",
      "train loss:0.41927625430583715\n",
      "train loss:0.26500221137527313\n",
      "train loss:0.2142286094239696\n",
      "train loss:0.16954598189877937\n",
      "train loss:0.34189138307360656\n",
      "train loss:0.3828920009274286\n",
      "train loss:0.36951347602355505\n",
      "train loss:0.20963096294033995\n",
      "train loss:0.3158081583782056\n",
      "train loss:0.22315174044219865\n",
      "train loss:0.2842316034757159\n",
      "train loss:0.28795562349518383\n",
      "train loss:0.23913862519827275\n",
      "train loss:0.2890850338313873\n",
      "train loss:0.14999153007842697\n",
      "train loss:0.2756754951037311\n",
      "train loss:0.2677210885616158\n",
      "train loss:0.2553867970545185\n",
      "train loss:0.3309900071406425\n",
      "train loss:0.5200697676457565\n",
      "train loss:0.4439589584239172\n",
      "train loss:0.3128550791688777\n",
      "train loss:0.24720600982977475\n",
      "train loss:0.28303693745268044\n",
      "train loss:0.31516138729412724\n",
      "train loss:0.3324534633599649\n",
      "train loss:0.3880269404108997\n",
      "train loss:0.20774813090901706\n",
      "train loss:0.381445379716974\n",
      "train loss:0.3107332458836632\n",
      "train loss:0.32044307424731266\n",
      "train loss:0.2312564401713734\n",
      "train loss:0.24125290977947525\n",
      "train loss:0.3291216444995409\n",
      "train loss:0.38625475680161586\n",
      "train loss:0.18404063526775125\n",
      "train loss:0.24377213167248254\n",
      "train loss:0.196045211650022\n",
      "train loss:0.3365095367810956\n",
      "train loss:0.35074625563060396\n",
      "train loss:0.2283927122473884\n",
      "train loss:0.2352340907566003\n",
      "train loss:0.21727322298076732\n",
      "train loss:0.31304345730555644\n",
      "train loss:0.2708720746393702\n",
      "train loss:0.33530902093533305\n",
      "train loss:0.3057175570231957\n",
      "train loss:0.3423799659208726\n",
      "train loss:0.32880805088713033\n",
      "train loss:0.2561682922071822\n",
      "train loss:0.3181911187969305\n",
      "train loss:0.2742117836734362\n",
      "train loss:0.2459329715474328\n",
      "train loss:0.28883797989272464\n",
      "train loss:0.4510152328176823\n",
      "train loss:0.3090300390872744\n",
      "train loss:0.4818462379436123\n",
      "train loss:0.30116438904314535\n",
      "train loss:0.441747587176288\n",
      "train loss:0.47426631500452876\n",
      "train loss:0.40141560294746476\n",
      "train loss:0.3092755034129465\n",
      "train loss:0.31488591752457096\n",
      "train loss:0.19984958505596315\n",
      "train loss:0.2666659071993666\n",
      "train loss:0.4320518663618637\n",
      "train loss:0.39942199732972855\n",
      "train loss:0.3302358371690131\n",
      "train loss:0.3387619045129291\n",
      "train loss:0.19697437626192824\n",
      "train loss:0.2614941830515722\n",
      "train loss:0.21701892637240053\n",
      "train loss:0.27266094701587745\n",
      "train loss:0.22995605792307333\n",
      "train loss:0.36867565622901355\n",
      "train loss:0.38640620908021794\n",
      "train loss:0.301554711124428\n",
      "train loss:0.23877342937151366\n",
      "train loss:0.344386770968595\n",
      "train loss:0.23093849862974675\n",
      "train loss:0.31953305436806195\n",
      "train loss:0.27799710374235165\n",
      "train loss:0.28437766587881935\n",
      "train loss:0.22554296299841145\n",
      "train loss:0.281480475780006\n",
      "train loss:0.32258225053297673\n",
      "train loss:0.2818079504011084\n",
      "train loss:0.2805441572683038\n",
      "train loss:0.407691808967786\n",
      "train loss:0.3102463125053203\n",
      "train loss:0.22272850125729424\n",
      "train loss:0.3753855173034837\n",
      "train loss:0.24695729332935606\n",
      "train loss:0.23119690516484936\n",
      "train loss:0.29649232399712827\n",
      "train loss:0.36788469419284375\n",
      "train loss:0.2022426450451604\n",
      "train loss:0.35573247768567773\n",
      "train loss:0.31498682688369517\n",
      "train loss:0.3217813144444541\n",
      "train loss:0.4105057879678223\n",
      "train loss:0.297601968375301\n",
      "train loss:0.35408037303729656\n",
      "train loss:0.20529310956290106\n",
      "train loss:0.2741896664480911\n",
      "train loss:0.3960792355593603\n",
      "train loss:0.4388455931970646\n",
      "train loss:0.28581817149323063\n",
      "train loss:0.30603051163618\n",
      "train loss:0.3234770271487508\n",
      "train loss:0.25962576699410966\n",
      "train loss:0.37015612616089333\n",
      "train loss:0.31852611892870125\n",
      "train loss:0.30869668078308493\n",
      "train loss:0.30483472741418566\n",
      "train loss:0.20612461710219052\n",
      "train loss:0.265241273091028\n",
      "train loss:0.2458288365145805\n",
      "train loss:0.251920717882076\n",
      "train loss:0.37571800162105595\n",
      "train loss:0.28532733221970663\n",
      "train loss:0.27859965670872544\n",
      "train loss:0.2099660495126879\n",
      "train loss:0.30345535264064877\n",
      "train loss:0.2687436632040626\n",
      "train loss:0.24693605383363781\n",
      "train loss:0.405309054360909\n",
      "train loss:0.31077230124291816\n",
      "train loss:0.34801269862468714\n",
      "train loss:0.35004129269724965\n",
      "train loss:0.27697313727695977\n",
      "train loss:0.15010037022951556\n",
      "train loss:0.17217416988067477\n",
      "train loss:0.2083087218035605\n",
      "train loss:0.1875945412233849\n",
      "train loss:0.3491794077209272\n",
      "train loss:0.24713959894985643\n",
      "train loss:0.3558576922696129\n",
      "train loss:0.19494222876862602\n",
      "train loss:0.371297676281291\n",
      "train loss:0.26292937837853964\n",
      "train loss:0.40974311393163715\n",
      "train loss:0.4748860369522192\n",
      "train loss:0.36414521905495845\n",
      "train loss:0.4128067826101339\n",
      "train loss:0.3193897258112904\n",
      "train loss:0.24057544501402547\n",
      "train loss:0.36317314761130376\n",
      "train loss:0.28652328549828016\n",
      "train loss:0.33424775026954817\n",
      "train loss:0.35764209411437237\n",
      "train loss:0.30103441836539385\n",
      "train loss:0.3513011211153427\n",
      "train loss:0.20795485805086802\n",
      "train loss:0.32200609337815356\n",
      "train loss:0.2630176873516039\n",
      "train loss:0.2732102923416105\n",
      "train loss:0.29627992362589484\n",
      "train loss:0.29216067518521377\n",
      "train loss:0.35405544825418134\n",
      "train loss:0.35239691520944705\n",
      "train loss:0.37054541146326686\n",
      "train loss:0.3229473596343898\n",
      "train loss:0.2585250647361501\n",
      "train loss:0.3611908527600829\n",
      "train loss:0.2838240874708759\n",
      "train loss:0.3874975065477691\n",
      "train loss:0.27992792253466653\n",
      "train loss:0.2618251863023846\n",
      "train loss:0.3525641377883116\n",
      "train loss:0.3002647140782823\n",
      "train loss:0.30541760043197924\n",
      "train loss:0.3009868163739314\n",
      "train loss:0.25656239309671897\n",
      "train loss:0.34258142936879954\n",
      "train loss:0.24445415413353594\n",
      "train loss:0.3613306837725285\n",
      "train loss:0.5126048285564943\n",
      "train loss:0.25060413995847297\n",
      "train loss:0.26052624855592127\n",
      "train loss:0.2365940369710202\n",
      "train loss:0.30479300121146863\n",
      "train loss:0.3059758833297682\n",
      "train loss:0.2767460538372354\n",
      "train loss:0.21472139305789317\n",
      "train loss:0.14960586807802895\n",
      "train loss:0.4332185699107098\n",
      "train loss:0.28610435153613173\n",
      "train loss:0.25450704944559793\n",
      "train loss:0.2263684862918567\n",
      "train loss:0.2586260029099531\n",
      "train loss:0.3168479161760895\n",
      "train loss:0.3300840315062599\n",
      "train loss:0.195946901329303\n",
      "train loss:0.3466991132129455\n",
      "train loss:0.25524354599185733\n",
      "train loss:0.22907535991204284\n",
      "train loss:0.22193330091690364\n",
      "train loss:0.410153210148734\n",
      "train loss:0.2204423513032648\n",
      "train loss:0.19791915460087384\n",
      "train loss:0.3078071194353603\n",
      "train loss:0.2681124534673581\n",
      "train loss:0.3126089247495324\n",
      "train loss:0.21121477383062742\n",
      "train loss:0.17636747949202555\n",
      "train loss:0.2553476053777799\n",
      "train loss:0.3014763376183485\n",
      "train loss:0.3497638272654205\n",
      "train loss:0.3292761131685545\n",
      "train loss:0.2389058062819746\n",
      "train loss:0.386816085251909\n",
      "train loss:0.1989582994061082\n",
      "train loss:0.28731336306852434\n",
      "train loss:0.26579886548561016\n",
      "train loss:0.32820457842087153\n",
      "train loss:0.26992307110321045\n",
      "train loss:0.2375191764428594\n",
      "train loss:0.24578728722421725\n",
      "train loss:0.32626893223694686\n",
      "train loss:0.30265394126865053\n",
      "train loss:0.213123731232403\n",
      "train loss:0.28987749084498765\n",
      "train loss:0.2632641684576789\n",
      "train loss:0.22344763586417013\n",
      "train loss:0.23990829611052825\n",
      "train loss:0.28892747764410365\n",
      "train loss:0.17244668607832062\n",
      "train loss:0.320802450099402\n",
      "train loss:0.24210572543195977\n",
      "train loss:0.2433740239389255\n",
      "train loss:0.24333894717032803\n",
      "train loss:0.22075163587968283\n",
      "train loss:0.34352919953568894\n",
      "train loss:0.2004152658035381\n",
      "train loss:0.26077577212697317\n",
      "train loss:0.3120266435050366\n",
      "train loss:0.19857770149314546\n",
      "train loss:0.27654046465225723\n",
      "train loss:0.24685325878557923\n",
      "train loss:0.23610074456598723\n",
      "train loss:0.29192364100042506\n",
      "train loss:0.3474462366003437\n",
      "train loss:0.19232795430156174\n",
      "train loss:0.357048597647889\n",
      "train loss:0.17954112988648072\n",
      "train loss:0.304980915366165\n",
      "train loss:0.40473601013833843\n",
      "train loss:0.2942977069353431\n",
      "train loss:0.20155007515782664\n",
      "train loss:0.38173763415405004\n",
      "train loss:0.3287804452302652\n",
      "train loss:0.19346652200590114\n",
      "train loss:0.39646092218141554\n",
      "train loss:0.31210887860609465\n",
      "train loss:0.2942074809645003\n",
      "train loss:0.17502833133360743\n",
      "train loss:0.37587912992437866\n",
      "train loss:0.40147803972562124\n",
      "train loss:0.4349836037952555\n",
      "train loss:0.2278436747701889\n",
      "train loss:0.32268760206951463\n",
      "train loss:0.2987782208198284\n",
      "train loss:0.36126220032166\n",
      "train loss:0.2442632824069896\n",
      "train loss:0.22766230729691533\n",
      "train loss:0.255465328227245\n",
      "train loss:0.41195214821947573\n",
      "train loss:0.2773781087985428\n",
      "train loss:0.30255292256163213\n",
      "train loss:0.2574084664296179\n",
      "train loss:0.2836152562071264\n",
      "train loss:0.312292943245039\n",
      "train loss:0.27396708051920143\n",
      "train loss:0.36704072702039886\n",
      "train loss:0.3663480773411977\n",
      "train loss:0.23787863960013245\n",
      "train loss:0.2705767400130476\n",
      "train loss:0.2161871209757138\n",
      "train loss:0.2437676921039515\n",
      "train loss:0.23162913991845407\n",
      "train loss:0.24441753229575905\n",
      "train loss:0.23689628626042603\n",
      "train loss:0.32558435580792877\n",
      "train loss:0.28009477795448784\n",
      "train loss:0.2630187671631279\n",
      "train loss:0.2456620794595139\n",
      "train loss:0.1797965899422883\n",
      "train loss:0.16584782602441436\n",
      "train loss:0.19821557359920774\n",
      "train loss:0.26366469909609747\n",
      "train loss:0.29285463189189653\n",
      "train loss:0.236391395835629\n",
      "train loss:0.30145898746010674\n",
      "train loss:0.25911816700707463\n",
      "train loss:0.21541349439777469\n",
      "train loss:0.2025034532894943\n",
      "train loss:0.23707072912471688\n",
      "train loss:0.2468664042820747\n",
      "train loss:0.18148782580789788\n",
      "train loss:0.2555866924634084\n",
      "train loss:0.27777040366248157\n",
      "train loss:0.3515172566906989\n",
      "train loss:0.2503101281880572\n",
      "train loss:0.4034568337247827\n",
      "train loss:0.4003824754774963\n",
      "train loss:0.4336021615552081\n",
      "train loss:0.28447185890772014\n",
      "train loss:0.3478174640082988\n",
      "train loss:0.2906609197884766\n",
      "train loss:0.2676124281537482\n",
      "train loss:0.2651062265643727\n",
      "train loss:0.28090195211979796\n",
      "train loss:0.2733598543700376\n",
      "train loss:0.23079856384331576\n",
      "train loss:0.25242869355863873\n",
      "train loss:0.26559076466128917\n",
      "train loss:0.2927130015075299\n",
      "train loss:0.32532799030492254\n",
      "train loss:0.3336695289366727\n",
      "train loss:0.24480988920447896\n",
      "train loss:0.3411445753889604\n",
      "train loss:0.3058989838598557\n",
      "train loss:0.2182224274054594\n",
      "train loss:0.27179510644517835\n",
      "train loss:0.20078235313905995\n",
      "train loss:0.36914819481013217\n",
      "train loss:0.31925819120851473\n",
      "train loss:0.24202820984301543\n",
      "train loss:0.31669497123002793\n",
      "train loss:0.2698887695494219\n",
      "train loss:0.2530322469896913\n",
      "train loss:0.2524563520400024\n",
      "train loss:0.3122250863051151\n",
      "train loss:0.23087508178939856\n",
      "train loss:0.26483613777934517\n",
      "train loss:0.46513714727983624\n",
      "train loss:0.2480317541228081\n",
      "train loss:0.1552855211037023\n",
      "train loss:0.18865253692991849\n",
      "train loss:0.23588071179576128\n",
      "train loss:0.22158285712168305\n",
      "train loss:0.42155171230403005\n",
      "train loss:0.2280716866383461\n",
      "train loss:0.27980039737510176\n",
      "train loss:0.23827191340716414\n",
      "train loss:0.4051371798724402\n",
      "train loss:0.2927460001206296\n",
      "train loss:0.242827828216477\n",
      "train loss:0.3668324172756188\n",
      "train loss:0.2611413352589068\n",
      "train loss:0.2600732106144918\n",
      "train loss:0.35569133682201154\n",
      "train loss:0.22096724568488835\n",
      "train loss:0.23490155939869564\n",
      "train loss:0.2824004045591971\n",
      "train loss:0.2855374450181276\n",
      "train loss:0.2362992922460968\n",
      "train loss:0.3589081915858139\n",
      "train loss:0.36270473044892937\n",
      "train loss:0.3835860628601744\n",
      "train loss:0.2730276921655841\n",
      "train loss:0.3725442468731986\n",
      "train loss:0.25078463251339067\n",
      "train loss:0.2683092346928506\n",
      "train loss:0.30614747805291914\n",
      "train loss:0.26776195584215634\n",
      "train loss:0.24295970085648233\n",
      "train loss:0.2675291571220823\n",
      "train loss:0.19436041492790607\n",
      "train loss:0.14778251156024727\n",
      "train loss:0.2681101468741809\n",
      "train loss:0.1392629175577743\n",
      "train loss:0.25284198035279754\n",
      "train loss:0.258389814462599\n",
      "train loss:0.1786019759563516\n",
      "train loss:0.3073201785888816\n",
      "train loss:0.29769165239447903\n",
      "train loss:0.31356670438727824\n",
      "train loss:0.19968620752800936\n",
      "train loss:0.2499050262563724\n",
      "train loss:0.33474977082540186\n",
      "train loss:0.3102450990936798\n",
      "train loss:0.3245238669355765\n",
      "train loss:0.33111133136741877\n",
      "train loss:0.32674911477399954\n",
      "train loss:0.28607641382007254\n",
      "train loss:0.3651033162884862\n",
      "train loss:0.28103245921152215\n",
      "train loss:0.3553558243232952\n",
      "train loss:0.22417310016673173\n",
      "train loss:0.26734547716350665\n",
      "train loss:0.23984735713255026\n",
      "train loss:0.29256222529815906\n",
      "train loss:0.28830363999391345\n",
      "train loss:0.24517498922686687\n",
      "train loss:0.5087774304347598\n",
      "train loss:0.2332854046580687\n",
      "train loss:0.39638534408855086\n",
      "train loss:0.2907932058073617\n",
      "train loss:0.30900392856480485\n",
      "train loss:0.34912809538335515\n",
      "train loss:0.19583366310967099\n",
      "train loss:0.3343651479715344\n",
      "train loss:0.2557923771280205\n",
      "train loss:0.4081683593049154\n",
      "train loss:0.23576426008035084\n",
      "train loss:0.32050356418695336\n",
      "train loss:0.2820368495295965\n",
      "train loss:0.2722719649245122\n",
      "train loss:0.2019254560420403\n",
      "train loss:0.23400089324749987\n",
      "train loss:0.25587908481343463\n",
      "train loss:0.3746125771580555\n",
      "train loss:0.18449263701325566\n",
      "train loss:0.29302843847172666\n",
      "train loss:0.2190095551127224\n",
      "train loss:0.3765726719095349\n",
      "train loss:0.31900253974022613\n",
      "train loss:0.2554238723441514\n",
      "train loss:0.2772885713659234\n",
      "train loss:0.31820353543798974\n",
      "train loss:0.2968298603339491\n",
      "train loss:0.27842591035495573\n",
      "train loss:0.2606319597532653\n",
      "train loss:0.4655024919656235\n",
      "train loss:0.4176073948257519\n",
      "train loss:0.38766900183124986\n",
      "train loss:0.30402353577448293\n",
      "train loss:0.2579678241332735\n",
      "train loss:0.30559912731330596\n",
      "train loss:0.19414659458642688\n",
      "train loss:0.22863575680175008\n",
      "train loss:0.23708061961830879\n",
      "train loss:0.30083408079366775\n",
      "train loss:0.20275055921164625\n",
      "train loss:0.30011396029386095\n",
      "train loss:0.3109162378918045\n",
      "train loss:0.20378892987817665\n",
      "train loss:0.3259393735018159\n",
      "train loss:0.2506655130004836\n",
      "train loss:0.3404701284822721\n",
      "train loss:0.3258345798904186\n",
      "train loss:0.20843524291976506\n",
      "train loss:0.2032763187122814\n",
      "train loss:0.3437483775341452\n",
      "train loss:0.3556175547086889\n",
      "train loss:0.30725779621468785\n",
      "train loss:0.2895182706411849\n",
      "train loss:0.2771980959042153\n",
      "train loss:0.3540062808741454\n",
      "train loss:0.29099266467594753\n",
      "train loss:0.2736005240390547\n",
      "train loss:0.23398160011359262\n",
      "train loss:0.18587531823326842\n",
      "train loss:0.25409616839213234\n",
      "train loss:0.32283789794707024\n",
      "train loss:0.26793156478112645\n",
      "train loss:0.23248108646181237\n",
      "train loss:0.22828745071382617\n",
      "train loss:0.21344238392195364\n",
      "train loss:0.2747071445631715\n",
      "train loss:0.18054239598251795\n",
      "train loss:0.32570401826967227\n",
      "train loss:0.3959032745782203\n",
      "train loss:0.2782261241474096\n",
      "train loss:0.39321605401741416\n",
      "train loss:0.2636738782312541\n",
      "train loss:0.2659539362110296\n",
      "train loss:0.2165892349252261\n",
      "train loss:0.3329896456326821\n",
      "train loss:0.2520690082988586\n",
      "train loss:0.3271497073441344\n",
      "train loss:0.2599389280987083\n",
      "train loss:0.25453359621065713\n",
      "train loss:0.2806638869215174\n",
      "train loss:0.24426429323190088\n",
      "train loss:0.23096226020653293\n",
      "train loss:0.19637273975635644\n",
      "train loss:0.3864528246233034\n",
      "train loss:0.2168329408193752\n",
      "train loss:0.28163848291970295\n",
      "train loss:0.30771376278716617\n",
      "train loss:0.25109706143478294\n",
      "train loss:0.18628363135851603\n",
      "train loss:0.3004577723085242\n",
      "train loss:0.16115781042863164\n",
      "train loss:0.23448976407221164\n",
      "train loss:0.21376645482262763\n",
      "train loss:0.23186080471057927\n",
      "train loss:0.21422965245515715\n",
      "train loss:0.33540447227890213\n",
      "train loss:0.4911757041148172\n",
      "train loss:0.23558463116269707\n",
      "train loss:0.20917883265208143\n",
      "train loss:0.20065101967724555\n",
      "train loss:0.19004075729743797\n",
      "train loss:0.34514875079122154\n",
      "train loss:0.3454009616263999\n",
      "train loss:0.23766354789013053\n",
      "train loss:0.19206276219464521\n",
      "train loss:0.2550691381957678\n",
      "train loss:0.3235332943336873\n",
      "train loss:0.18300535095635337\n",
      "train loss:0.39025306777883734\n",
      "train loss:0.27549640848571383\n",
      "train loss:0.19260421259025318\n",
      "train loss:0.23870548720356488\n",
      "train loss:0.2880162485861267\n",
      "train loss:0.23541581533004405\n",
      "train loss:0.3494938135526364\n",
      "train loss:0.3037599159423881\n",
      "train loss:0.2977760650935538\n",
      "train loss:0.14472843456251505\n",
      "train loss:0.32783215566195073\n",
      "train loss:0.2683186315347317\n",
      "train loss:0.30950472024438924\n",
      "train loss:0.28737702267475823\n",
      "train loss:0.31679493559405963\n",
      "train loss:0.2724049399221882\n",
      "train loss:0.259656258130392\n",
      "train loss:0.28122452241249474\n",
      "train loss:0.18102666706669002\n",
      "train loss:0.24346636103754613\n",
      "train loss:0.19301599415982623\n",
      "train loss:0.30932491499908976\n",
      "train loss:0.3874024315146296\n",
      "train loss:0.3018766450529271\n",
      "train loss:0.3962111384677703\n",
      "train loss:0.31871982650074715\n",
      "train loss:0.2932880096486857\n",
      "train loss:0.22175318422506618\n",
      "train loss:0.2654230117774323\n",
      "train loss:0.22087646656248758\n",
      "train loss:0.13774258893182542\n",
      "train loss:0.2383232824608135\n",
      "train loss:0.306482046791878\n",
      "train loss:0.26831193201798537\n",
      "train loss:0.24898852476876607\n",
      "train loss:0.16354852366250378\n",
      "train loss:0.313972324062679\n",
      "train loss:0.2483391074426045\n",
      "train loss:0.21325831287317215\n",
      "train loss:0.15915136544583663\n",
      "train loss:0.18973820164300764\n",
      "train loss:0.17187298254297914\n",
      "train loss:0.3302519227827456\n",
      "train loss:0.21477662626070798\n",
      "train loss:0.24278934855707127\n",
      "train loss:0.31048606995162603\n",
      "train loss:0.28661060701032964\n",
      "train loss:0.28606832299604557\n",
      "train loss:0.22059676592549318\n",
      "train loss:0.36497909317493665\n",
      "train loss:0.17245040124476105\n",
      "train loss:0.2778984310803469\n",
      "train loss:0.2353894611654657\n",
      "train loss:0.13230247307248114\n",
      "train loss:0.28779947456802546\n",
      "train loss:0.2937485466898285\n",
      "train loss:0.2802779738336778\n",
      "train loss:0.24542065329042173\n",
      "train loss:0.3045055524930371\n",
      "train loss:0.19566926834793427\n",
      "train loss:0.24890693388400517\n",
      "train loss:0.48597120397502835\n",
      "train loss:0.16613310525483782\n",
      "train loss:0.27036549974607293\n",
      "train loss:0.32408417574188847\n",
      "train loss:0.21758471846798216\n",
      "train loss:0.1543929593170437\n",
      "train loss:0.3129038491285981\n",
      "train loss:0.30574260376696605\n",
      "train loss:0.24324626915179295\n",
      "train loss:0.26285538624701066\n",
      "train loss:0.24723761745613404\n",
      "train loss:0.15658898043381475\n",
      "train loss:0.33434302628654955\n",
      "train loss:0.31760178652379983\n",
      "train loss:0.19900661221575913\n",
      "train loss:0.34933955473287814\n",
      "train loss:0.17608763192413046\n",
      "train loss:0.21008531472379588\n",
      "train loss:0.2988506517586762\n",
      "train loss:0.2716498966789869\n",
      "train loss:0.4170458808387601\n",
      "train loss:0.25697538835020045\n",
      "train loss:0.3052780462268624\n",
      "train loss:0.3494653959604031\n",
      "train loss:0.22895558459548543\n",
      "train loss:0.27918559040985064\n",
      "train loss:0.12835670103716404\n",
      "train loss:0.27472004730376304\n",
      "train loss:0.2322008948439041\n",
      "train loss:0.22286661747836767\n",
      "=== epoch:4, train acc:0.914, test acc:0.895 ===\n",
      "train loss:0.3241622201974606\n",
      "train loss:0.4025855871404105\n",
      "train loss:0.22011656283576614\n",
      "train loss:0.36799450659491556\n",
      "train loss:0.25240160190938987\n",
      "train loss:0.209566076412142\n",
      "train loss:0.19002769966590927\n",
      "train loss:0.3457774914535291\n",
      "train loss:0.27809151959068745\n",
      "train loss:0.2520942356649052\n",
      "train loss:0.3190243656987701\n",
      "train loss:0.19724507828583143\n",
      "train loss:0.2752120609738074\n",
      "train loss:0.22475104840595614\n",
      "train loss:0.23847477743694792\n",
      "train loss:0.31481608209049766\n",
      "train loss:0.25561999365474425\n",
      "train loss:0.33365792541869604\n",
      "train loss:0.2634553406811767\n",
      "train loss:0.2075016985324548\n",
      "train loss:0.2244588733196945\n",
      "train loss:0.31445374389223635\n",
      "train loss:0.2326012001505964\n",
      "train loss:0.2114850867690716\n",
      "train loss:0.25773620031087163\n",
      "train loss:0.16417431072099828\n",
      "train loss:0.35045801194109416\n",
      "train loss:0.23428841185628527\n",
      "train loss:0.22596001271100172\n",
      "train loss:0.37849895061936584\n",
      "train loss:0.29107423287380263\n",
      "train loss:0.292780056408029\n",
      "train loss:0.1527480511124449\n",
      "train loss:0.156669677120928\n",
      "train loss:0.38626970969397645\n",
      "train loss:0.2752217643273219\n",
      "train loss:0.21891698206031276\n",
      "train loss:0.3244667637695017\n",
      "train loss:0.31855507298402974\n",
      "train loss:0.18233993517715327\n",
      "train loss:0.1974928198827621\n",
      "train loss:0.2878856571441868\n",
      "train loss:0.3296138357268783\n",
      "train loss:0.2551290802841057\n",
      "train loss:0.45904673451785677\n",
      "train loss:0.3616790928928416\n",
      "train loss:0.2791023353905177\n",
      "train loss:0.17468343699439953\n",
      "train loss:0.19804770642805902\n",
      "train loss:0.39104772766532325\n",
      "train loss:0.3269015274328148\n",
      "train loss:0.27493225509788854\n",
      "train loss:0.3164463727615432\n",
      "train loss:0.30712659722932073\n",
      "train loss:0.18313453974983357\n",
      "train loss:0.35398651444015367\n",
      "train loss:0.2702732794125479\n",
      "train loss:0.316975193051509\n",
      "train loss:0.281723629538406\n",
      "train loss:0.37697866702275157\n",
      "train loss:0.3124877518095974\n",
      "train loss:0.2084781127492201\n",
      "train loss:0.21911383457547434\n",
      "train loss:0.3236867035452666\n",
      "train loss:0.3283826184614071\n",
      "train loss:0.24165323230908609\n",
      "train loss:0.2130075816208772\n",
      "train loss:0.24935834512669594\n",
      "train loss:0.2932260085604324\n",
      "train loss:0.3801710200693409\n",
      "train loss:0.2574727850284172\n",
      "train loss:0.3822478739738422\n",
      "train loss:0.32966552858725584\n",
      "train loss:0.22587793694628938\n",
      "train loss:0.2055492404198801\n",
      "train loss:0.2667763228716799\n",
      "train loss:0.3009957229422844\n",
      "train loss:0.21347225962626\n",
      "train loss:0.2957297239393586\n",
      "train loss:0.23688610391183315\n",
      "train loss:0.28110288770770825\n",
      "train loss:0.2877023206113106\n",
      "train loss:0.3042359278963175\n",
      "train loss:0.22248588208305553\n",
      "train loss:0.26208561630085403\n",
      "train loss:0.3254239266571482\n",
      "train loss:0.22683861914218462\n",
      "train loss:0.3413589067487567\n",
      "train loss:0.26614207163486175\n",
      "train loss:0.2880765411259532\n",
      "train loss:0.20484970525667978\n",
      "train loss:0.3255993242529645\n",
      "train loss:0.386746681165161\n",
      "train loss:0.28900538515735374\n",
      "train loss:0.3732115226065488\n",
      "train loss:0.1445130692298537\n",
      "train loss:0.14100792772264614\n",
      "train loss:0.22597851543888153\n",
      "train loss:0.2936963884243913\n",
      "train loss:0.29845325245193915\n",
      "train loss:0.25670043059495423\n",
      "train loss:0.18174709207265505\n",
      "train loss:0.26527712848351026\n",
      "train loss:0.2675722821321727\n",
      "train loss:0.2875534256996718\n",
      "train loss:0.29914401596059537\n",
      "train loss:0.2078669941023221\n",
      "train loss:0.2922668343013314\n",
      "train loss:0.2251974841665976\n",
      "train loss:0.2888054702086645\n",
      "train loss:0.2655604830647989\n",
      "train loss:0.19458960038729348\n",
      "train loss:0.3119942818054043\n",
      "train loss:0.2132108232752737\n",
      "train loss:0.31489693998863544\n",
      "train loss:0.3043950896559686\n",
      "train loss:0.22177817332228625\n",
      "train loss:0.19375614262969734\n",
      "train loss:0.22535252626841068\n",
      "train loss:0.3093709910152751\n",
      "train loss:0.2516193561060682\n",
      "train loss:0.17985153842442372\n",
      "train loss:0.2672651366424265\n",
      "train loss:0.24782653261435283\n",
      "train loss:0.17806013199994958\n",
      "train loss:0.37034136255584454\n",
      "train loss:0.19170730805263914\n",
      "train loss:0.23332609626600287\n",
      "train loss:0.36150251710038495\n",
      "train loss:0.23895350284239927\n",
      "train loss:0.2522607085540369\n",
      "train loss:0.20987127520683888\n",
      "train loss:0.21430507484612055\n",
      "train loss:0.2608118710652008\n",
      "train loss:0.2913515068243054\n",
      "train loss:0.32530545010092765\n",
      "train loss:0.2930805750801667\n",
      "train loss:0.19035521453035337\n",
      "train loss:0.23636625248008072\n",
      "train loss:0.22316797478905506\n",
      "train loss:0.21817116929327157\n",
      "train loss:0.3187651365816737\n",
      "train loss:0.3222235143838621\n",
      "train loss:0.2024219829697058\n",
      "train loss:0.26572553963612316\n",
      "train loss:0.17438995884384684\n",
      "train loss:0.22718124421957406\n",
      "train loss:0.28618068264725144\n",
      "train loss:0.18159704762256446\n",
      "train loss:0.3213733976369129\n",
      "train loss:0.1710405388265377\n",
      "train loss:0.23280987692256072\n",
      "train loss:0.2239115207872699\n",
      "train loss:0.36055801038141433\n",
      "train loss:0.19915028793053013\n",
      "train loss:0.2356707212682287\n",
      "train loss:0.16450005074829233\n",
      "train loss:0.21477572994354724\n",
      "train loss:0.25957739984316897\n",
      "train loss:0.1808545471370753\n",
      "train loss:0.16848946058174716\n",
      "train loss:0.250977294908737\n",
      "train loss:0.2867053466059616\n",
      "train loss:0.3210112583131238\n",
      "train loss:0.17129865650875659\n",
      "train loss:0.32441006068169304\n",
      "train loss:0.3263297293562768\n",
      "train loss:0.2832500175030625\n",
      "train loss:0.24639631466913858\n",
      "train loss:0.14916819378568047\n",
      "train loss:0.17867666347857208\n",
      "train loss:0.22924235761006392\n",
      "train loss:0.27890183487985526\n",
      "train loss:0.23306505585841258\n",
      "train loss:0.30849674525639825\n",
      "train loss:0.3272328850219675\n",
      "train loss:0.14930595525686527\n",
      "train loss:0.33375706055761706\n",
      "train loss:0.2652884642838388\n",
      "train loss:0.21245583853637331\n",
      "train loss:0.2096132339481849\n",
      "train loss:0.38839581511482346\n",
      "train loss:0.21416297612379462\n",
      "train loss:0.22276645928736916\n",
      "train loss:0.2654396654331846\n",
      "train loss:0.21328243050840479\n",
      "train loss:0.30027646759327115\n",
      "train loss:0.2702998746380082\n",
      "train loss:0.26849879250514147\n",
      "train loss:0.19289782075783202\n",
      "train loss:0.31269403980150234\n",
      "train loss:0.1995558193273121\n",
      "train loss:0.34271270920056585\n",
      "train loss:0.22598346030240685\n",
      "train loss:0.1506001583377078\n",
      "train loss:0.28261106219395044\n",
      "train loss:0.1919936560882345\n",
      "train loss:0.33358606602611923\n",
      "train loss:0.23424705180273256\n",
      "train loss:0.22792647606595054\n",
      "train loss:0.3975514536551335\n",
      "train loss:0.2043598215556274\n",
      "train loss:0.30687100232004033\n",
      "train loss:0.29771286490009374\n",
      "train loss:0.3519084262149128\n",
      "train loss:0.2747999192485669\n",
      "train loss:0.4191586238779375\n",
      "train loss:0.2396453990805246\n",
      "train loss:0.1439852789226911\n",
      "train loss:0.23941389605806748\n",
      "train loss:0.3114028384303982\n",
      "train loss:0.16865940970382837\n",
      "train loss:0.22340273465663604\n",
      "train loss:0.32291922607205115\n",
      "train loss:0.26346390253027\n",
      "train loss:0.3598667350672721\n",
      "train loss:0.19583855443159362\n",
      "train loss:0.164415668046919\n",
      "train loss:0.2637986946555571\n",
      "train loss:0.3507054013146408\n",
      "train loss:0.14430649559133837\n",
      "train loss:0.2242189603996644\n",
      "train loss:0.23416357629966697\n",
      "train loss:0.30427869431617816\n",
      "train loss:0.18919388111930094\n",
      "train loss:0.27435870283054126\n",
      "train loss:0.16954736483895766\n",
      "train loss:0.2317961027297782\n",
      "train loss:0.2309315835438907\n",
      "train loss:0.27144296057744005\n",
      "train loss:0.25798804463564723\n",
      "train loss:0.2074361516707134\n",
      "train loss:0.18408074670542324\n",
      "train loss:0.1971591758041636\n",
      "train loss:0.3387183439087314\n",
      "train loss:0.3130678801739371\n",
      "train loss:0.19164574473854562\n",
      "train loss:0.2544903361749897\n",
      "train loss:0.33457604814591435\n",
      "train loss:0.2296348217934322\n",
      "train loss:0.4005493351604925\n",
      "train loss:0.28233367540672666\n",
      "train loss:0.2217019165246324\n",
      "train loss:0.1771045915037078\n",
      "train loss:0.27055220019969334\n",
      "train loss:0.3609539265528924\n",
      "train loss:0.15760748380101328\n",
      "train loss:0.22908528039254597\n",
      "train loss:0.15628810165703644\n",
      "train loss:0.2991402248020831\n",
      "train loss:0.26324640819689277\n",
      "train loss:0.23959261769402088\n",
      "train loss:0.3279054888135129\n",
      "train loss:0.2874818453520597\n",
      "train loss:0.21156746938700677\n",
      "train loss:0.2716216913556298\n",
      "train loss:0.2194259476232424\n",
      "train loss:0.16439632059499837\n",
      "train loss:0.2553925152478589\n",
      "train loss:0.21052364338037383\n",
      "train loss:0.17286598614610635\n",
      "train loss:0.20952268797909265\n",
      "train loss:0.33577804528418087\n",
      "train loss:0.2217654921241282\n",
      "train loss:0.24350939555907658\n",
      "train loss:0.24955892548965525\n",
      "train loss:0.20386759814415\n",
      "train loss:0.30085668041674934\n",
      "train loss:0.26120938186009673\n",
      "train loss:0.20496856768387478\n",
      "train loss:0.23913029149059795\n",
      "train loss:0.3040192108266211\n",
      "train loss:0.20642108191155548\n",
      "train loss:0.30666880405813535\n",
      "train loss:0.2662014653304123\n",
      "train loss:0.3066289373384867\n",
      "train loss:0.18392304593143205\n",
      "train loss:0.34875648126389985\n",
      "train loss:0.22669027802596775\n",
      "train loss:0.20481312413853067\n",
      "train loss:0.23883682155879118\n",
      "train loss:0.28476726307937517\n",
      "train loss:0.2690869902134537\n",
      "train loss:0.21519258428264315\n",
      "train loss:0.2782537974772568\n",
      "train loss:0.3544611399283224\n",
      "train loss:0.3237690518378929\n",
      "train loss:0.19119085094111918\n",
      "train loss:0.26356792406982793\n",
      "train loss:0.25497731673595686\n",
      "train loss:0.2511786713398008\n",
      "train loss:0.1615017883851829\n",
      "train loss:0.23103318528723882\n",
      "train loss:0.2402458277593663\n",
      "train loss:0.3522080575171259\n",
      "train loss:0.33348961438375346\n",
      "train loss:0.3103814150230615\n",
      "train loss:0.32886122686478925\n",
      "train loss:0.3764802001576965\n",
      "train loss:0.14397672912363657\n",
      "train loss:0.1937367431013735\n",
      "train loss:0.19174570296300147\n",
      "train loss:0.24574185110816812\n",
      "train loss:0.19917700243181166\n",
      "train loss:0.2865593227380882\n",
      "train loss:0.21203942078382645\n",
      "train loss:0.14661484357063798\n",
      "train loss:0.29421646172887156\n",
      "train loss:0.3957545062903708\n",
      "train loss:0.19892848424714754\n",
      "train loss:0.2641931068518584\n",
      "train loss:0.18906338537835107\n",
      "train loss:0.20368105901453007\n",
      "train loss:0.27747184984018936\n",
      "train loss:0.22437358342661035\n",
      "train loss:0.22642655154720878\n",
      "train loss:0.3305960816706199\n",
      "train loss:0.43934633185794203\n",
      "train loss:0.21778020986761562\n",
      "train loss:0.2646065947440437\n",
      "train loss:0.3122715911326584\n",
      "train loss:0.15046408795975671\n",
      "train loss:0.17870822742923675\n",
      "train loss:0.32051064649729255\n",
      "train loss:0.2520081385084409\n",
      "train loss:0.21689601729494304\n",
      "train loss:0.2187172259545895\n",
      "train loss:0.33192065163574774\n",
      "train loss:0.25231775164004167\n",
      "train loss:0.34869362686974037\n",
      "train loss:0.2484011847155342\n",
      "train loss:0.23196728128696836\n",
      "train loss:0.2979420335167131\n",
      "train loss:0.225038274553032\n",
      "train loss:0.17189697943942442\n",
      "train loss:0.2204028378822962\n",
      "train loss:0.2740481786888692\n",
      "train loss:0.1813373273894443\n",
      "train loss:0.17520501827550017\n",
      "train loss:0.16426218841569856\n",
      "train loss:0.2989356165987834\n",
      "train loss:0.18904593491633753\n",
      "train loss:0.23566497715572088\n",
      "train loss:0.26801988250920344\n",
      "train loss:0.23397633829328185\n",
      "train loss:0.13895992317755942\n",
      "train loss:0.3115595948603475\n",
      "train loss:0.16968757202632442\n",
      "train loss:0.2676859194965986\n",
      "train loss:0.30025852229341504\n",
      "train loss:0.19405008555769918\n",
      "train loss:0.3330572675279231\n",
      "train loss:0.32435081560665596\n",
      "train loss:0.3553162023148555\n",
      "train loss:0.3199136736441213\n",
      "train loss:0.2027129683002373\n",
      "train loss:0.26757661091174695\n",
      "train loss:0.29149288353155545\n",
      "train loss:0.31629553705997965\n",
      "train loss:0.27515379188962796\n",
      "train loss:0.3379762241514668\n",
      "train loss:0.32214610247616277\n",
      "train loss:0.2401939328658773\n",
      "train loss:0.4751812563195572\n",
      "train loss:0.1952027230649629\n",
      "train loss:0.28295938578793584\n",
      "train loss:0.21044378811645306\n",
      "train loss:0.205827760954971\n",
      "train loss:0.2693764432645272\n",
      "train loss:0.1400643866377866\n",
      "train loss:0.18786392849221947\n",
      "train loss:0.2791957022263769\n",
      "train loss:0.359638133369713\n",
      "train loss:0.19807488390469533\n",
      "train loss:0.18057215174821237\n",
      "train loss:0.27580731666330993\n",
      "train loss:0.20720286211167546\n",
      "train loss:0.28592655645152737\n",
      "train loss:0.23647479466657897\n",
      "train loss:0.19978415378356773\n",
      "train loss:0.3028778365848462\n",
      "train loss:0.17652155612317796\n",
      "train loss:0.21594834483884323\n",
      "train loss:0.24196405721809824\n",
      "train loss:0.2892363136537422\n",
      "train loss:0.2325589845180987\n",
      "train loss:0.2453037167556453\n",
      "train loss:0.23437803071730834\n",
      "train loss:0.19026548115203115\n",
      "train loss:0.30793071863187715\n",
      "train loss:0.24378328344820197\n",
      "train loss:0.22495937551591288\n",
      "train loss:0.25118845654511224\n",
      "train loss:0.22784689289647095\n",
      "train loss:0.24668292453650853\n",
      "train loss:0.20615396347421824\n",
      "train loss:0.2727732521302622\n",
      "train loss:0.18109705892809053\n",
      "train loss:0.356737673753289\n",
      "train loss:0.31567525864772017\n",
      "train loss:0.23735352046590513\n",
      "train loss:0.2929181038270477\n",
      "train loss:0.315327433229796\n",
      "train loss:0.21059966613133174\n",
      "train loss:0.2148297834564527\n",
      "train loss:0.12773334289616062\n",
      "train loss:0.3801540362816139\n",
      "train loss:0.22713327089761912\n",
      "train loss:0.23417290093002718\n",
      "train loss:0.2860389381741153\n",
      "train loss:0.19854748231656533\n",
      "train loss:0.3615757903701193\n",
      "train loss:0.3337200825121518\n",
      "train loss:0.2301039451914307\n",
      "train loss:0.12687954116407452\n",
      "train loss:0.20779748058852912\n",
      "train loss:0.1748653196180433\n",
      "train loss:0.18146148445928842\n",
      "train loss:0.23709353117198126\n",
      "train loss:0.22497538908621104\n",
      "train loss:0.23120665586803352\n",
      "train loss:0.3854342406219105\n",
      "train loss:0.2781617595175367\n",
      "train loss:0.25212708626542585\n",
      "train loss:0.3252189121522725\n",
      "train loss:0.1977804117802633\n",
      "train loss:0.23617004181362766\n",
      "train loss:0.25056195153351096\n",
      "train loss:0.11947636705851722\n",
      "train loss:0.2339582373281463\n",
      "train loss:0.23406882829449607\n",
      "train loss:0.18885913784592273\n",
      "train loss:0.2913740702631377\n",
      "train loss:0.3826098887661133\n",
      "train loss:0.3146460477680186\n",
      "train loss:0.2749353653860227\n",
      "train loss:0.3208014915768894\n",
      "train loss:0.13584902609198948\n",
      "train loss:0.24215386915320916\n",
      "train loss:0.13612186224187747\n",
      "train loss:0.22760330964142625\n",
      "train loss:0.2809311549730172\n",
      "train loss:0.19978379334402369\n",
      "train loss:0.23959540908860127\n",
      "train loss:0.20119299693962145\n",
      "train loss:0.10536384983114262\n",
      "train loss:0.2949981858865037\n",
      "train loss:0.13387142903499485\n",
      "train loss:0.22979100959325172\n",
      "train loss:0.2394920670761805\n",
      "train loss:0.18315610312677927\n",
      "train loss:0.18175347924577487\n",
      "train loss:0.1995862575085254\n",
      "train loss:0.23591071250594658\n",
      "train loss:0.19261395147183996\n",
      "train loss:0.17213963544760016\n",
      "train loss:0.29544877659154034\n",
      "train loss:0.25080924289981726\n",
      "train loss:0.2747337105256173\n",
      "train loss:0.22524944045349074\n",
      "train loss:0.3659318927559083\n",
      "train loss:0.20763960162485545\n",
      "train loss:0.22059261469721114\n",
      "train loss:0.24550924427699933\n",
      "train loss:0.24330761203405518\n",
      "train loss:0.3850990169235363\n",
      "train loss:0.17687360792364984\n",
      "train loss:0.24047426966891539\n",
      "train loss:0.25238977217930464\n",
      "train loss:0.20085123068436822\n",
      "train loss:0.2722917362125402\n",
      "train loss:0.16444819576149683\n",
      "train loss:0.3291987555001623\n",
      "train loss:0.16157153893632525\n",
      "train loss:0.18666169385594675\n",
      "train loss:0.29103517625002573\n",
      "train loss:0.12843305425045262\n",
      "train loss:0.17298850797755197\n",
      "train loss:0.2666269712376931\n",
      "train loss:0.30601383816906014\n",
      "train loss:0.4195658892232971\n",
      "train loss:0.23603712793661727\n",
      "train loss:0.11591627401426542\n",
      "train loss:0.2794603161840135\n",
      "train loss:0.24719099586703364\n",
      "train loss:0.23976082532203688\n",
      "train loss:0.24434019314341565\n",
      "train loss:0.2051415460625389\n",
      "train loss:0.19048826542247788\n",
      "train loss:0.17032185984636897\n",
      "train loss:0.17101163070950207\n",
      "train loss:0.3777192509630649\n",
      "train loss:0.20117680833926574\n",
      "train loss:0.19564341774961863\n",
      "train loss:0.1578367354360411\n",
      "train loss:0.24951141689235942\n",
      "train loss:0.16175025299201454\n",
      "train loss:0.11915792568123522\n",
      "train loss:0.1882539768448438\n",
      "train loss:0.2847605281123193\n",
      "train loss:0.27951537003077337\n",
      "train loss:0.2529743587219791\n",
      "train loss:0.2302348713277092\n",
      "train loss:0.16229808085458797\n",
      "train loss:0.24138862174397638\n",
      "train loss:0.1883083478648148\n",
      "train loss:0.17092866991005767\n",
      "train loss:0.2406025089249769\n",
      "train loss:0.20342447569324185\n",
      "train loss:0.20572530728287752\n",
      "train loss:0.2101532811770426\n",
      "train loss:0.16270657280047632\n",
      "train loss:0.4462589556414773\n",
      "train loss:0.1847782413128702\n",
      "train loss:0.15658574654726948\n",
      "train loss:0.22552827443016432\n",
      "train loss:0.18381305207347853\n",
      "train loss:0.2517779193123361\n",
      "train loss:0.15651259907226528\n",
      "train loss:0.39822320959632856\n",
      "train loss:0.26258931880301767\n",
      "train loss:0.30562301403788494\n",
      "train loss:0.268525222910406\n",
      "train loss:0.153970460074607\n",
      "train loss:0.24366530293478308\n",
      "train loss:0.22829783110659052\n",
      "train loss:0.20581183357806535\n",
      "train loss:0.1623987665489541\n",
      "train loss:0.16715114164635125\n",
      "train loss:0.4066314682559436\n",
      "train loss:0.1399179874963686\n",
      "train loss:0.18646339909225493\n",
      "train loss:0.19720878916849713\n",
      "train loss:0.30690986262568154\n",
      "train loss:0.2650878547443568\n",
      "train loss:0.1628231007904705\n",
      "train loss:0.29003586569859313\n",
      "train loss:0.19728161782254847\n",
      "train loss:0.16965891236045674\n",
      "train loss:0.25561382059770427\n",
      "train loss:0.21117551496168788\n",
      "train loss:0.2206893225201647\n",
      "train loss:0.2484994464093646\n",
      "train loss:0.26469900821827\n",
      "train loss:0.3095303832503719\n",
      "train loss:0.21758992745565586\n",
      "train loss:0.16614484515998465\n",
      "train loss:0.2033301343666732\n",
      "train loss:0.22796017486731823\n",
      "train loss:0.20888357964258172\n",
      "train loss:0.18133328350953448\n",
      "train loss:0.2035042027795047\n",
      "train loss:0.2512580072799673\n",
      "train loss:0.28533782341459174\n",
      "train loss:0.21183388328014005\n",
      "train loss:0.25003308577345057\n",
      "train loss:0.29915238026495855\n",
      "train loss:0.20896424516806963\n",
      "train loss:0.21767713552754814\n",
      "train loss:0.30512593537052285\n",
      "train loss:0.3075448399235031\n",
      "train loss:0.18947276947165506\n",
      "train loss:0.18490091865033598\n",
      "train loss:0.3855809594131751\n",
      "train loss:0.2503853234583471\n",
      "train loss:0.2479500231924451\n",
      "train loss:0.24431626809108972\n",
      "train loss:0.3146600765304556\n",
      "train loss:0.29589189327099186\n",
      "train loss:0.2112071187651422\n",
      "train loss:0.22196960947883448\n",
      "train loss:0.20458052616664887\n",
      "train loss:0.3668573956356837\n",
      "train loss:0.17671076787882842\n",
      "train loss:0.34659159445590804\n",
      "train loss:0.23363470300265934\n",
      "train loss:0.2727861131793769\n",
      "train loss:0.2433847970121385\n",
      "train loss:0.24339072797293754\n",
      "train loss:0.26589801416581765\n",
      "train loss:0.2558286645688407\n",
      "train loss:0.3494268788153558\n",
      "train loss:0.2532614689730758\n",
      "train loss:0.2270485539105553\n",
      "train loss:0.2591087167096773\n",
      "train loss:0.2132790831003874\n",
      "train loss:0.2169078472853436\n",
      "train loss:0.16183589691498196\n",
      "train loss:0.2762722986975036\n",
      "train loss:0.276992265128387\n",
      "train loss:0.25529442587902157\n",
      "train loss:0.2819780966030113\n",
      "train loss:0.31166917679996464\n",
      "train loss:0.20545704613617802\n",
      "train loss:0.22306515519214365\n",
      "train loss:0.2904476802711507\n",
      "train loss:0.25502552104815\n",
      "train loss:0.2422505472635286\n",
      "train loss:0.23037074996263443\n",
      "train loss:0.18490391715594842\n",
      "=== epoch:5, train acc:0.926, test acc:0.903 ===\n",
      "train loss:0.2185565377555681\n",
      "train loss:0.23660460042867726\n",
      "train loss:0.2081043624608644\n",
      "train loss:0.26369871407352263\n",
      "train loss:0.1592474945259192\n",
      "train loss:0.34707937113599435\n",
      "train loss:0.24239679401572928\n",
      "train loss:0.18681188152530173\n",
      "train loss:0.2826717370975753\n",
      "train loss:0.18787840580865894\n",
      "train loss:0.24489359054085058\n",
      "train loss:0.20017112459806077\n",
      "train loss:0.20777656855839635\n",
      "train loss:0.22826938871645996\n",
      "train loss:0.33283982700317977\n",
      "train loss:0.2506522666502702\n",
      "train loss:0.18317054093414903\n",
      "train loss:0.28410087101612425\n",
      "train loss:0.30502254514787264\n",
      "train loss:0.29754813131399066\n",
      "train loss:0.21971986001290295\n",
      "train loss:0.2679142717913056\n",
      "train loss:0.15098986314384094\n",
      "train loss:0.16586778986841286\n",
      "train loss:0.10826584309538259\n",
      "train loss:0.3766372153664833\n",
      "train loss:0.16859274956110293\n",
      "train loss:0.16764225892430648\n",
      "train loss:0.24588026114803965\n",
      "train loss:0.3197356825409284\n",
      "train loss:0.21144033005467666\n",
      "train loss:0.37710770996648507\n",
      "train loss:0.25587981759982453\n",
      "train loss:0.23371780721806448\n",
      "train loss:0.22846006105495772\n",
      "train loss:0.25013930437583803\n",
      "train loss:0.2933853046365247\n",
      "train loss:0.26163255617390674\n",
      "train loss:0.21439281364312712\n",
      "train loss:0.17512278192131764\n",
      "train loss:0.26772886302143695\n",
      "train loss:0.2526487042180679\n",
      "train loss:0.22338980309316242\n",
      "train loss:0.25111478042864904\n",
      "train loss:0.2743364393380882\n",
      "train loss:0.3844964319406896\n",
      "train loss:0.2329102619298584\n",
      "train loss:0.19871062308849233\n",
      "train loss:0.28541743550275295\n",
      "train loss:0.2944230160382085\n",
      "train loss:0.25079691105808805\n",
      "train loss:0.244328941787296\n",
      "train loss:0.20515857975681626\n",
      "train loss:0.21638309038592302\n",
      "train loss:0.18533993654402955\n",
      "train loss:0.22786727155920564\n",
      "train loss:0.25363624941149676\n",
      "train loss:0.2585502760763734\n",
      "train loss:0.2838217017266439\n",
      "train loss:0.2513755489163494\n",
      "train loss:0.18508523877875466\n",
      "train loss:0.1925145090778499\n",
      "train loss:0.21092543721488177\n",
      "train loss:0.1664141693805228\n",
      "train loss:0.18754519338377953\n",
      "train loss:0.24606198380129668\n",
      "train loss:0.23264615512413378\n",
      "train loss:0.13966673980037148\n",
      "train loss:0.2949234916265867\n",
      "train loss:0.19265819508846807\n",
      "train loss:0.2779835235662638\n",
      "train loss:0.21255039499862394\n",
      "train loss:0.3070795130793353\n",
      "train loss:0.20230399415150302\n",
      "train loss:0.20991681659089464\n",
      "train loss:0.1531552693907804\n",
      "train loss:0.20981525861493755\n",
      "train loss:0.23423880964826943\n",
      "train loss:0.15701417021808814\n",
      "train loss:0.2829140497736964\n",
      "train loss:0.18200665603415841\n",
      "train loss:0.20453993808530108\n",
      "train loss:0.18520274232625977\n",
      "train loss:0.2244828859701186\n",
      "train loss:0.1652623872344327\n",
      "train loss:0.16852247506624918\n",
      "train loss:0.23410808297796767\n",
      "train loss:0.22258704007414107\n",
      "train loss:0.2445557425204942\n",
      "train loss:0.25662843633006793\n",
      "train loss:0.22975150104930664\n",
      "train loss:0.31685361573091547\n",
      "train loss:0.2038619778040913\n",
      "train loss:0.25850407046752905\n",
      "train loss:0.2384333849524209\n",
      "train loss:0.1520006505099266\n",
      "train loss:0.323823097164234\n",
      "train loss:0.18017081105543511\n",
      "train loss:0.13959401585877648\n",
      "train loss:0.26607065549593095\n",
      "train loss:0.1757977642618128\n",
      "train loss:0.19031972222480661\n",
      "train loss:0.13753719975572382\n",
      "train loss:0.17485355167179797\n",
      "train loss:0.21589651761718898\n",
      "train loss:0.17654395139149742\n",
      "train loss:0.2435045072569819\n",
      "train loss:0.16702645393488577\n",
      "train loss:0.1113980918674824\n",
      "train loss:0.1408847992266943\n",
      "train loss:0.1567865826493355\n",
      "train loss:0.23386160889975374\n",
      "train loss:0.1941168975943874\n",
      "train loss:0.189510000468916\n",
      "train loss:0.2480391008043408\n",
      "train loss:0.22727878973455565\n",
      "train loss:0.19853200433434526\n",
      "train loss:0.3228485907733869\n",
      "train loss:0.29169322079639837\n",
      "train loss:0.2680354875506995\n",
      "train loss:0.2634734338484188\n",
      "train loss:0.13956363204942654\n",
      "train loss:0.33316067307379915\n",
      "train loss:0.19565411486807524\n",
      "train loss:0.18527525403897357\n",
      "train loss:0.2821515527330936\n",
      "train loss:0.382555773035314\n",
      "train loss:0.2794022036930077\n",
      "train loss:0.2290173811536852\n",
      "train loss:0.3454391094175622\n",
      "train loss:0.20007720606102664\n",
      "train loss:0.24109643538884754\n",
      "train loss:0.29286809211799053\n",
      "train loss:0.1941689308555554\n",
      "train loss:0.27800908424629134\n",
      "train loss:0.22943788528543935\n",
      "train loss:0.19228424762779206\n",
      "train loss:0.1590610807759617\n",
      "train loss:0.2806602467305667\n",
      "train loss:0.15923365026377428\n",
      "train loss:0.2595030143192259\n",
      "train loss:0.22715390979040342\n",
      "train loss:0.19730120473330753\n",
      "train loss:0.2126434819487348\n",
      "train loss:0.31421215505807987\n",
      "train loss:0.21795671652037363\n",
      "train loss:0.33394845314158517\n",
      "train loss:0.2147743848623195\n",
      "train loss:0.25515508291674954\n",
      "train loss:0.3664367709347298\n",
      "train loss:0.27413403091119776\n",
      "train loss:0.2427071737213198\n",
      "train loss:0.31996829967874335\n",
      "train loss:0.20816230476372147\n",
      "train loss:0.30276523517296794\n",
      "train loss:0.26250691398462234\n",
      "train loss:0.2644464212537394\n",
      "train loss:0.21887163756909478\n",
      "train loss:0.24846532058693793\n",
      "train loss:0.25962070400211096\n",
      "train loss:0.26288520021765277\n",
      "train loss:0.23688533835977008\n",
      "train loss:0.20752228527498814\n",
      "train loss:0.22322708614865377\n",
      "train loss:0.20526384737444417\n",
      "train loss:0.21706340496302243\n",
      "train loss:0.18913103723204727\n",
      "train loss:0.09527718826796945\n",
      "train loss:0.28643107291251624\n",
      "train loss:0.24443034695578456\n",
      "train loss:0.19322894253399167\n",
      "train loss:0.2873687179235608\n",
      "train loss:0.22013355880145555\n",
      "train loss:0.15835629350562785\n",
      "train loss:0.1644376284186321\n",
      "train loss:0.2673167048111306\n",
      "train loss:0.38955754693160505\n",
      "train loss:0.18102084353672027\n",
      "train loss:0.29248462876485953\n",
      "train loss:0.3176863035183822\n",
      "train loss:0.25155349228007806\n",
      "train loss:0.27579547141871247\n",
      "train loss:0.2473516914474709\n",
      "train loss:0.14085354931462157\n",
      "train loss:0.2858088489506398\n",
      "train loss:0.29625157749534314\n",
      "train loss:0.31121442962774526\n",
      "train loss:0.30889434051778564\n",
      "train loss:0.12575902448967857\n",
      "train loss:0.16033642621399036\n",
      "train loss:0.2419442974810412\n",
      "train loss:0.25254267936334857\n",
      "train loss:0.169313162836471\n",
      "train loss:0.30429878663656323\n",
      "train loss:0.21343066832759436\n",
      "train loss:0.18356729347015485\n",
      "train loss:0.11804335858197536\n",
      "train loss:0.312649219084997\n",
      "train loss:0.21370102392912346\n",
      "train loss:0.3417273899506903\n",
      "train loss:0.26730480909423443\n",
      "train loss:0.39452822706548957\n",
      "train loss:0.2510317483024446\n",
      "train loss:0.24321544016033209\n",
      "train loss:0.2357835965997004\n",
      "train loss:0.23604893279634281\n",
      "train loss:0.1447724676981307\n",
      "train loss:0.23317454326750717\n",
      "train loss:0.16015579489911133\n",
      "train loss:0.27925684951424345\n",
      "train loss:0.19618706152559084\n",
      "train loss:0.22940813930015122\n",
      "train loss:0.23746452185393238\n",
      "train loss:0.27712698044313516\n",
      "train loss:0.2048973657547105\n",
      "train loss:0.12543200524262885\n",
      "train loss:0.2266203252110065\n",
      "train loss:0.20972159347466274\n",
      "train loss:0.24285323737580694\n",
      "train loss:0.23732848071399038\n",
      "train loss:0.14513888605091022\n",
      "train loss:0.20658196483521135\n",
      "train loss:0.2372418986773001\n",
      "train loss:0.2516860615092411\n",
      "train loss:0.2692167957527205\n",
      "train loss:0.28305066650800303\n",
      "train loss:0.19087079038367544\n",
      "train loss:0.1722690060388001\n",
      "train loss:0.23220385026948764\n",
      "train loss:0.24488823692675166\n",
      "train loss:0.19160274685418557\n",
      "train loss:0.22133874537608025\n",
      "train loss:0.26045300905338614\n",
      "train loss:0.21768533231707718\n",
      "train loss:0.3019541189033672\n",
      "train loss:0.26144924975454\n",
      "train loss:0.2480817171327575\n",
      "train loss:0.17363735874521677\n",
      "train loss:0.25101808633927053\n",
      "train loss:0.17095272662082187\n",
      "train loss:0.2121766524324885\n",
      "train loss:0.28000057042658144\n",
      "train loss:0.2738040579049037\n",
      "train loss:0.20169903191281308\n",
      "train loss:0.26234374281995504\n",
      "train loss:0.25865659490757104\n",
      "train loss:0.28023378299060525\n",
      "train loss:0.14216565566123399\n",
      "train loss:0.2509855632939863\n",
      "train loss:0.33128305696182403\n",
      "train loss:0.25405117473575783\n",
      "train loss:0.20054808865843238\n",
      "train loss:0.12581179544126994\n",
      "train loss:0.12156020726058399\n",
      "train loss:0.15719093887032254\n",
      "train loss:0.2813054879759785\n",
      "train loss:0.14424301504948697\n",
      "train loss:0.2111596124399287\n",
      "train loss:0.16955594665105914\n",
      "train loss:0.30550209793762695\n",
      "train loss:0.2117772583308606\n",
      "train loss:0.1900290413490311\n",
      "train loss:0.24220020444798107\n",
      "train loss:0.18790777826315797\n",
      "train loss:0.2900868872346094\n",
      "train loss:0.2783501876731932\n",
      "train loss:0.14744228225593134\n",
      "train loss:0.2601445100724187\n",
      "train loss:0.13477629890426612\n",
      "train loss:0.2436841805599878\n",
      "train loss:0.3115293782692332\n",
      "train loss:0.15275347331089262\n",
      "train loss:0.19139078958579328\n",
      "train loss:0.24732069706036022\n",
      "train loss:0.22443961883942584\n",
      "train loss:0.1576792450314022\n",
      "train loss:0.31065173777316557\n",
      "train loss:0.21535241541685388\n",
      "train loss:0.19280330230789372\n",
      "train loss:0.22746052850441043\n",
      "train loss:0.19234609938909952\n",
      "train loss:0.16117982804012268\n",
      "train loss:0.17535893798449453\n",
      "train loss:0.37172536492093533\n",
      "train loss:0.22762597336084198\n",
      "train loss:0.15347437920720391\n",
      "train loss:0.35020899395902283\n",
      "train loss:0.3465788120436845\n",
      "train loss:0.2608209541507967\n",
      "train loss:0.1364030098274045\n",
      "train loss:0.16417064998247136\n",
      "train loss:0.1683174156389622\n",
      "train loss:0.21124045295904495\n",
      "train loss:0.14388024626953486\n",
      "train loss:0.3278216635238575\n",
      "train loss:0.12878674377914653\n",
      "train loss:0.20400236340689148\n",
      "train loss:0.1500697093187801\n",
      "train loss:0.3302123856217436\n",
      "train loss:0.28430784121060637\n",
      "train loss:0.269701757110619\n",
      "train loss:0.24489283560981434\n",
      "train loss:0.2110796494288139\n",
      "train loss:0.19934408382989993\n",
      "train loss:0.29424981620040674\n",
      "train loss:0.18294530075709708\n",
      "train loss:0.15467709533754861\n",
      "train loss:0.19552559072829545\n",
      "train loss:0.3104586094227159\n",
      "train loss:0.22676643072982408\n",
      "train loss:0.12928637326218387\n",
      "train loss:0.18793393317696444\n",
      "train loss:0.201213547010199\n",
      "train loss:0.176478972643918\n",
      "train loss:0.3313271353595498\n",
      "train loss:0.26164682586196597\n",
      "train loss:0.28230195408544173\n",
      "train loss:0.28359271608029923\n",
      "train loss:0.26635539799620417\n",
      "train loss:0.15765205772960353\n",
      "train loss:0.17392193504417836\n",
      "train loss:0.1516970114059363\n",
      "train loss:0.2253588205662944\n",
      "train loss:0.19764075033573278\n",
      "train loss:0.21814880883866547\n",
      "train loss:0.23861918484791386\n",
      "train loss:0.16514883949167747\n",
      "train loss:0.1955142750508677\n",
      "train loss:0.1671752940208696\n",
      "train loss:0.23486527956168032\n",
      "train loss:0.2063970113570268\n",
      "train loss:0.18805957263940637\n",
      "train loss:0.1987481014605804\n",
      "train loss:0.18980992036049765\n",
      "train loss:0.1817677210697113\n",
      "train loss:0.25551395150919126\n",
      "train loss:0.18114642273783008\n",
      "train loss:0.18764022485606735\n",
      "train loss:0.1603379839226614\n",
      "train loss:0.367671068438339\n",
      "train loss:0.19179345877013942\n",
      "train loss:0.1533662219661869\n",
      "train loss:0.17657455198994654\n",
      "train loss:0.24609682600548413\n",
      "train loss:0.27309675540053596\n",
      "train loss:0.28152043668714793\n",
      "train loss:0.27356949173164763\n",
      "train loss:0.142061157679662\n",
      "train loss:0.18985913065020793\n",
      "train loss:0.39647108166783807\n",
      "train loss:0.24837235157219797\n",
      "train loss:0.1601064990076522\n",
      "train loss:0.17302282406315408\n",
      "train loss:0.15522185119926946\n",
      "train loss:0.3407042909106606\n",
      "train loss:0.20863761461264066\n",
      "train loss:0.19965728732914417\n",
      "train loss:0.22753096150486787\n",
      "train loss:0.1553730785730382\n",
      "train loss:0.17250969442142366\n",
      "train loss:0.22295130890591952\n",
      "train loss:0.19885155882810104\n",
      "train loss:0.19505050825249984\n",
      "train loss:0.21793578092582785\n",
      "train loss:0.19266369945712927\n",
      "train loss:0.15186747394406502\n",
      "train loss:0.23555247106439936\n",
      "train loss:0.3413595735158865\n",
      "train loss:0.20907978238677122\n",
      "train loss:0.16922564393676587\n",
      "train loss:0.28524965086875603\n",
      "train loss:0.20360104647409932\n",
      "train loss:0.2816007240269579\n",
      "train loss:0.2658917178681518\n",
      "train loss:0.3017023783010356\n",
      "train loss:0.2864870399555187\n",
      "train loss:0.1695854691518331\n",
      "train loss:0.21359902805142222\n",
      "train loss:0.20512144772720006\n",
      "train loss:0.30919206354000073\n",
      "train loss:0.35562282233917764\n",
      "train loss:0.1763263291536422\n",
      "train loss:0.15154987515123883\n",
      "train loss:0.196630158930175\n",
      "train loss:0.15390523769295963\n",
      "train loss:0.2697159992216258\n",
      "train loss:0.2133551000665114\n",
      "train loss:0.2207229545290958\n",
      "train loss:0.1950957861607421\n",
      "train loss:0.14351699258275696\n",
      "train loss:0.1282490098566954\n",
      "train loss:0.19198899614295162\n",
      "train loss:0.20225659370800986\n",
      "train loss:0.2597518828964338\n",
      "train loss:0.21067570435946295\n",
      "train loss:0.22569543107554693\n",
      "train loss:0.19763040427775547\n",
      "train loss:0.21275806248225915\n",
      "train loss:0.17602855130066117\n",
      "train loss:0.39794243178139566\n",
      "train loss:0.29297200008499397\n",
      "train loss:0.26985598853187104\n",
      "train loss:0.11427960373692946\n",
      "train loss:0.12638457878735274\n",
      "train loss:0.13705745900693744\n",
      "train loss:0.2953771177686901\n",
      "train loss:0.11572147110133553\n",
      "train loss:0.3214859910364726\n",
      "train loss:0.2203184476618283\n",
      "train loss:0.2827236150373265\n",
      "train loss:0.2283112404730381\n",
      "train loss:0.1490303765439742\n",
      "train loss:0.24412193220248787\n",
      "train loss:0.12702757682532476\n",
      "train loss:0.15523406649638624\n",
      "train loss:0.23849644293166897\n",
      "train loss:0.236934136655602\n",
      "train loss:0.09920874253016378\n",
      "train loss:0.23191086738587108\n",
      "train loss:0.20616278136222238\n",
      "train loss:0.15324871334380213\n",
      "train loss:0.20897473974173322\n",
      "train loss:0.3827085869806423\n",
      "train loss:0.12276286983163855\n",
      "train loss:0.2696115797520204\n",
      "train loss:0.12130939997523477\n",
      "train loss:0.29925757568065814\n",
      "train loss:0.15131575606794756\n",
      "train loss:0.20728504215615776\n",
      "train loss:0.1516109015695624\n",
      "train loss:0.12350155844072928\n",
      "train loss:0.20083721158246695\n",
      "train loss:0.22125457230596482\n",
      "train loss:0.1570207927976382\n",
      "train loss:0.21169775979129557\n",
      "train loss:0.18020811998910877\n",
      "train loss:0.2515679775777133\n",
      "train loss:0.22994971489556026\n",
      "train loss:0.20220918024440931\n",
      "train loss:0.19766349691885732\n",
      "train loss:0.11923999761196512\n",
      "train loss:0.32424628844971065\n",
      "train loss:0.3188325236566264\n",
      "train loss:0.2206719440611585\n",
      "train loss:0.1689661687199778\n",
      "train loss:0.27662530657086337\n",
      "train loss:0.27252793229942646\n",
      "train loss:0.15395287953797646\n",
      "train loss:0.19093052185309906\n",
      "train loss:0.15419865861539056\n",
      "train loss:0.192043326520287\n",
      "train loss:0.2189367215690908\n",
      "train loss:0.2610360166929\n",
      "train loss:0.18556108289650625\n",
      "train loss:0.21446572438598943\n",
      "train loss:0.2208938598666184\n",
      "train loss:0.19119515743079485\n",
      "train loss:0.23468174592425262\n",
      "train loss:0.13624523193465188\n",
      "train loss:0.17676612746594794\n",
      "train loss:0.2788286208426931\n",
      "train loss:0.20761688267242842\n",
      "train loss:0.23591667516213327\n",
      "train loss:0.2014382384787517\n",
      "train loss:0.12878213400380878\n",
      "train loss:0.3041790962710093\n",
      "train loss:0.17161047517026629\n",
      "train loss:0.35130367892989867\n",
      "train loss:0.19536028553030335\n",
      "train loss:0.2700558909034377\n",
      "train loss:0.1642188873691727\n",
      "train loss:0.23289097492553104\n",
      "train loss:0.2915624771310433\n",
      "train loss:0.20151390832743796\n",
      "train loss:0.20783473682853296\n",
      "train loss:0.3014918046843741\n",
      "train loss:0.19749741134703375\n",
      "train loss:0.3212839833571281\n",
      "train loss:0.1904536522163947\n",
      "train loss:0.24404065956162238\n",
      "train loss:0.2632835336841311\n",
      "train loss:0.13583793143582232\n",
      "train loss:0.14995643479849904\n",
      "train loss:0.2590325816587019\n",
      "train loss:0.17888212953262872\n",
      "train loss:0.18877469332115623\n",
      "train loss:0.18190056830516135\n",
      "train loss:0.09158384239815241\n",
      "train loss:0.26299189558025904\n",
      "train loss:0.21145885774899875\n",
      "train loss:0.21756531108329305\n",
      "train loss:0.271825488722919\n",
      "train loss:0.1821052746990835\n",
      "train loss:0.24672732601704486\n",
      "train loss:0.14441778671019762\n",
      "train loss:0.23961476050980768\n",
      "train loss:0.2263280723352204\n",
      "train loss:0.2942287035283579\n",
      "train loss:0.24356345112434166\n",
      "train loss:0.2067673775064393\n",
      "train loss:0.19317163064703538\n",
      "train loss:0.29817356733932016\n",
      "train loss:0.17261940015511065\n",
      "train loss:0.19782098790232197\n",
      "train loss:0.189604691546977\n",
      "train loss:0.15943502929097936\n",
      "train loss:0.17703351172892445\n",
      "train loss:0.12631475647813056\n",
      "train loss:0.239021128621473\n",
      "train loss:0.16253154784451265\n",
      "train loss:0.11765526271487425\n",
      "train loss:0.330402513311996\n",
      "train loss:0.17907733874730686\n",
      "train loss:0.18812581717627316\n",
      "train loss:0.2346145571315227\n",
      "train loss:0.1927488391887762\n",
      "train loss:0.2926066609487507\n",
      "train loss:0.1802622842748109\n",
      "train loss:0.14947079455516435\n",
      "train loss:0.20991229953531643\n",
      "train loss:0.2605578983811837\n",
      "train loss:0.2759223720928771\n",
      "train loss:0.23204450959358905\n",
      "train loss:0.20640160018404077\n",
      "train loss:0.16303755442762122\n",
      "train loss:0.29524509894636464\n",
      "train loss:0.2412800366277454\n",
      "train loss:0.18994657571950743\n",
      "train loss:0.116427921357595\n",
      "train loss:0.20897009175098819\n",
      "train loss:0.30990523333939135\n",
      "train loss:0.2620891274770973\n",
      "train loss:0.15110334048638557\n",
      "train loss:0.1543732047488157\n",
      "train loss:0.2054411272126168\n",
      "train loss:0.21904515166457464\n",
      "train loss:0.24143394624904116\n",
      "train loss:0.2081922713931382\n",
      "train loss:0.3578051818032712\n",
      "train loss:0.1703969866332761\n",
      "train loss:0.18048255920666367\n",
      "train loss:0.25837594969528804\n",
      "train loss:0.24834482037360078\n",
      "train loss:0.23031233463113968\n",
      "train loss:0.22250426991734415\n",
      "train loss:0.1761458158140332\n",
      "train loss:0.2757198731124587\n",
      "train loss:0.27914958610027707\n",
      "train loss:0.23879908893202298\n",
      "train loss:0.1962718028606951\n",
      "train loss:0.10779971462706582\n",
      "train loss:0.17662760885586282\n",
      "train loss:0.16845635400765174\n",
      "train loss:0.10987536527337598\n",
      "train loss:0.2685865967508031\n",
      "train loss:0.16714472780125536\n",
      "train loss:0.2759453103526508\n",
      "train loss:0.19857582825395645\n",
      "train loss:0.22726765321466144\n",
      "train loss:0.2643743019602948\n",
      "train loss:0.28647838805810183\n",
      "train loss:0.29501630229181247\n",
      "train loss:0.1540169881431571\n",
      "train loss:0.15562605896589995\n",
      "train loss:0.20692093971365594\n",
      "train loss:0.21381692424810494\n",
      "train loss:0.33341781149487454\n",
      "train loss:0.27190252363772943\n",
      "train loss:0.2081174684965339\n",
      "train loss:0.12010418914816513\n",
      "train loss:0.18854257176258193\n",
      "train loss:0.11416387419115752\n",
      "train loss:0.2114636285501926\n",
      "train loss:0.28548159811636126\n",
      "train loss:0.1671660314724785\n",
      "train loss:0.20865473728655867\n",
      "train loss:0.16375462058277268\n",
      "train loss:0.2742222590276918\n",
      "train loss:0.15074312231200054\n",
      "train loss:0.1928284623956132\n",
      "train loss:0.21427166399787367\n",
      "train loss:0.156320066458337\n",
      "train loss:0.15637060229093808\n",
      "train loss:0.2720988312160262\n",
      "train loss:0.20610161129684496\n",
      "train loss:0.19544771957153062\n",
      "train loss:0.1779246220513034\n",
      "train loss:0.1633559920988223\n",
      "train loss:0.18468944026895234\n",
      "train loss:0.20489935327176256\n",
      "train loss:0.18499212860535735\n",
      "train loss:0.2662572574491789\n",
      "train loss:0.24961868818774757\n",
      "train loss:0.1737707773261097\n",
      "train loss:0.19177112274623842\n",
      "train loss:0.18624314534762074\n",
      "train loss:0.175258213965655\n",
      "train loss:0.17200975978317268\n",
      "train loss:0.33323392310963734\n",
      "train loss:0.3139227311213294\n",
      "=== epoch:6, train acc:0.934, test acc:0.907 ===\n",
      "train loss:0.24286121435946492\n",
      "train loss:0.3641553475575997\n",
      "train loss:0.14417134609369395\n",
      "train loss:0.1940364912277653\n",
      "train loss:0.1649308858681914\n",
      "train loss:0.18124237851265726\n",
      "train loss:0.21762181493904034\n",
      "train loss:0.18873549019280503\n",
      "train loss:0.23727661980655881\n",
      "train loss:0.22041362629736608\n",
      "train loss:0.2503553213772239\n",
      "train loss:0.17466377244734968\n",
      "train loss:0.25644594237240725\n",
      "train loss:0.2938598108722768\n",
      "train loss:0.10523593990904948\n",
      "train loss:0.38194495742507095\n",
      "train loss:0.1793551027491224\n",
      "train loss:0.1248701236533637\n",
      "train loss:0.27748833209271084\n",
      "train loss:0.2732603188118091\n",
      "train loss:0.22093329866265254\n",
      "train loss:0.15352083080985987\n",
      "train loss:0.3218551736043879\n",
      "train loss:0.2314751271601535\n",
      "train loss:0.2926707441306783\n",
      "train loss:0.1872432885738176\n",
      "train loss:0.21704123025863964\n",
      "train loss:0.18229953837810384\n",
      "train loss:0.15206079997126445\n",
      "train loss:0.20040744038700262\n",
      "train loss:0.344702080100818\n",
      "train loss:0.33168345322577847\n",
      "train loss:0.16512143644146696\n",
      "train loss:0.17785879538570878\n",
      "train loss:0.25162878148332984\n",
      "train loss:0.1254506116810261\n",
      "train loss:0.11575957776605629\n",
      "train loss:0.26824999405370387\n",
      "train loss:0.17014315401426422\n",
      "train loss:0.2668672685517986\n",
      "train loss:0.1937184784267017\n",
      "train loss:0.2718020456959783\n",
      "train loss:0.1824206156209174\n",
      "train loss:0.221960264799168\n",
      "train loss:0.21807657751521273\n",
      "train loss:0.2088692492470711\n",
      "train loss:0.23127265463174726\n",
      "train loss:0.31041497711625643\n",
      "train loss:0.14244580523261205\n",
      "train loss:0.2549549143960869\n",
      "train loss:0.2274317069580859\n",
      "train loss:0.19098516810444113\n",
      "train loss:0.266644042333752\n",
      "train loss:0.17918911209172578\n",
      "train loss:0.2508857482026222\n",
      "train loss:0.3568447841159949\n",
      "train loss:0.1166530570401601\n",
      "train loss:0.11663886572227324\n",
      "train loss:0.15761994439074273\n",
      "train loss:0.28991992989229787\n",
      "train loss:0.2581899882943023\n",
      "train loss:0.24572099167736206\n",
      "train loss:0.17374756737075706\n",
      "train loss:0.14808535564998881\n",
      "train loss:0.2593200973547073\n",
      "train loss:0.18365655435011277\n",
      "train loss:0.17680865014918024\n",
      "train loss:0.20348298900191333\n",
      "train loss:0.13891126534405276\n",
      "train loss:0.2672211730667716\n",
      "train loss:0.29760771290886556\n",
      "train loss:0.22746271208972912\n",
      "train loss:0.26890841631994866\n",
      "train loss:0.11794449080743621\n",
      "train loss:0.1735211207686081\n",
      "train loss:0.2763856256814103\n",
      "train loss:0.2354616473632181\n",
      "train loss:0.22268075022187628\n",
      "train loss:0.3166437868101003\n",
      "train loss:0.185295523819156\n",
      "train loss:0.17268332455691876\n",
      "train loss:0.21147167058628447\n",
      "train loss:0.2217005904941308\n",
      "train loss:0.14633784089220805\n",
      "train loss:0.23819676619553953\n",
      "train loss:0.2516642506917136\n",
      "train loss:0.270662882765498\n",
      "train loss:0.18850258383755975\n",
      "train loss:0.29084205729417884\n",
      "train loss:0.23711250400365508\n",
      "train loss:0.22092885332791223\n",
      "train loss:0.39901880430756537\n",
      "train loss:0.12797579722974406\n",
      "train loss:0.16567061289917576\n",
      "train loss:0.19054047155214518\n",
      "train loss:0.16124634744798175\n",
      "train loss:0.1408023425237518\n",
      "train loss:0.23310057080506985\n",
      "train loss:0.1959879297888899\n",
      "train loss:0.2260439061749875\n",
      "train loss:0.21210609593710036\n",
      "train loss:0.13283824996026558\n",
      "train loss:0.23286350696918526\n",
      "train loss:0.22225976833608665\n",
      "train loss:0.19365327389707146\n",
      "train loss:0.1331812545984684\n",
      "train loss:0.24916605764106567\n",
      "train loss:0.1290794711863128\n",
      "train loss:0.19442352676722993\n",
      "train loss:0.38685526841327006\n",
      "train loss:0.21237528581583606\n",
      "train loss:0.23107543762716642\n",
      "train loss:0.2450517222316756\n",
      "train loss:0.27779410186754294\n",
      "train loss:0.1993610408455941\n",
      "train loss:0.20692658634342398\n",
      "train loss:0.24539101243847677\n",
      "train loss:0.17048994530008382\n",
      "train loss:0.1903228865283201\n",
      "train loss:0.2362137054895135\n",
      "train loss:0.12195280984395335\n",
      "train loss:0.2986032134436493\n",
      "train loss:0.24498715334270116\n",
      "train loss:0.1574087195013995\n",
      "train loss:0.187803937858926\n",
      "train loss:0.24697474482261966\n",
      "train loss:0.13649747801538173\n",
      "train loss:0.20139859573849933\n",
      "train loss:0.21830795593593144\n",
      "train loss:0.19332823266230165\n",
      "train loss:0.21088225432277732\n",
      "train loss:0.15631510702932483\n",
      "train loss:0.20184211029981267\n",
      "train loss:0.09771436262230723\n",
      "train loss:0.17778816162404656\n",
      "train loss:0.1560376092449154\n",
      "train loss:0.14509043478986208\n",
      "train loss:0.2243535178426198\n",
      "train loss:0.25907762549992497\n",
      "train loss:0.2502118718403365\n",
      "train loss:0.2804012489950777\n",
      "train loss:0.38037761710673423\n",
      "train loss:0.2021295429747463\n",
      "train loss:0.16725606872612558\n",
      "train loss:0.12752493003627308\n",
      "train loss:0.16708627526582753\n",
      "train loss:0.2559744027648212\n",
      "train loss:0.1966543039703008\n",
      "train loss:0.23477344866253552\n",
      "train loss:0.2082548276721192\n",
      "train loss:0.14044966119117236\n",
      "train loss:0.13566696947077386\n",
      "train loss:0.2905551987704154\n",
      "train loss:0.2248141810772691\n",
      "train loss:0.11742742956597266\n",
      "train loss:0.11045788845270249\n",
      "train loss:0.12854054890489355\n",
      "train loss:0.1447019250616247\n",
      "train loss:0.1769557969993896\n",
      "train loss:0.13035477047251343\n",
      "train loss:0.20382013695013146\n",
      "train loss:0.22518997446455594\n",
      "train loss:0.19902616280440572\n",
      "train loss:0.12006303023300396\n",
      "train loss:0.20970312124691654\n",
      "train loss:0.20951474735669284\n",
      "train loss:0.13119694473692517\n",
      "train loss:0.21266921157460428\n",
      "train loss:0.20372086053341346\n",
      "train loss:0.32962441840741846\n",
      "train loss:0.07993037783769291\n",
      "train loss:0.19651804791073377\n",
      "train loss:0.2550320490512772\n",
      "train loss:0.14496219603955893\n",
      "train loss:0.21850154079747344\n",
      "train loss:0.2186372083722304\n",
      "train loss:0.11559260212742851\n",
      "train loss:0.2262652870696754\n",
      "train loss:0.24681699246342198\n",
      "train loss:0.1451889299871693\n",
      "train loss:0.14822249799188342\n",
      "train loss:0.09019460512062144\n",
      "train loss:0.13422322653361635\n",
      "train loss:0.3466539445431053\n",
      "train loss:0.25464808756833335\n",
      "train loss:0.16072645419397705\n",
      "train loss:0.24533291336233504\n",
      "train loss:0.14510039740849223\n",
      "train loss:0.20776429695822304\n",
      "train loss:0.16158091171740538\n",
      "train loss:0.32175971197629644\n",
      "train loss:0.12866156761360587\n",
      "train loss:0.17879730492131224\n",
      "train loss:0.383091166438287\n",
      "train loss:0.19057649567403284\n",
      "train loss:0.17056574777440492\n",
      "train loss:0.18968223594889216\n",
      "train loss:0.2974544656260753\n",
      "train loss:0.21597681347286574\n",
      "train loss:0.2878175599419016\n",
      "train loss:0.26839992650737254\n",
      "train loss:0.17150408043269982\n",
      "train loss:0.18825567167165438\n",
      "train loss:0.16123961876020487\n",
      "train loss:0.2246364659405912\n",
      "train loss:0.25979409645066937\n",
      "train loss:0.15330299341017756\n",
      "train loss:0.17263309906339863\n",
      "train loss:0.3283609338899932\n",
      "train loss:0.16347975366422304\n",
      "train loss:0.13775394263017274\n",
      "train loss:0.17518560945420994\n",
      "train loss:0.1531713136279166\n",
      "train loss:0.12560344778469865\n",
      "train loss:0.19189352257448117\n",
      "train loss:0.20071243395714802\n",
      "train loss:0.30250124728413863\n",
      "train loss:0.2546357427053801\n",
      "train loss:0.21531265738636082\n",
      "train loss:0.23634837848149143\n",
      "train loss:0.10675758639367443\n",
      "train loss:0.24465987440785905\n",
      "train loss:0.2708044331796111\n",
      "train loss:0.25200712285641935\n",
      "train loss:0.1674415217430738\n",
      "train loss:0.17705347561001722\n",
      "train loss:0.23405013224105395\n",
      "train loss:0.20592125572017772\n",
      "train loss:0.22698088976071898\n",
      "train loss:0.18801921664757684\n",
      "train loss:0.30437619072437777\n",
      "train loss:0.2333700471173833\n",
      "train loss:0.14275661977547438\n",
      "train loss:0.19195104182581435\n",
      "train loss:0.18087381578019238\n",
      "train loss:0.27709918074344875\n",
      "train loss:0.29786217665637055\n",
      "train loss:0.16903753227891194\n",
      "train loss:0.2711009446349656\n",
      "train loss:0.2266185258138291\n",
      "train loss:0.18694744350115186\n",
      "train loss:0.34592638190200076\n",
      "train loss:0.16964505868357713\n",
      "train loss:0.20834662320425978\n",
      "train loss:0.2216858966340007\n",
      "train loss:0.20675905799745123\n",
      "train loss:0.1998484117517716\n",
      "train loss:0.16733826276923666\n",
      "train loss:0.12005941323705921\n",
      "train loss:0.14436394613772197\n",
      "train loss:0.24545179059536065\n",
      "train loss:0.36734909658009485\n",
      "train loss:0.15623680143690546\n",
      "train loss:0.1590752813837836\n",
      "train loss:0.2918681553672602\n",
      "train loss:0.15861505225528943\n",
      "train loss:0.19747962653667656\n",
      "train loss:0.14972479719136042\n",
      "train loss:0.2071994605295717\n",
      "train loss:0.16485013868359796\n",
      "train loss:0.32332236356632776\n",
      "train loss:0.1629879306118277\n",
      "train loss:0.16190301121726067\n",
      "train loss:0.2906311225416969\n",
      "train loss:0.20197912701074663\n",
      "train loss:0.20944624684071567\n",
      "train loss:0.17023309079055665\n",
      "train loss:0.2830541946642037\n",
      "train loss:0.20973422598379685\n",
      "train loss:0.40380601376563807\n",
      "train loss:0.20695856413315258\n",
      "train loss:0.16741395343227478\n",
      "train loss:0.1453684502480673\n",
      "train loss:0.1574457904339903\n",
      "train loss:0.21554586527870853\n",
      "train loss:0.22408653274487317\n",
      "train loss:0.24040917139218057\n",
      "train loss:0.21641264584305367\n",
      "train loss:0.08588129892863386\n",
      "train loss:0.252648891954508\n",
      "train loss:0.17235748242186058\n",
      "train loss:0.1770303245027859\n",
      "train loss:0.21720207460615065\n",
      "train loss:0.15733381978850897\n",
      "train loss:0.27106635945872065\n",
      "train loss:0.21606662604504123\n",
      "train loss:0.13943468646369908\n",
      "train loss:0.16734014578356013\n",
      "train loss:0.18567765322437416\n",
      "train loss:0.24201585983424262\n",
      "train loss:0.16913449197692054\n",
      "train loss:0.1799836500258936\n",
      "train loss:0.1630634320386426\n",
      "train loss:0.1659088419570358\n",
      "train loss:0.15686929343619396\n",
      "train loss:0.1699885417241515\n",
      "train loss:0.20926078628599445\n",
      "train loss:0.1848939802033577\n",
      "train loss:0.15747823656198937\n",
      "train loss:0.12496561471655218\n",
      "train loss:0.148779823149303\n",
      "train loss:0.19056691646446233\n",
      "train loss:0.17077283471781743\n",
      "train loss:0.13885939771262545\n",
      "train loss:0.11352583062441347\n",
      "train loss:0.24667586704622513\n",
      "train loss:0.13205406400117023\n",
      "train loss:0.13919641064477906\n",
      "train loss:0.1456902170521312\n",
      "train loss:0.20619747737495206\n",
      "train loss:0.21127789084212542\n",
      "train loss:0.17493071431035825\n",
      "train loss:0.1522161236490838\n",
      "train loss:0.10365579103630665\n",
      "train loss:0.1473223210521174\n",
      "train loss:0.1343912122469462\n",
      "train loss:0.16751671412803606\n",
      "train loss:0.24868437437295665\n",
      "train loss:0.1860275272283103\n",
      "train loss:0.20286072328100935\n",
      "train loss:0.1864901327432672\n",
      "train loss:0.241435789642321\n",
      "train loss:0.09653281674665473\n",
      "train loss:0.16466488667830628\n",
      "train loss:0.2039785556079588\n",
      "train loss:0.21220492697710522\n",
      "train loss:0.12889230680010388\n",
      "train loss:0.28125981613276274\n",
      "train loss:0.24170777791991027\n",
      "train loss:0.18836080895662563\n",
      "train loss:0.22963156267218\n",
      "train loss:0.18913903349455669\n",
      "train loss:0.18775085787685955\n",
      "train loss:0.20776067323757202\n",
      "train loss:0.1762390973559465\n",
      "train loss:0.1386559480933814\n",
      "train loss:0.13209384214923983\n",
      "train loss:0.1308578736641333\n",
      "train loss:0.17264842212513293\n",
      "train loss:0.2744707066699316\n",
      "train loss:0.19542386325601907\n",
      "train loss:0.13325682493744376\n",
      "train loss:0.12441273192999831\n",
      "train loss:0.13901887780951816\n",
      "train loss:0.21449976888858682\n",
      "train loss:0.19085644083635853\n",
      "train loss:0.3382696496717269\n",
      "train loss:0.15322670270802366\n",
      "train loss:0.1308537781743936\n",
      "train loss:0.13843497491156243\n",
      "train loss:0.10931342362425188\n",
      "train loss:0.1777215810664803\n",
      "train loss:0.2649004932808431\n",
      "train loss:0.24525177107410875\n",
      "train loss:0.2089802532045448\n",
      "train loss:0.18656114587770525\n",
      "train loss:0.1355726704271468\n",
      "train loss:0.20264373098137284\n",
      "train loss:0.13169189467090084\n",
      "train loss:0.1610467762620245\n",
      "train loss:0.1449253719386374\n",
      "train loss:0.19200114722709288\n",
      "train loss:0.159883324549266\n",
      "train loss:0.255915550299197\n",
      "train loss:0.20283241228109916\n",
      "train loss:0.22912565874019028\n",
      "train loss:0.2153562179698782\n",
      "train loss:0.19406372400435515\n",
      "train loss:0.19251692120589112\n",
      "train loss:0.25454811688854034\n",
      "train loss:0.23823827290386784\n",
      "train loss:0.16331330502840719\n",
      "train loss:0.2276490264085791\n",
      "train loss:0.15031848500106032\n",
      "train loss:0.22452901145134083\n",
      "train loss:0.28611027575872966\n",
      "train loss:0.17684609423870473\n",
      "train loss:0.19984473117077964\n",
      "train loss:0.3043208123753512\n",
      "train loss:0.22836093707758004\n",
      "train loss:0.14284984288921046\n",
      "train loss:0.3209632199783885\n",
      "train loss:0.2888237126923704\n",
      "train loss:0.26409830952172686\n",
      "train loss:0.31102554560307727\n",
      "train loss:0.16950942325965643\n",
      "train loss:0.18109288123394005\n",
      "train loss:0.13787024026548939\n",
      "train loss:0.15849067305836867\n",
      "train loss:0.22170285122860162\n",
      "train loss:0.23895316293039934\n",
      "train loss:0.15607394093985122\n",
      "train loss:0.15960779463023836\n",
      "train loss:0.2800574277987199\n",
      "train loss:0.3072249806264629\n",
      "train loss:0.16109162670115784\n",
      "train loss:0.10896477968363698\n",
      "train loss:0.18328012559793705\n",
      "train loss:0.23570118750126312\n",
      "train loss:0.17764450751524077\n",
      "train loss:0.12550365483061834\n",
      "train loss:0.2857426320539384\n",
      "train loss:0.17383627739406168\n",
      "train loss:0.13557819984208017\n",
      "train loss:0.19392719646644938\n",
      "train loss:0.17753104388010613\n",
      "train loss:0.25085952288430735\n",
      "train loss:0.20116835265328403\n",
      "train loss:0.1121869971620105\n",
      "train loss:0.1560740823465267\n",
      "train loss:0.21511856888989644\n",
      "train loss:0.17674962600756156\n",
      "train loss:0.21225751179594282\n",
      "train loss:0.18961226560333405\n",
      "train loss:0.2273299619920154\n",
      "train loss:0.24208682082198207\n",
      "train loss:0.1484123556059104\n",
      "train loss:0.20154944482436776\n",
      "train loss:0.2342089371556435\n",
      "train loss:0.14028392149507815\n",
      "train loss:0.20657021950023968\n",
      "train loss:0.20072681057352168\n",
      "train loss:0.18955239353228653\n",
      "train loss:0.1447216380017716\n",
      "train loss:0.18380175809926325\n",
      "train loss:0.14836016494053203\n",
      "train loss:0.22903412843911866\n",
      "train loss:0.1593371958862408\n",
      "train loss:0.13668154761329376\n",
      "train loss:0.2736119153774593\n",
      "train loss:0.17384679167643916\n",
      "train loss:0.1592575722481933\n",
      "train loss:0.22255778305262108\n",
      "train loss:0.14477883452610732\n",
      "train loss:0.19042708433955852\n",
      "train loss:0.12238290967775901\n",
      "train loss:0.20356114534077002\n",
      "train loss:0.2545528973779429\n",
      "train loss:0.2034166193114095\n",
      "train loss:0.18904881479499028\n",
      "train loss:0.20370334762829842\n",
      "train loss:0.24808159594122386\n",
      "train loss:0.22121545456833114\n",
      "train loss:0.17177413266805402\n",
      "train loss:0.17824228938555947\n",
      "train loss:0.20496154713246828\n",
      "train loss:0.1407492879155957\n",
      "train loss:0.214243747054319\n",
      "train loss:0.13144341977502869\n",
      "train loss:0.2084450152849588\n",
      "train loss:0.17870575575925496\n",
      "train loss:0.29898539518312894\n",
      "train loss:0.25802029442695196\n",
      "train loss:0.18372557218675292\n",
      "train loss:0.26140255840821935\n",
      "train loss:0.1941274289444273\n",
      "train loss:0.18113871722905484\n",
      "train loss:0.17259543498085017\n",
      "train loss:0.18951729293780364\n",
      "train loss:0.18680694033659984\n",
      "train loss:0.17924993362214514\n",
      "train loss:0.2158659681024308\n",
      "train loss:0.24563221934860693\n",
      "train loss:0.2742679462169753\n",
      "train loss:0.16578753564218052\n",
      "train loss:0.23906405824559065\n",
      "train loss:0.26146478188758593\n",
      "train loss:0.25066980630993885\n",
      "train loss:0.1432287065911662\n",
      "train loss:0.15221275472563583\n",
      "train loss:0.23848796142736436\n",
      "train loss:0.1459791476358264\n",
      "train loss:0.1889742242147782\n",
      "train loss:0.31347488220304554\n",
      "train loss:0.2880783873999702\n",
      "train loss:0.21705260947385865\n",
      "train loss:0.27852267907515404\n",
      "train loss:0.2473910621780825\n",
      "train loss:0.18884186219629717\n",
      "train loss:0.17588789941623148\n",
      "train loss:0.16548503366779316\n",
      "train loss:0.19439875875994594\n",
      "train loss:0.26894773159830043\n",
      "train loss:0.14341496323763553\n",
      "train loss:0.13018032021112952\n",
      "train loss:0.29513775009709614\n",
      "train loss:0.31977776383520007\n",
      "train loss:0.11392309346608703\n",
      "train loss:0.21715349567476397\n",
      "train loss:0.17307903434389268\n",
      "train loss:0.18321748724408635\n",
      "train loss:0.15976105818730388\n",
      "train loss:0.20099587337906352\n",
      "train loss:0.2804583070919408\n",
      "train loss:0.16950225865760074\n",
      "train loss:0.3945121016231243\n",
      "train loss:0.10619401146530989\n",
      "train loss:0.28374219600701817\n",
      "train loss:0.17210453774263296\n",
      "train loss:0.26886227514094324\n",
      "train loss:0.19847169932176253\n",
      "train loss:0.1709107658351236\n",
      "train loss:0.18222098077605461\n",
      "train loss:0.28910236048513926\n",
      "train loss:0.10567588893901897\n",
      "train loss:0.18503767406132757\n",
      "train loss:0.19556542696681042\n",
      "train loss:0.11462113404325674\n",
      "train loss:0.14744993913112459\n",
      "train loss:0.22193092339670148\n",
      "train loss:0.20860214896007073\n",
      "train loss:0.1946166959288711\n",
      "train loss:0.12722212874671782\n",
      "train loss:0.16367398466079827\n",
      "train loss:0.263827174813162\n",
      "train loss:0.16812968516423396\n",
      "train loss:0.23315786286003948\n",
      "train loss:0.1299741422867364\n",
      "train loss:0.24099991356766226\n",
      "train loss:0.14902383066245392\n",
      "train loss:0.27152846835877764\n",
      "train loss:0.28519659277885867\n",
      "train loss:0.1806382857050684\n",
      "train loss:0.11920507604427433\n",
      "train loss:0.32320699123026814\n",
      "train loss:0.21477157838605657\n",
      "train loss:0.187982405055039\n",
      "train loss:0.17546135994686377\n",
      "train loss:0.23594943120482303\n",
      "train loss:0.18683120148228036\n",
      "train loss:0.19815717681535058\n",
      "train loss:0.22558068083355098\n",
      "train loss:0.13418382716333402\n",
      "train loss:0.2144451088088563\n",
      "train loss:0.1942234638653359\n",
      "train loss:0.23878517039955074\n",
      "train loss:0.1475840905475195\n",
      "train loss:0.16788825200927712\n",
      "train loss:0.254613031756479\n",
      "train loss:0.10244888452507958\n",
      "train loss:0.2256792163206867\n",
      "train loss:0.23741867180001514\n",
      "train loss:0.19490907593471823\n",
      "train loss:0.15380597794057704\n",
      "train loss:0.15749683355078137\n",
      "train loss:0.13386760972367595\n",
      "train loss:0.17160388313381644\n",
      "train loss:0.15316601797860463\n",
      "train loss:0.1372434633415603\n",
      "train loss:0.11887203666770832\n",
      "train loss:0.13758855167903694\n",
      "train loss:0.17983857885340482\n",
      "train loss:0.07956333279977908\n",
      "train loss:0.2327134630133337\n",
      "train loss:0.2669505417247053\n",
      "train loss:0.2286741785708525\n",
      "train loss:0.19335940020160758\n",
      "train loss:0.13704058264336522\n",
      "train loss:0.17490142119408522\n",
      "train loss:0.13593897187658924\n",
      "train loss:0.15521467586655296\n",
      "train loss:0.1489781061809342\n",
      "train loss:0.12632516769065533\n",
      "train loss:0.12952543227424315\n",
      "train loss:0.1254352084798999\n",
      "train loss:0.21910802882472782\n",
      "train loss:0.17348052268396233\n",
      "train loss:0.18971153394277407\n",
      "train loss:0.09838380537978168\n",
      "train loss:0.1126160766600418\n",
      "train loss:0.20743767653400375\n",
      "train loss:0.19211492402905017\n",
      "train loss:0.2136948440859182\n",
      "train loss:0.27144255917692606\n",
      "train loss:0.22435332224752463\n",
      "train loss:0.186842932002703\n",
      "train loss:0.19653472178999631\n",
      "train loss:0.1588516217073619\n",
      "train loss:0.09021124691294494\n",
      "train loss:0.21037782766189142\n",
      "train loss:0.20837561743785404\n",
      "train loss:0.2321777539999593\n",
      "train loss:0.17635771975324302\n",
      "train loss:0.20640280533062608\n",
      "train loss:0.1895499254739895\n",
      "train loss:0.1483179629788133\n",
      "train loss:0.22088312640124205\n",
      "train loss:0.155135335471786\n",
      "train loss:0.2568031798639334\n",
      "train loss:0.15756374833757142\n",
      "train loss:0.24160523499049089\n",
      "train loss:0.21498249530320876\n",
      "train loss:0.29385283276356644\n",
      "train loss:0.20178071023876804\n",
      "train loss:0.14201913441306604\n",
      "train loss:0.28679951314777025\n",
      "train loss:0.15265480850486468\n",
      "train loss:0.17877992564413384\n",
      "train loss:0.23006802481059044\n",
      "train loss:0.2415247618576044\n",
      "=== epoch:7, train acc:0.932, test acc:0.905 ===\n",
      "train loss:0.11940081609319389\n",
      "train loss:0.16595186174391638\n",
      "train loss:0.21798923277296742\n",
      "train loss:0.16836806645185676\n",
      "train loss:0.18735063239741492\n",
      "train loss:0.16476348970610805\n",
      "train loss:0.21085092442178632\n",
      "train loss:0.2362163327538787\n",
      "train loss:0.18761453546311047\n",
      "train loss:0.2695117717030517\n",
      "train loss:0.2083775711143538\n",
      "train loss:0.2028498913727092\n",
      "train loss:0.19468022630042564\n",
      "train loss:0.08367310968233709\n",
      "train loss:0.11196668191569648\n",
      "train loss:0.22284022646396826\n",
      "train loss:0.23121199283258367\n",
      "train loss:0.17418298988395048\n",
      "train loss:0.2104936532741866\n",
      "train loss:0.1675454233768839\n",
      "train loss:0.15268764544128788\n",
      "train loss:0.2256854037007083\n",
      "train loss:0.10548648846122241\n",
      "train loss:0.3558351323696129\n",
      "train loss:0.32537676415106476\n",
      "train loss:0.09008178201949305\n",
      "train loss:0.1328558260618028\n",
      "train loss:0.2741110708509424\n",
      "train loss:0.17165290307674927\n",
      "train loss:0.27663146670396793\n",
      "train loss:0.1619052732092515\n",
      "train loss:0.25713169461149216\n",
      "train loss:0.16571588436773926\n",
      "train loss:0.09700643395672488\n",
      "train loss:0.16658390298383638\n",
      "train loss:0.3035362414581008\n",
      "train loss:0.1338193410461755\n",
      "train loss:0.18736788572117316\n",
      "train loss:0.16978880050196948\n",
      "train loss:0.14908205031126937\n",
      "train loss:0.24995676878440407\n",
      "train loss:0.23644472594541785\n",
      "train loss:0.17968300245233626\n",
      "train loss:0.2772120632486696\n",
      "train loss:0.12908290507306838\n",
      "train loss:0.26876490533846725\n",
      "train loss:0.2691175671330951\n",
      "train loss:0.1924002151785535\n",
      "train loss:0.1360195687627829\n",
      "train loss:0.18661309734669018\n",
      "train loss:0.18368377810999292\n",
      "train loss:0.3074760614794409\n",
      "train loss:0.15169292866285475\n",
      "train loss:0.24906626092985365\n",
      "train loss:0.18339085176701386\n",
      "train loss:0.1774493281801509\n",
      "train loss:0.1521854137176196\n",
      "train loss:0.18228296576699332\n",
      "train loss:0.20523651055670952\n",
      "train loss:0.2206724163646651\n",
      "train loss:0.2231830962282466\n",
      "train loss:0.1449171066285965\n",
      "train loss:0.19178242129525166\n",
      "train loss:0.19374272763471317\n",
      "train loss:0.3055399094204329\n",
      "train loss:0.1283737555650775\n",
      "train loss:0.17727205277207309\n",
      "train loss:0.26135322573200503\n",
      "train loss:0.22006729532373406\n",
      "train loss:0.12898909609943937\n",
      "train loss:0.23460016990564234\n",
      "train loss:0.14927326428185553\n",
      "train loss:0.21485787429282002\n",
      "train loss:0.1806914888678132\n",
      "train loss:0.21711164860963159\n",
      "train loss:0.22506351410159142\n",
      "train loss:0.23066824914457754\n",
      "train loss:0.1985025684167281\n",
      "train loss:0.1572266785301858\n",
      "train loss:0.23402423306898398\n",
      "train loss:0.1771482849137741\n",
      "train loss:0.14884379290650543\n",
      "train loss:0.2236441673466674\n",
      "train loss:0.13376085317319134\n",
      "train loss:0.2097852563353264\n",
      "train loss:0.1983194161343188\n",
      "train loss:0.2109049737584271\n",
      "train loss:0.16153468321295528\n",
      "train loss:0.10657281245015307\n",
      "train loss:0.11628524371030774\n",
      "train loss:0.16839463551732192\n",
      "train loss:0.17905193002714523\n",
      "train loss:0.21673253567631076\n",
      "train loss:0.09102017476845564\n",
      "train loss:0.172715245634536\n",
      "train loss:0.15659872830586546\n",
      "train loss:0.1604491904883857\n",
      "train loss:0.21128725686040575\n",
      "train loss:0.2412758771507356\n",
      "train loss:0.1257580987105685\n",
      "train loss:0.19868532664272504\n",
      "train loss:0.18426465310473378\n",
      "train loss:0.24676593444338138\n",
      "train loss:0.2382823989214946\n",
      "train loss:0.26319604917139794\n",
      "train loss:0.22096250651120924\n",
      "train loss:0.3757880188876827\n",
      "train loss:0.18369284968446242\n",
      "train loss:0.10435445221115003\n",
      "train loss:0.1665055749333569\n",
      "train loss:0.14610787638880685\n",
      "train loss:0.20149884346728356\n",
      "train loss:0.20222868650095777\n",
      "train loss:0.21124454175362722\n",
      "train loss:0.23281359891474881\n",
      "train loss:0.2678574317506835\n",
      "train loss:0.31243874656347215\n",
      "train loss:0.2329582024014819\n",
      "train loss:0.1656658527808582\n",
      "train loss:0.1665576651770786\n",
      "train loss:0.05869329519894333\n",
      "train loss:0.15063408253433053\n",
      "train loss:0.19063519469330384\n",
      "train loss:0.14283714566103467\n",
      "train loss:0.20241656429614513\n",
      "train loss:0.19198210249906517\n",
      "train loss:0.40314774660492037\n",
      "train loss:0.10889899517915881\n",
      "train loss:0.14256827336304936\n",
      "train loss:0.15629021282541541\n",
      "train loss:0.26279822426046473\n",
      "train loss:0.30038744126364636\n",
      "train loss:0.251863697867185\n",
      "train loss:0.19150918194287103\n",
      "train loss:0.2479321837734409\n",
      "train loss:0.22823539963020434\n",
      "train loss:0.1729746252439226\n",
      "train loss:0.18037954554272992\n",
      "train loss:0.15696376556639274\n",
      "train loss:0.1494768656779598\n",
      "train loss:0.07448229949534783\n",
      "train loss:0.24227516114345943\n",
      "train loss:0.21315456137035493\n",
      "train loss:0.19170310164073887\n",
      "train loss:0.23810904373557473\n",
      "train loss:0.2008063466016024\n",
      "train loss:0.08771289818038913\n",
      "train loss:0.1791904916136096\n",
      "train loss:0.22265738082514916\n",
      "train loss:0.2377516986136258\n",
      "train loss:0.1390358604525521\n",
      "train loss:0.18265527828647898\n",
      "train loss:0.17862321063900663\n",
      "train loss:0.302091620158889\n",
      "train loss:0.2770377863038112\n",
      "train loss:0.216184667336011\n",
      "train loss:0.18923535183587303\n",
      "train loss:0.18517128370709524\n",
      "train loss:0.26817347453345197\n",
      "train loss:0.24755159994259496\n",
      "train loss:0.25951327179665357\n",
      "train loss:0.2003636409456027\n",
      "train loss:0.1421070670750537\n",
      "train loss:0.1589449235143371\n",
      "train loss:0.1780399218680256\n",
      "train loss:0.16448921424304302\n",
      "train loss:0.10221419074668577\n",
      "train loss:0.13316123117619325\n",
      "train loss:0.13684826113866008\n",
      "train loss:0.1217221151345438\n",
      "train loss:0.16036197470942376\n",
      "train loss:0.15643129777312345\n",
      "train loss:0.2053981306868022\n",
      "train loss:0.15882546889980226\n",
      "train loss:0.20107970663965433\n",
      "train loss:0.1858132537475672\n",
      "train loss:0.19278967070149872\n",
      "train loss:0.12764715749902333\n",
      "train loss:0.30006313661815165\n",
      "train loss:0.26057036154219143\n",
      "train loss:0.15841705977608972\n",
      "train loss:0.20051223937338616\n",
      "train loss:0.154056712293591\n",
      "train loss:0.12188308308689227\n",
      "train loss:0.19375418923299073\n",
      "train loss:0.15908799837140408\n",
      "train loss:0.17610432278612906\n",
      "train loss:0.13873074157446996\n",
      "train loss:0.2515053019161299\n",
      "train loss:0.1107326310042578\n",
      "train loss:0.2208859546201211\n",
      "train loss:0.19495586050619007\n",
      "train loss:0.12823208607003542\n",
      "train loss:0.15211350641049085\n",
      "train loss:0.09830220924096388\n",
      "train loss:0.17557441933044482\n",
      "train loss:0.08730947761525332\n",
      "train loss:0.14028137387484255\n",
      "train loss:0.2930138952092809\n",
      "train loss:0.19212524319708688\n",
      "train loss:0.14999609847781176\n",
      "train loss:0.1988957446649701\n",
      "train loss:0.10141276620932313\n",
      "train loss:0.1632890269842669\n",
      "train loss:0.19753374516621158\n",
      "train loss:0.1965645003584208\n",
      "train loss:0.132169984371621\n",
      "train loss:0.22544258596057523\n",
      "train loss:0.14447765726996814\n",
      "train loss:0.10948634526407887\n",
      "train loss:0.06660367486328637\n",
      "train loss:0.23405281226109878\n",
      "train loss:0.17753430924836086\n",
      "train loss:0.19248610896176724\n",
      "train loss:0.2574777681802608\n",
      "train loss:0.18025212724671236\n",
      "train loss:0.18744638943163228\n",
      "train loss:0.11463515753550052\n",
      "train loss:0.09724863941046745\n",
      "train loss:0.13739959683689884\n",
      "train loss:0.26388464799870137\n",
      "train loss:0.12103575661716011\n",
      "train loss:0.30664686038661443\n",
      "train loss:0.1483829087184519\n",
      "train loss:0.19646165841389585\n",
      "train loss:0.1831926306824717\n",
      "train loss:0.09586733409013756\n",
      "train loss:0.1971025421242896\n",
      "train loss:0.16287563691784532\n",
      "train loss:0.3916134742016944\n",
      "train loss:0.21613629310059568\n",
      "train loss:0.18635130858243953\n",
      "train loss:0.1546660934503335\n",
      "train loss:0.2376863416799224\n",
      "train loss:0.21396659188745132\n",
      "train loss:0.1986393877750202\n",
      "train loss:0.19564613801416772\n",
      "train loss:0.12888235339616025\n",
      "train loss:0.2272172914323856\n",
      "train loss:0.1664637765528829\n",
      "train loss:0.23928554144821682\n",
      "train loss:0.14747762930834166\n",
      "train loss:0.23837308498974555\n",
      "train loss:0.1852330734727338\n",
      "train loss:0.23050952597764135\n",
      "train loss:0.2166365444328732\n",
      "train loss:0.21068756335710753\n",
      "train loss:0.17773564771433722\n",
      "train loss:0.26929420488566547\n",
      "train loss:0.18653790895272648\n",
      "train loss:0.084175707203139\n",
      "train loss:0.18566543595011983\n",
      "train loss:0.18854923583481611\n",
      "train loss:0.250076508716697\n",
      "train loss:0.07189142173404314\n",
      "train loss:0.19433715912519453\n",
      "train loss:0.20465020508071802\n",
      "train loss:0.24443605799095852\n",
      "train loss:0.22100717321657712\n",
      "train loss:0.18551896558673928\n",
      "train loss:0.31124614056202743\n",
      "train loss:0.18416481880532293\n",
      "train loss:0.22772703649878195\n",
      "train loss:0.24669156052255528\n",
      "train loss:0.18216947083785698\n",
      "train loss:0.15166050269251882\n",
      "train loss:0.15524002576112267\n",
      "train loss:0.21365298409186817\n",
      "train loss:0.10460153667620974\n",
      "train loss:0.15006089983961035\n",
      "train loss:0.21040181820211948\n",
      "train loss:0.19704284401406993\n",
      "train loss:0.18001333322109836\n",
      "train loss:0.25619697410322856\n",
      "train loss:0.33492631561352154\n",
      "train loss:0.2304170528348993\n",
      "train loss:0.15237843397033604\n",
      "train loss:0.24533161939758547\n",
      "train loss:0.14994746068019094\n",
      "train loss:0.11838366519051609\n",
      "train loss:0.18626564805620288\n",
      "train loss:0.18080411473776614\n",
      "train loss:0.1733687777620372\n",
      "train loss:0.24755030576363019\n",
      "train loss:0.22552944269799505\n",
      "train loss:0.16588349704436173\n",
      "train loss:0.19813273245257837\n",
      "train loss:0.19064156042069277\n",
      "train loss:0.20310669174979012\n",
      "train loss:0.1514689449095619\n",
      "train loss:0.20440195512393758\n",
      "train loss:0.1384156501332997\n",
      "train loss:0.3134287293884682\n",
      "train loss:0.2437457760736704\n",
      "train loss:0.3077970671976136\n",
      "train loss:0.14229023378378494\n",
      "train loss:0.09465638765331776\n",
      "train loss:0.13188063677942555\n",
      "train loss:0.13688652405647012\n",
      "train loss:0.20708262112798476\n",
      "train loss:0.20842609541564344\n",
      "train loss:0.09959779205111215\n",
      "train loss:0.13038528419516704\n",
      "train loss:0.22390602465653703\n",
      "train loss:0.11940641081203034\n",
      "train loss:0.2924560752063122\n",
      "train loss:0.19552944476175146\n",
      "train loss:0.32198214647318635\n",
      "train loss:0.18902681926771184\n",
      "train loss:0.16037542854929626\n",
      "train loss:0.20889191439894536\n",
      "train loss:0.17776877639596253\n",
      "train loss:0.21636873802738218\n",
      "train loss:0.26240663914931345\n",
      "train loss:0.23616020310505262\n",
      "train loss:0.12997294887022343\n",
      "train loss:0.18148485755727248\n",
      "train loss:0.17502864598826423\n",
      "train loss:0.21510806331041152\n",
      "train loss:0.1906630930325776\n",
      "train loss:0.15169492076050317\n",
      "train loss:0.15529472263816219\n",
      "train loss:0.17617153145535372\n",
      "train loss:0.21055181161352332\n",
      "train loss:0.192306832254441\n",
      "train loss:0.14251764686474264\n",
      "train loss:0.1804872491059402\n",
      "train loss:0.17853004915222964\n",
      "train loss:0.1994855264066426\n",
      "train loss:0.1594356368200942\n",
      "train loss:0.13440921047933185\n",
      "train loss:0.08459107149300485\n",
      "train loss:0.19796126451425816\n",
      "train loss:0.15100892945077157\n",
      "train loss:0.08847833159107571\n",
      "train loss:0.17975907646186712\n",
      "train loss:0.19740415025324637\n",
      "train loss:0.21833416791454086\n",
      "train loss:0.10758041855458936\n",
      "train loss:0.2085676860401004\n",
      "train loss:0.11077111121843544\n",
      "train loss:0.22889304996777568\n",
      "train loss:0.19985943258507674\n",
      "train loss:0.3184172747050606\n",
      "train loss:0.08081799096301666\n",
      "train loss:0.10374181593223959\n",
      "train loss:0.23149144681551515\n",
      "train loss:0.24421454741783039\n",
      "train loss:0.15843382992503746\n",
      "train loss:0.1804228383350992\n",
      "train loss:0.0860083651599072\n",
      "train loss:0.2534069775525069\n",
      "train loss:0.1397893077011536\n",
      "train loss:0.1709385667000691\n",
      "train loss:0.15407828895479045\n",
      "train loss:0.19418432191049662\n",
      "train loss:0.22766279267360953\n",
      "train loss:0.18502860258764475\n",
      "train loss:0.14889786573867056\n",
      "train loss:0.18084409451125383\n",
      "train loss:0.1851332611255912\n",
      "train loss:0.15758197633881404\n",
      "train loss:0.17439368904322772\n",
      "train loss:0.11278974821080606\n",
      "train loss:0.19504728323102527\n",
      "train loss:0.15726782401652506\n",
      "train loss:0.17691886437419196\n",
      "train loss:0.12666364728137028\n",
      "train loss:0.3218060205535117\n",
      "train loss:0.3543378478879083\n",
      "train loss:0.2357060291014574\n",
      "train loss:0.1599041327084901\n",
      "train loss:0.1723660214526198\n",
      "train loss:0.10613600575939618\n",
      "train loss:0.17905451305020553\n",
      "train loss:0.16023545643679182\n",
      "train loss:0.18647103782730476\n",
      "train loss:0.15822653838313044\n",
      "train loss:0.281540157629577\n",
      "train loss:0.14987592365094393\n",
      "train loss:0.16837749998244222\n",
      "train loss:0.21786227486943296\n",
      "train loss:0.1332902249440698\n",
      "train loss:0.140292676900076\n",
      "train loss:0.12805423900920015\n",
      "train loss:0.12436356084164682\n",
      "train loss:0.22067816148329203\n",
      "train loss:0.13291574649470095\n",
      "train loss:0.22561214131103044\n",
      "train loss:0.19781099345557837\n",
      "train loss:0.15238924464041292\n",
      "train loss:0.1455766688446176\n",
      "train loss:0.08019716428219327\n",
      "train loss:0.27463016741860546\n",
      "train loss:0.15701699159465834\n",
      "train loss:0.1375161514027833\n",
      "train loss:0.08632204687055585\n",
      "train loss:0.23260046670616988\n",
      "train loss:0.144785347812656\n",
      "train loss:0.16638431966104836\n",
      "train loss:0.14550951255430994\n",
      "train loss:0.20084662825335242\n",
      "train loss:0.2631086991750291\n",
      "train loss:0.27126483283450953\n",
      "train loss:0.23910964393812675\n",
      "train loss:0.15364790565670117\n",
      "train loss:0.13453346343758146\n",
      "train loss:0.17094538427237116\n",
      "train loss:0.09188699591598518\n",
      "train loss:0.14651896056451208\n",
      "train loss:0.1233183492623882\n",
      "train loss:0.2176769405701811\n",
      "train loss:0.14633068750714953\n",
      "train loss:0.19150964810170173\n",
      "train loss:0.2605037412742142\n",
      "train loss:0.17416975542097718\n",
      "train loss:0.32770000974454666\n",
      "train loss:0.19300829614013917\n",
      "train loss:0.16180918243193507\n",
      "train loss:0.1417709298727672\n",
      "train loss:0.18519600623112573\n",
      "train loss:0.1942007447626973\n",
      "train loss:0.15699927165472738\n",
      "train loss:0.21074579641961766\n",
      "train loss:0.23168777351636527\n",
      "train loss:0.2514126218511996\n",
      "train loss:0.20363885602847595\n",
      "train loss:0.14009994859906574\n",
      "train loss:0.07244649704647327\n",
      "train loss:0.2053196056690768\n",
      "train loss:0.20962156721705333\n",
      "train loss:0.14525304508656434\n",
      "train loss:0.09606203558982518\n",
      "train loss:0.20223550404544052\n",
      "train loss:0.08385238777856081\n",
      "train loss:0.14243228863185733\n",
      "train loss:0.14998080738027408\n",
      "train loss:0.15248104568324367\n",
      "train loss:0.10592180217755644\n",
      "train loss:0.18732912158624773\n",
      "train loss:0.21376371812453016\n",
      "train loss:0.19017618230594813\n",
      "train loss:0.19686482869836566\n",
      "train loss:0.24846835546803728\n",
      "train loss:0.17594654785621436\n",
      "train loss:0.2907686094877455\n",
      "train loss:0.21500465026278914\n",
      "train loss:0.19817743443755828\n",
      "train loss:0.10836320832371107\n",
      "train loss:0.2348985500568095\n",
      "train loss:0.1407570425842956\n",
      "train loss:0.18008640219612\n",
      "train loss:0.1530603097369391\n",
      "train loss:0.21595634530685104\n",
      "train loss:0.19877824203701144\n",
      "train loss:0.18313587051747576\n",
      "train loss:0.17603420300955822\n",
      "train loss:0.21507934024934083\n",
      "train loss:0.14382678899768775\n",
      "train loss:0.23377006533006953\n",
      "train loss:0.19993783229641793\n",
      "train loss:0.1520080557971279\n",
      "train loss:0.27851087120067824\n",
      "train loss:0.1341451719672571\n",
      "train loss:0.11281545436452839\n",
      "train loss:0.20754820483760877\n",
      "train loss:0.16409886021956147\n",
      "train loss:0.19543345273090182\n",
      "train loss:0.17142805843213332\n",
      "train loss:0.16751123152080896\n",
      "train loss:0.14386599889065668\n",
      "train loss:0.13038894930099132\n",
      "train loss:0.08597854541288101\n",
      "train loss:0.10757207620387418\n",
      "train loss:0.25659431450895603\n",
      "train loss:0.2444627597526842\n",
      "train loss:0.2028318229575279\n",
      "train loss:0.12196573001468324\n",
      "train loss:0.22625309122936238\n",
      "train loss:0.18334988885873418\n",
      "train loss:0.17390034351501896\n",
      "train loss:0.13873571707646204\n",
      "train loss:0.18973937588937909\n",
      "train loss:0.13394957414655428\n",
      "train loss:0.1899860819291526\n",
      "train loss:0.18214087704651608\n",
      "train loss:0.13221809468875337\n",
      "train loss:0.1850168338183191\n",
      "train loss:0.27292632235070075\n",
      "train loss:0.1689814180839645\n",
      "train loss:0.18226571363528937\n",
      "train loss:0.10912588153156079\n",
      "train loss:0.12386897413660788\n",
      "train loss:0.10367821477917265\n",
      "train loss:0.19120126677806082\n",
      "train loss:0.23716804570351308\n",
      "train loss:0.17153304124996901\n",
      "train loss:0.23192834898805628\n",
      "train loss:0.22644928011004029\n",
      "train loss:0.2323509030788012\n",
      "train loss:0.25352500658721944\n",
      "train loss:0.10968241391036564\n",
      "train loss:0.1668400134477167\n",
      "train loss:0.30331541936719\n",
      "train loss:0.23579762134416626\n",
      "train loss:0.11134171511099085\n",
      "train loss:0.11860127059875714\n",
      "train loss:0.21831627825219882\n",
      "train loss:0.16391496155967786\n",
      "train loss:0.21194768227128402\n",
      "train loss:0.1719761892881068\n",
      "train loss:0.25222600929014866\n",
      "train loss:0.1853185625781617\n",
      "train loss:0.1455043239233924\n",
      "train loss:0.14006071247673885\n",
      "train loss:0.20688251345225062\n",
      "train loss:0.17042709539282463\n",
      "train loss:0.14825476934963436\n",
      "train loss:0.24788965868762877\n",
      "train loss:0.22975824299790318\n",
      "train loss:0.16235174654884396\n",
      "train loss:0.11476400426440968\n",
      "train loss:0.14495107963033527\n",
      "train loss:0.19118742106863423\n",
      "train loss:0.3008941526887144\n",
      "train loss:0.2038362091742334\n",
      "train loss:0.13585574258655295\n",
      "train loss:0.18539423319196807\n",
      "train loss:0.1342797108097425\n",
      "train loss:0.12076131146780505\n",
      "train loss:0.16775589703015623\n",
      "train loss:0.2168522625914818\n",
      "train loss:0.2212223845899902\n",
      "train loss:0.11485546674652508\n",
      "train loss:0.13749278237099827\n",
      "train loss:0.148978473212366\n",
      "train loss:0.14296373988665367\n",
      "train loss:0.16790394957359947\n",
      "train loss:0.22381206872701384\n",
      "train loss:0.17083997059726275\n",
      "train loss:0.2175668324913814\n",
      "train loss:0.10500923575738827\n",
      "train loss:0.2316548646909769\n",
      "train loss:0.11573227483563812\n",
      "train loss:0.08102745785277884\n",
      "train loss:0.18789653398200554\n",
      "train loss:0.2564737400373719\n",
      "train loss:0.1338819962121031\n",
      "train loss:0.06792315270936963\n",
      "train loss:0.23637943107837775\n",
      "train loss:0.1746118682164694\n",
      "train loss:0.13039613608193457\n",
      "train loss:0.14422754754384162\n",
      "train loss:0.09649367109017329\n",
      "train loss:0.19197358549895316\n",
      "train loss:0.14262097380100885\n",
      "train loss:0.13231530374071562\n",
      "train loss:0.25900389268283364\n",
      "train loss:0.22051970087887315\n",
      "train loss:0.12564860811297757\n",
      "train loss:0.2210660923172018\n",
      "train loss:0.2238738396681885\n",
      "train loss:0.16778566779391277\n",
      "train loss:0.18882363537135788\n",
      "train loss:0.17863409944387346\n",
      "train loss:0.10548733104740775\n",
      "train loss:0.1356482338346501\n",
      "train loss:0.11178380231772715\n",
      "train loss:0.2323067516171187\n",
      "train loss:0.19185336219260093\n",
      "train loss:0.11013961878988528\n",
      "train loss:0.18339973238007995\n",
      "train loss:0.20118757408517116\n",
      "train loss:0.22611560023481683\n",
      "train loss:0.23119706616823496\n",
      "train loss:0.21013635341258186\n",
      "train loss:0.2579622175279209\n",
      "train loss:0.26510682422402837\n",
      "train loss:0.1929042615903537\n",
      "train loss:0.16038800378680498\n",
      "train loss:0.07740351774979279\n",
      "train loss:0.18055602133381032\n",
      "train loss:0.206522082813084\n",
      "train loss:0.11784330646935678\n",
      "train loss:0.28465059710262497\n",
      "train loss:0.13697896858902342\n",
      "train loss:0.23591404099335322\n",
      "train loss:0.13586958372477104\n",
      "train loss:0.21554558412704636\n",
      "train loss:0.15169250019096867\n",
      "train loss:0.3007679658013132\n",
      "train loss:0.09647990013567194\n",
      "train loss:0.2098543377393447\n",
      "train loss:0.14408286778156276\n",
      "train loss:0.09799125901559062\n",
      "train loss:0.22780186402819524\n",
      "train loss:0.19981561247732446\n",
      "train loss:0.14908076331360035\n",
      "train loss:0.16029575836832902\n",
      "train loss:0.175433578485103\n",
      "=== epoch:8, train acc:0.931, test acc:0.912 ===\n",
      "train loss:0.1572538686156311\n",
      "train loss:0.16573994327469044\n",
      "train loss:0.12097248692791536\n",
      "train loss:0.17239028369078674\n",
      "train loss:0.14312877468786983\n",
      "train loss:0.12735234451183242\n",
      "train loss:0.1131799915227298\n",
      "train loss:0.10075467643049356\n",
      "train loss:0.17575434610111576\n",
      "train loss:0.21749308472786866\n",
      "train loss:0.22050084340845072\n",
      "train loss:0.20327628522460597\n",
      "train loss:0.265251153316806\n",
      "train loss:0.1585289589632532\n",
      "train loss:0.2028247589455239\n",
      "train loss:0.14721290724888486\n",
      "train loss:0.1869701058420051\n",
      "train loss:0.09333639346547333\n",
      "train loss:0.11341617958147092\n",
      "train loss:0.10912094188958331\n",
      "train loss:0.21949373517579696\n",
      "train loss:0.19359421227065388\n",
      "train loss:0.16062305768085994\n",
      "train loss:0.22416873844337776\n",
      "train loss:0.190602119906886\n",
      "train loss:0.1916627232451608\n",
      "train loss:0.0827603568008556\n",
      "train loss:0.25660333838614424\n",
      "train loss:0.2115004100908997\n",
      "train loss:0.21634629519104867\n",
      "train loss:0.27466846386984006\n",
      "train loss:0.07702313861347528\n",
      "train loss:0.09208458519466854\n",
      "train loss:0.28037083792632556\n",
      "train loss:0.18338400230195911\n",
      "train loss:0.18197193395633968\n",
      "train loss:0.1145922258017256\n",
      "train loss:0.14545978920115052\n",
      "train loss:0.2216327459218082\n",
      "train loss:0.1433488943468127\n",
      "train loss:0.2785089245613724\n",
      "train loss:0.11430095110962146\n",
      "train loss:0.14874806966020945\n",
      "train loss:0.22139023030498162\n",
      "train loss:0.18146032021276765\n",
      "train loss:0.20129908018896767\n",
      "train loss:0.14400425160410216\n",
      "train loss:0.19010476720197542\n",
      "train loss:0.20605417806623794\n",
      "train loss:0.07491760270274118\n",
      "train loss:0.22056936755573847\n",
      "train loss:0.10325533101427149\n",
      "train loss:0.19426128256690547\n",
      "train loss:0.18917150256662615\n",
      "train loss:0.20814583160083278\n",
      "train loss:0.22017017569019962\n",
      "train loss:0.12812853521411818\n",
      "train loss:0.12513846478252955\n",
      "train loss:0.11199414773925717\n",
      "train loss:0.15453569098343517\n",
      "train loss:0.11228727061473631\n",
      "train loss:0.09188670286063111\n",
      "train loss:0.1932115110517566\n",
      "train loss:0.22616846903962048\n",
      "train loss:0.3486996135481493\n",
      "train loss:0.20779500052240102\n",
      "train loss:0.19159399287545717\n",
      "train loss:0.1479891673120311\n",
      "train loss:0.175430132345912\n",
      "train loss:0.1007768262970189\n",
      "train loss:0.15744450976760724\n",
      "train loss:0.17259274476345823\n",
      "train loss:0.21128725186824507\n",
      "train loss:0.2586858471040956\n",
      "train loss:0.20904524715620007\n",
      "train loss:0.17260751648998277\n",
      "train loss:0.14275620928039306\n",
      "train loss:0.16675760019096167\n",
      "train loss:0.2385775525983317\n",
      "train loss:0.15048417150175988\n",
      "train loss:0.1662454488614444\n",
      "train loss:0.228448037093748\n",
      "train loss:0.20762601545227774\n",
      "train loss:0.149206925541415\n",
      "train loss:0.18896289921987505\n",
      "train loss:0.3389783838158642\n",
      "train loss:0.09255665438604646\n",
      "train loss:0.1561948534241671\n",
      "train loss:0.09408500295218786\n",
      "train loss:0.1129126665817334\n",
      "train loss:0.2010463221329461\n",
      "train loss:0.13120170806785736\n",
      "train loss:0.14114264638234345\n",
      "train loss:0.18010128619588028\n",
      "train loss:0.20482627480638751\n",
      "train loss:0.2589981404944243\n",
      "train loss:0.16315683616112445\n",
      "train loss:0.23482342093554315\n",
      "train loss:0.19885586020786267\n",
      "train loss:0.13888569204376908\n",
      "train loss:0.15171318961087732\n",
      "train loss:0.0819303528787969\n",
      "train loss:0.2112212681437511\n",
      "train loss:0.2514287277214089\n",
      "train loss:0.2470634641546814\n",
      "train loss:0.16133247832278796\n",
      "train loss:0.10751865821072676\n",
      "train loss:0.22104097521882304\n",
      "train loss:0.12831941695150043\n",
      "train loss:0.08982173230453057\n",
      "train loss:0.10957724121360904\n",
      "train loss:0.19870035520885426\n",
      "train loss:0.15054801607740928\n",
      "train loss:0.157445513654995\n",
      "train loss:0.1736434131760729\n",
      "train loss:0.1943439385407577\n",
      "train loss:0.17924907923705283\n",
      "train loss:0.20105365262086894\n",
      "train loss:0.2019220290820033\n",
      "train loss:0.18967423428094293\n",
      "train loss:0.19074118906934934\n",
      "train loss:0.18827660290250212\n",
      "train loss:0.17431073985072984\n",
      "train loss:0.1492797813239681\n",
      "train loss:0.1989866113867328\n",
      "train loss:0.13353243108740132\n",
      "train loss:0.0778665271898332\n",
      "train loss:0.22493229823884792\n",
      "train loss:0.17924778183268417\n",
      "train loss:0.1380058955255219\n",
      "train loss:0.23327996362218045\n",
      "train loss:0.1065183921772021\n",
      "train loss:0.1382588373302078\n",
      "train loss:0.18517956956338757\n",
      "train loss:0.18444644838634425\n",
      "train loss:0.18244507218300793\n",
      "train loss:0.11699018127434645\n",
      "train loss:0.19791204671837392\n",
      "train loss:0.14654507857866\n",
      "train loss:0.19742514237495468\n",
      "train loss:0.13875574304517557\n",
      "train loss:0.14100456426840155\n",
      "train loss:0.22159980931401382\n",
      "train loss:0.1046669024231209\n",
      "train loss:0.18313996478191677\n",
      "train loss:0.2345786040996077\n",
      "train loss:0.12792652012283587\n",
      "train loss:0.13884115759279467\n",
      "train loss:0.19832808765438248\n",
      "train loss:0.13690599362973851\n",
      "train loss:0.1637440556601685\n",
      "train loss:0.1789913764678926\n",
      "train loss:0.11433370042631914\n",
      "train loss:0.18635783007149925\n",
      "train loss:0.14731248024523902\n",
      "train loss:0.32345730003162154\n",
      "train loss:0.27746613200062986\n",
      "train loss:0.15020323152114215\n",
      "train loss:0.12865637476714478\n",
      "train loss:0.1400221536049737\n",
      "train loss:0.18053111099589586\n",
      "train loss:0.1670864843157756\n",
      "train loss:0.13916112597544078\n",
      "train loss:0.1712587402033742\n",
      "train loss:0.10470035475272046\n",
      "train loss:0.13798189643705183\n",
      "train loss:0.20385818583539148\n",
      "train loss:0.16348949655452777\n",
      "train loss:0.2854961957755976\n",
      "train loss:0.1501211293672699\n",
      "train loss:0.18166712391009143\n",
      "train loss:0.13800257753763254\n",
      "train loss:0.22333478368414184\n",
      "train loss:0.18326590740519325\n",
      "train loss:0.19217882638359637\n",
      "train loss:0.20587676812812628\n",
      "train loss:0.15611243244200498\n",
      "train loss:0.16327780728059182\n",
      "train loss:0.14271218243043068\n",
      "train loss:0.33301395040957615\n",
      "train loss:0.1763912262431324\n",
      "train loss:0.1272419745155057\n",
      "train loss:0.21611105698215533\n",
      "train loss:0.23208329792902357\n",
      "train loss:0.19487899781594806\n",
      "train loss:0.11378873859885032\n",
      "train loss:0.07362507919436195\n",
      "train loss:0.1778869474106995\n",
      "train loss:0.17402387511054876\n",
      "train loss:0.14867581108582406\n",
      "train loss:0.14363489061534984\n",
      "train loss:0.2169700994151068\n",
      "train loss:0.18626476487579738\n",
      "train loss:0.2490245528241774\n",
      "train loss:0.12141168319540713\n",
      "train loss:0.119867432377273\n",
      "train loss:0.0900720099337182\n",
      "train loss:0.11881857092093667\n",
      "train loss:0.10846186263657108\n",
      "train loss:0.3148862119660244\n",
      "train loss:0.18822195885932544\n",
      "train loss:0.17790985687182534\n",
      "train loss:0.1800106001688074\n",
      "train loss:0.15093741283271472\n",
      "train loss:0.10332556503190451\n",
      "train loss:0.19631391579239735\n",
      "train loss:0.1282354512969235\n",
      "train loss:0.12533094499584652\n",
      "train loss:0.11525884841906495\n",
      "train loss:0.13259742051487494\n",
      "train loss:0.1782300522904508\n",
      "train loss:0.1095879253847669\n",
      "train loss:0.15256993046350192\n",
      "train loss:0.2043503442956521\n",
      "train loss:0.1335591711282163\n",
      "train loss:0.23252473669637133\n",
      "train loss:0.11465568348212953\n",
      "train loss:0.13023324021705368\n",
      "train loss:0.17317243381827852\n",
      "train loss:0.19737717445443484\n",
      "train loss:0.13791820814950306\n",
      "train loss:0.2550803547419742\n",
      "train loss:0.13590924940966864\n",
      "train loss:0.21777358304390085\n",
      "train loss:0.22105727833981562\n",
      "train loss:0.15778465589846816\n",
      "train loss:0.12236919918635751\n",
      "train loss:0.15631849913721854\n",
      "train loss:0.21878953218939987\n",
      "train loss:0.10234716048605799\n",
      "train loss:0.25245698885243817\n",
      "train loss:0.08792605575624063\n",
      "train loss:0.10141359962001338\n",
      "train loss:0.25541146155348465\n",
      "train loss:0.28080667105094864\n",
      "train loss:0.20311433122072686\n",
      "train loss:0.06967128355189718\n",
      "train loss:0.09543330787176035\n",
      "train loss:0.21804514009440418\n",
      "train loss:0.13417557273055888\n",
      "train loss:0.09162969397979692\n",
      "train loss:0.12063025993563167\n",
      "train loss:0.18069243801093227\n",
      "train loss:0.12479379947034479\n",
      "train loss:0.12216498296771164\n",
      "train loss:0.1684136997935387\n",
      "train loss:0.13033674438691267\n",
      "train loss:0.15676127579902574\n",
      "train loss:0.1822449324034632\n",
      "train loss:0.13152932690356794\n",
      "train loss:0.1183913170431063\n",
      "train loss:0.15090551322077894\n",
      "train loss:0.1509624782475962\n",
      "train loss:0.18551258742744925\n",
      "train loss:0.25035354755222355\n",
      "train loss:0.22063559365320995\n",
      "train loss:0.12430057443395469\n",
      "train loss:0.16510614478730393\n",
      "train loss:0.14005527801044393\n",
      "train loss:0.18763871633166807\n",
      "train loss:0.17342464584016087\n",
      "train loss:0.13517619347536855\n",
      "train loss:0.11648304533496491\n",
      "train loss:0.10091395993512074\n",
      "train loss:0.13462272214861437\n",
      "train loss:0.19365374232398425\n",
      "train loss:0.13032523193248782\n",
      "train loss:0.046949627273610295\n",
      "train loss:0.12127942788642444\n",
      "train loss:0.176425592249728\n",
      "train loss:0.10854477684799962\n",
      "train loss:0.2010243623946607\n",
      "train loss:0.1802814437483419\n",
      "train loss:0.1568917788791286\n",
      "train loss:0.23440495683649462\n",
      "train loss:0.12412604304238158\n",
      "train loss:0.24420093832659995\n",
      "train loss:0.18618170919175647\n",
      "train loss:0.11017451541831064\n",
      "train loss:0.09531950291475563\n",
      "train loss:0.11360189777227303\n",
      "train loss:0.11329451868862815\n",
      "train loss:0.09855943921353261\n",
      "train loss:0.15750654354390123\n",
      "train loss:0.15088906456456883\n",
      "train loss:0.24159022665162935\n",
      "train loss:0.17660833332047512\n",
      "train loss:0.2028117382675689\n",
      "train loss:0.15224404824872\n",
      "train loss:0.17981455328221763\n",
      "train loss:0.13303170842620365\n",
      "train loss:0.15530571348877914\n",
      "train loss:0.09729549961661062\n",
      "train loss:0.14596511161484618\n",
      "train loss:0.14335480228520542\n",
      "train loss:0.09486861587370905\n",
      "train loss:0.13747483943078745\n",
      "train loss:0.17966759147190456\n",
      "train loss:0.24942883630523813\n",
      "train loss:0.10121090110325058\n",
      "train loss:0.16469492959618454\n",
      "train loss:0.08856136481217977\n",
      "train loss:0.2185549093607909\n",
      "train loss:0.159357068784651\n",
      "train loss:0.1589381807261703\n",
      "train loss:0.1995978042409524\n",
      "train loss:0.22852923745159898\n",
      "train loss:0.1817402032571848\n",
      "train loss:0.21406321692629812\n",
      "train loss:0.1986981805338377\n",
      "train loss:0.19181736813681982\n",
      "train loss:0.21173520126492595\n",
      "train loss:0.09839854041504276\n",
      "train loss:0.21730386494628648\n",
      "train loss:0.19607272129311554\n",
      "train loss:0.17795915569052087\n",
      "train loss:0.24720400770539416\n",
      "train loss:0.14793520261118517\n",
      "train loss:0.15659207508735137\n",
      "train loss:0.19919811761805906\n",
      "train loss:0.15977957013537958\n",
      "train loss:0.16617552042113462\n",
      "train loss:0.13585639715120312\n",
      "train loss:0.16671210668626904\n",
      "train loss:0.19186299877301694\n",
      "train loss:0.1467412188018435\n",
      "train loss:0.17460380171404352\n",
      "train loss:0.11306358466978342\n",
      "train loss:0.22138166594383943\n",
      "train loss:0.1795781078728435\n",
      "train loss:0.10811401771685791\n",
      "train loss:0.1319275770244875\n",
      "train loss:0.2405569532948266\n",
      "train loss:0.16915430650859595\n",
      "train loss:0.14791794038183978\n",
      "train loss:0.26063939767874383\n",
      "train loss:0.18162577034246452\n",
      "train loss:0.24747528132027777\n",
      "train loss:0.12946606296661517\n",
      "train loss:0.10443354574947344\n",
      "train loss:0.15278224169383042\n",
      "train loss:0.11010532887512406\n",
      "train loss:0.16628128706207135\n",
      "train loss:0.18324036787415468\n",
      "train loss:0.18606266592977608\n",
      "train loss:0.1307111919469788\n",
      "train loss:0.20592061470990022\n",
      "train loss:0.11069290056562493\n",
      "train loss:0.2505864074645393\n",
      "train loss:0.1433264149245257\n",
      "train loss:0.11320005857706752\n",
      "train loss:0.13441082821235656\n",
      "train loss:0.12769120685755422\n",
      "train loss:0.20098149386063097\n",
      "train loss:0.11513798786668218\n",
      "train loss:0.18028253209023998\n",
      "train loss:0.184979168173039\n",
      "train loss:0.21204065628013777\n",
      "train loss:0.15448707705605103\n",
      "train loss:0.10301257235489386\n",
      "train loss:0.10606813452103936\n",
      "train loss:0.18384894906085855\n",
      "train loss:0.27488939976390436\n",
      "train loss:0.16436888408252553\n",
      "train loss:0.22262866356062816\n",
      "train loss:0.16497014830733697\n",
      "train loss:0.09713155703697868\n",
      "train loss:0.0992025654221094\n",
      "train loss:0.22803593216336268\n",
      "train loss:0.15124182965047178\n",
      "train loss:0.2200201009686729\n",
      "train loss:0.17953779221360233\n",
      "train loss:0.21180289432028712\n",
      "train loss:0.13638879899761636\n",
      "train loss:0.15258789984229104\n",
      "train loss:0.1645949890098623\n",
      "train loss:0.09974698065715559\n",
      "train loss:0.21050160412811675\n",
      "train loss:0.09845402908166272\n",
      "train loss:0.09255929322514421\n",
      "train loss:0.20263096871519945\n",
      "train loss:0.2827936365037417\n",
      "train loss:0.17392397521979608\n",
      "train loss:0.10729619152179903\n",
      "train loss:0.20691365963102323\n",
      "train loss:0.185379119306832\n",
      "train loss:0.12466137499756032\n",
      "train loss:0.17961339160226633\n",
      "train loss:0.23939961878147892\n",
      "train loss:0.09242320322641354\n",
      "train loss:0.1295451097463447\n",
      "train loss:0.3208985261277828\n",
      "train loss:0.19630447078716748\n",
      "train loss:0.09025260363714394\n",
      "train loss:0.27318957414681966\n",
      "train loss:0.25995221582561057\n",
      "train loss:0.2725259939425417\n",
      "train loss:0.17214554389281023\n",
      "train loss:0.14342677472095455\n",
      "train loss:0.1840789316287839\n",
      "train loss:0.1577367339916089\n",
      "train loss:0.21938828175279068\n",
      "train loss:0.13132347125028926\n",
      "train loss:0.14865506441137988\n",
      "train loss:0.0953937844679426\n",
      "train loss:0.19955266379271286\n",
      "train loss:0.18947538325579358\n",
      "train loss:0.23171173593695152\n",
      "train loss:0.16911285340683466\n",
      "train loss:0.12754421257815815\n",
      "train loss:0.2578334130232152\n",
      "train loss:0.10247490539716538\n",
      "train loss:0.19293241426868518\n",
      "train loss:0.11586213968639222\n",
      "train loss:0.20940676428777427\n",
      "train loss:0.16711408361969568\n",
      "train loss:0.19161898779395176\n",
      "train loss:0.09690446672513285\n",
      "train loss:0.1838552474285321\n",
      "train loss:0.16911759999422732\n",
      "train loss:0.15091726905774627\n",
      "train loss:0.24648514944708735\n",
      "train loss:0.263697201388558\n",
      "train loss:0.14412503498391122\n",
      "train loss:0.07361254191892072\n",
      "train loss:0.13496862654729086\n",
      "train loss:0.1571588406916983\n",
      "train loss:0.1101936974600772\n",
      "train loss:0.19561566036610822\n",
      "train loss:0.26667112082973926\n",
      "train loss:0.250250356151406\n",
      "train loss:0.10323499836957951\n",
      "train loss:0.18756862040737166\n",
      "train loss:0.2154882885383293\n",
      "train loss:0.23485743592034605\n",
      "train loss:0.1570585927796543\n",
      "train loss:0.10948641166837335\n",
      "train loss:0.1652648419088227\n",
      "train loss:0.1488235767428955\n",
      "train loss:0.15051896409172236\n",
      "train loss:0.15141945350118646\n",
      "train loss:0.1989521813007202\n",
      "train loss:0.13862030864220884\n",
      "train loss:0.1004681721696282\n",
      "train loss:0.1404595117610832\n",
      "train loss:0.18640411242089935\n",
      "train loss:0.24263579569461025\n",
      "train loss:0.1217938813021083\n",
      "train loss:0.1249760310548249\n",
      "train loss:0.12465090749006075\n",
      "train loss:0.11158469407087047\n",
      "train loss:0.17190469022192242\n",
      "train loss:0.1950116711667513\n",
      "train loss:0.1267942919617048\n",
      "train loss:0.058494798699795514\n",
      "train loss:0.1922648914888768\n",
      "train loss:0.23189592207716583\n",
      "train loss:0.18096012165176747\n",
      "train loss:0.12349235780253923\n",
      "train loss:0.1426186856401496\n",
      "train loss:0.2587226738838957\n",
      "train loss:0.0934652017045892\n",
      "train loss:0.24194000369929775\n",
      "train loss:0.25194247953595567\n",
      "train loss:0.18256926421354625\n",
      "train loss:0.1588927062190789\n",
      "train loss:0.14306626584025225\n",
      "train loss:0.16982208851727307\n",
      "train loss:0.15347148954960854\n",
      "train loss:0.1105416626135897\n",
      "train loss:0.15057150432917313\n",
      "train loss:0.1602618650174023\n",
      "train loss:0.0692816852823131\n",
      "train loss:0.18180583446901705\n",
      "train loss:0.12753095119707433\n",
      "train loss:0.1278090189383187\n",
      "train loss:0.1942392715742163\n",
      "train loss:0.16859348425697662\n",
      "train loss:0.13014981661730363\n",
      "train loss:0.09901535663302707\n",
      "train loss:0.17448676013760311\n",
      "train loss:0.15398953167122495\n",
      "train loss:0.1970263965495418\n",
      "train loss:0.1514929216978991\n",
      "train loss:0.2026724255920124\n",
      "train loss:0.2231039841280456\n",
      "train loss:0.17532100965345013\n",
      "train loss:0.13947719655478116\n",
      "train loss:0.16882993600225515\n",
      "train loss:0.2332267672153308\n",
      "train loss:0.1302850314073601\n",
      "train loss:0.15963170180414538\n",
      "train loss:0.15373910764590504\n",
      "train loss:0.17766750412609864\n",
      "train loss:0.11968795438204237\n",
      "train loss:0.10424482748965186\n",
      "train loss:0.12314583317436455\n",
      "train loss:0.0925292055104385\n",
      "train loss:0.1785841527537886\n",
      "train loss:0.07556587175007773\n",
      "train loss:0.22374682602259757\n",
      "train loss:0.16764880095713872\n",
      "train loss:0.1764797677895633\n",
      "train loss:0.2380973095444375\n",
      "train loss:0.2340025627822626\n",
      "train loss:0.1099394889231858\n",
      "train loss:0.12061181771458525\n",
      "train loss:0.10456318372282368\n",
      "train loss:0.17211245732929217\n",
      "train loss:0.11646040670213953\n",
      "train loss:0.14490492615834602\n",
      "train loss:0.16770668813783302\n",
      "train loss:0.11318547264811592\n",
      "train loss:0.2013986381444569\n",
      "train loss:0.12058406992010917\n",
      "train loss:0.10101960096946633\n",
      "train loss:0.19778679879274955\n",
      "train loss:0.1613657612621853\n",
      "train loss:0.2057004727430712\n",
      "train loss:0.1811288585787364\n",
      "train loss:0.12595037375535037\n",
      "train loss:0.1677981510165369\n",
      "train loss:0.1203126132494131\n",
      "train loss:0.1994172204540418\n",
      "train loss:0.21939927703759388\n",
      "train loss:0.09869406180475776\n",
      "train loss:0.1356655838290582\n",
      "train loss:0.1534681024138942\n",
      "train loss:0.1803903964351732\n",
      "train loss:0.10656324476995996\n",
      "train loss:0.15431960594889757\n",
      "train loss:0.10141608142765401\n",
      "train loss:0.25676050974861275\n",
      "train loss:0.09579965857564694\n",
      "train loss:0.15997338204582454\n",
      "train loss:0.08159440011675223\n",
      "train loss:0.13532315312175858\n",
      "train loss:0.1518416286644357\n",
      "train loss:0.14421189496277168\n",
      "train loss:0.14459720449945385\n",
      "train loss:0.08472731987909993\n",
      "train loss:0.11122167337644052\n",
      "train loss:0.25814871722423516\n",
      "train loss:0.2656978480556484\n",
      "train loss:0.16339368319857808\n",
      "train loss:0.2321473946352159\n",
      "train loss:0.16101311214826147\n",
      "train loss:0.09230820406730976\n",
      "train loss:0.14671821275346636\n",
      "train loss:0.09367236369538501\n",
      "train loss:0.11589304110694394\n",
      "train loss:0.15541253242406092\n",
      "train loss:0.15532072195020008\n",
      "train loss:0.10828812834627376\n",
      "train loss:0.13346089909752307\n",
      "train loss:0.1619984542297394\n",
      "train loss:0.19366782328891585\n",
      "train loss:0.12706701871599427\n",
      "train loss:0.24608214822404434\n",
      "train loss:0.12739380580275383\n",
      "train loss:0.1869425763684425\n",
      "train loss:0.18451346422921944\n",
      "train loss:0.14544369692118903\n",
      "train loss:0.15063871945726012\n",
      "train loss:0.10211342400798445\n",
      "train loss:0.23452682689960344\n",
      "train loss:0.08911412389328427\n",
      "train loss:0.16653576858860583\n",
      "train loss:0.0594678177989486\n",
      "train loss:0.16890307878083252\n",
      "train loss:0.12877937118434052\n",
      "train loss:0.12190778743023463\n",
      "train loss:0.0552184546528687\n",
      "train loss:0.3951805815729436\n",
      "train loss:0.23607425194736045\n",
      "train loss:0.12398685259796262\n",
      "train loss:0.1912514277169069\n",
      "train loss:0.25010444523215214\n",
      "train loss:0.18094344484398836\n",
      "train loss:0.2650088916124315\n",
      "train loss:0.13223680563594517\n",
      "train loss:0.08436191047303426\n",
      "train loss:0.20361480247872585\n",
      "train loss:0.1409550566244528\n",
      "train loss:0.08734297282518527\n",
      "train loss:0.13019929514238324\n",
      "train loss:0.09871146736286499\n",
      "train loss:0.16581590989773598\n",
      "train loss:0.13542251071009848\n",
      "train loss:0.13490018180107544\n",
      "train loss:0.159901462545074\n",
      "train loss:0.10833556564732229\n",
      "train loss:0.15352784842942782\n",
      "train loss:0.1519060178816267\n",
      "train loss:0.13913004124621\n",
      "train loss:0.15146118528180344\n",
      "train loss:0.1861110365029118\n",
      "train loss:0.10307544344513046\n",
      "train loss:0.2165229403504028\n",
      "train loss:0.13832385166315225\n",
      "=== epoch:9, train acc:0.95, test acc:0.906 ===\n",
      "train loss:0.27028425572275416\n",
      "train loss:0.11210703644858704\n",
      "train loss:0.10854071643024905\n",
      "train loss:0.0954082113718635\n",
      "train loss:0.16395922784385022\n",
      "train loss:0.12155098306387589\n",
      "train loss:0.18022736235423842\n",
      "train loss:0.12456385399412341\n",
      "train loss:0.16536650138118028\n",
      "train loss:0.09994048403428595\n",
      "train loss:0.2177610291429649\n",
      "train loss:0.08362341891320298\n",
      "train loss:0.14498502346708336\n",
      "train loss:0.2010949342789103\n",
      "train loss:0.18458917307561076\n",
      "train loss:0.12800874436892704\n",
      "train loss:0.18085241565000743\n",
      "train loss:0.23678420969145283\n",
      "train loss:0.301227018080445\n",
      "train loss:0.13960252106468343\n",
      "train loss:0.11188780734121108\n",
      "train loss:0.12792512841347445\n",
      "train loss:0.19958362256221154\n",
      "train loss:0.05256803227486127\n",
      "train loss:0.11140350133564894\n",
      "train loss:0.14617526559449934\n",
      "train loss:0.1589508247889904\n",
      "train loss:0.16569957262726145\n",
      "train loss:0.1822154441081266\n",
      "train loss:0.09885212345973354\n",
      "train loss:0.3004095347746031\n",
      "train loss:0.07185512639268903\n",
      "train loss:0.12147152537378095\n",
      "train loss:0.17055074879652882\n",
      "train loss:0.13888706053419647\n",
      "train loss:0.23360437074786183\n",
      "train loss:0.1301736585812835\n",
      "train loss:0.19139425168214758\n",
      "train loss:0.1192461052673786\n",
      "train loss:0.15452427882812864\n",
      "train loss:0.20462571545324856\n",
      "train loss:0.23660598207308398\n",
      "train loss:0.13878391106395818\n",
      "train loss:0.1874615115999807\n",
      "train loss:0.22443762184412108\n",
      "train loss:0.13974955211957105\n",
      "train loss:0.06305487980901649\n",
      "train loss:0.2652771805674758\n",
      "train loss:0.12706700023466108\n",
      "train loss:0.0942977757382961\n",
      "train loss:0.09369073849592052\n",
      "train loss:0.13450608945489406\n",
      "train loss:0.24519412471648871\n",
      "train loss:0.11516803010982732\n",
      "train loss:0.19954124650189142\n",
      "train loss:0.18865234237095424\n",
      "train loss:0.16631814068538373\n",
      "train loss:0.16923161078874238\n",
      "train loss:0.11364278413966364\n",
      "train loss:0.2724644065047261\n",
      "train loss:0.11390824273321164\n",
      "train loss:0.140441080467974\n",
      "train loss:0.1635349696323889\n",
      "train loss:0.16022084925495164\n",
      "train loss:0.0771595591368078\n",
      "train loss:0.14301629641829788\n",
      "train loss:0.24677141529265442\n",
      "train loss:0.11971560456978604\n",
      "train loss:0.15235023062961983\n",
      "train loss:0.2280843593412806\n",
      "train loss:0.11005368929815557\n",
      "train loss:0.14536149006069046\n",
      "train loss:0.12278061261183357\n",
      "train loss:0.194497394065579\n",
      "train loss:0.16845607619894978\n",
      "train loss:0.13149825704284204\n",
      "train loss:0.16717133191503297\n",
      "train loss:0.1627629623537088\n",
      "train loss:0.13700588727952176\n",
      "train loss:0.27375842952654256\n",
      "train loss:0.11202916118567284\n",
      "train loss:0.0764522039829816\n",
      "train loss:0.1250579621660024\n",
      "train loss:0.11547450917157497\n",
      "train loss:0.09845829800257827\n",
      "train loss:0.27131998674297864\n",
      "train loss:0.1459981631471169\n",
      "train loss:0.21623918687668808\n",
      "train loss:0.19326307198774095\n",
      "train loss:0.140359001402615\n",
      "train loss:0.10451893862274687\n",
      "train loss:0.17824909875048667\n",
      "train loss:0.12332303137662785\n",
      "train loss:0.12365188773385771\n",
      "train loss:0.14802310736644145\n",
      "train loss:0.0731878080026526\n",
      "train loss:0.15442345132830046\n",
      "train loss:0.25629455206060153\n",
      "train loss:0.18651245440955655\n",
      "train loss:0.17220581897354076\n",
      "train loss:0.18957846562144443\n",
      "train loss:0.15749032745691122\n",
      "train loss:0.11317032039246622\n",
      "train loss:0.2321151333320436\n",
      "train loss:0.12071905539031884\n",
      "train loss:0.20663274550253216\n",
      "train loss:0.16110053845543637\n",
      "train loss:0.14596101604406345\n",
      "train loss:0.1523956825665502\n",
      "train loss:0.1289430950752392\n",
      "train loss:0.13021055053944444\n",
      "train loss:0.14277410991149525\n",
      "train loss:0.15497054774595412\n",
      "train loss:0.18969951059044668\n",
      "train loss:0.15607640800352196\n",
      "train loss:0.09112608832339149\n",
      "train loss:0.12132230038792102\n",
      "train loss:0.12987425271284805\n",
      "train loss:0.18635276867877007\n",
      "train loss:0.221031462455159\n",
      "train loss:0.08259507166942726\n",
      "train loss:0.22438463288091304\n",
      "train loss:0.1557648942302915\n",
      "train loss:0.22758532645214388\n",
      "train loss:0.11145706946662493\n",
      "train loss:0.1332317389108333\n",
      "train loss:0.12828983956936887\n",
      "train loss:0.13636505960020323\n",
      "train loss:0.1759142851385092\n",
      "train loss:0.11717854084725385\n",
      "train loss:0.13539493003484393\n",
      "train loss:0.19968607749299053\n",
      "train loss:0.1151103957782278\n",
      "train loss:0.18637257516196204\n",
      "train loss:0.1567645385253777\n",
      "train loss:0.138518660683849\n",
      "train loss:0.05425448914565232\n",
      "train loss:0.22293782723235075\n",
      "train loss:0.10293601886977541\n",
      "train loss:0.20982958733034665\n",
      "train loss:0.11572500312599138\n",
      "train loss:0.14555417835839388\n",
      "train loss:0.10854422770081264\n",
      "train loss:0.10956526964158668\n",
      "train loss:0.19846040915989918\n",
      "train loss:0.11348092950164614\n",
      "train loss:0.2090668511504651\n",
      "train loss:0.14104147451114177\n",
      "train loss:0.1603315097229646\n",
      "train loss:0.18703714021263443\n",
      "train loss:0.07584733348999448\n",
      "train loss:0.1050419391438066\n",
      "train loss:0.05939955535416269\n",
      "train loss:0.22599347101088835\n",
      "train loss:0.2636014206946959\n",
      "train loss:0.07952844671498278\n",
      "train loss:0.14490249484692197\n",
      "train loss:0.11428780033318045\n",
      "train loss:0.1719579978280298\n",
      "train loss:0.14983734392793902\n",
      "train loss:0.09907323584298404\n",
      "train loss:0.1531132263106048\n",
      "train loss:0.1271783906322067\n",
      "train loss:0.1848177462090482\n",
      "train loss:0.1541958223337826\n",
      "train loss:0.24110930620098678\n",
      "train loss:0.10118577472456625\n",
      "train loss:0.0818206771435951\n",
      "train loss:0.1557637544615749\n",
      "train loss:0.09619573983590923\n",
      "train loss:0.0659109913426446\n",
      "train loss:0.15081816645570056\n",
      "train loss:0.1329650034735318\n",
      "train loss:0.10562166576505495\n",
      "train loss:0.10722763483730825\n",
      "train loss:0.09675840319197283\n",
      "train loss:0.1193567996548874\n",
      "train loss:0.09537875805360763\n",
      "train loss:0.09925548494222446\n",
      "train loss:0.12634216531425155\n",
      "train loss:0.16783402601216796\n",
      "train loss:0.18063441822502757\n",
      "train loss:0.09376042975081379\n",
      "train loss:0.10728673065680176\n",
      "train loss:0.16554932597402153\n",
      "train loss:0.0834753843470477\n",
      "train loss:0.22334576738241968\n",
      "train loss:0.16445001560999636\n",
      "train loss:0.1514761738745576\n",
      "train loss:0.32205585641190765\n",
      "train loss:0.1153290287423262\n",
      "train loss:0.08198384998910967\n",
      "train loss:0.16917773029265848\n",
      "train loss:0.08320114344997286\n",
      "train loss:0.14238190245194024\n",
      "train loss:0.19705510514162064\n",
      "train loss:0.08872255200548114\n",
      "train loss:0.10893145813269708\n",
      "train loss:0.2817010615007408\n",
      "train loss:0.18239147738655617\n",
      "train loss:0.1568958814902502\n",
      "train loss:0.16514286256137947\n",
      "train loss:0.12174583854631255\n",
      "train loss:0.17664961779131702\n",
      "train loss:0.15624155890786992\n",
      "train loss:0.13688135062282403\n",
      "train loss:0.1673904229870119\n",
      "train loss:0.14430514591420165\n",
      "train loss:0.09616046479989661\n",
      "train loss:0.18022663712463116\n",
      "train loss:0.09221732399573375\n",
      "train loss:0.25721826188735675\n",
      "train loss:0.17632307309604467\n",
      "train loss:0.07349664185557275\n",
      "train loss:0.1390348113535634\n",
      "train loss:0.08358991606059728\n",
      "train loss:0.2152935199083269\n",
      "train loss:0.13164706694895148\n",
      "train loss:0.15749969205758665\n",
      "train loss:0.17073232272243502\n",
      "train loss:0.17165429550223674\n",
      "train loss:0.11497790443209505\n",
      "train loss:0.12159989197728838\n",
      "train loss:0.15534273041514715\n",
      "train loss:0.1456427982946584\n",
      "train loss:0.15647146385359195\n",
      "train loss:0.15598702902817443\n",
      "train loss:0.1332661920892386\n",
      "train loss:0.1336909848565937\n",
      "train loss:0.13257317518811573\n",
      "train loss:0.23248114429535838\n",
      "train loss:0.19650264876845397\n",
      "train loss:0.16931559524633166\n",
      "train loss:0.17062776582812378\n",
      "train loss:0.11914815029241979\n",
      "train loss:0.161415815679252\n",
      "train loss:0.1901092358353192\n",
      "train loss:0.10244271466907094\n",
      "train loss:0.21423854272317105\n",
      "train loss:0.23881851270674784\n",
      "train loss:0.17015295226499777\n",
      "train loss:0.08694512557242069\n",
      "train loss:0.27864338723585047\n",
      "train loss:0.12957848633632657\n",
      "train loss:0.15989234185363171\n",
      "train loss:0.19873586043628905\n",
      "train loss:0.15697396251795548\n",
      "train loss:0.2273373497782484\n",
      "train loss:0.1046056181965555\n",
      "train loss:0.21687238391915492\n",
      "train loss:0.14133076072319428\n",
      "train loss:0.17342167374659823\n",
      "train loss:0.15414626408936677\n",
      "train loss:0.15918296691244957\n",
      "train loss:0.1270768558821517\n",
      "train loss:0.11784433301829661\n",
      "train loss:0.14020904788577743\n",
      "train loss:0.10912348827823574\n",
      "train loss:0.1780918286822743\n",
      "train loss:0.12670540598475133\n",
      "train loss:0.1848114639678571\n",
      "train loss:0.1816619416653791\n",
      "train loss:0.12615385177397923\n",
      "train loss:0.10290250424263479\n",
      "train loss:0.09740075727929265\n",
      "train loss:0.2606655426994897\n",
      "train loss:0.19167368491689232\n",
      "train loss:0.12980671565509636\n",
      "train loss:0.15287979403307905\n",
      "train loss:0.126445198690205\n",
      "train loss:0.18033545597761708\n",
      "train loss:0.14366404742109323\n",
      "train loss:0.19988370463271285\n",
      "train loss:0.12725665333905625\n",
      "train loss:0.13754390301695218\n",
      "train loss:0.13354850338536906\n",
      "train loss:0.27352850240179927\n",
      "train loss:0.22698681306185403\n",
      "train loss:0.22824719632768162\n",
      "train loss:0.18109892707702166\n",
      "train loss:0.11274306173705594\n",
      "train loss:0.08337838378226882\n",
      "train loss:0.1518433674622868\n",
      "train loss:0.156895802989668\n",
      "train loss:0.12488261922225606\n",
      "train loss:0.19960000414372306\n",
      "train loss:0.08055696355557479\n",
      "train loss:0.18386784768307549\n",
      "train loss:0.12343867962935469\n",
      "train loss:0.11451991202057908\n",
      "train loss:0.09890974445890827\n",
      "train loss:0.16970862588917665\n",
      "train loss:0.14996204940328955\n",
      "train loss:0.10633203170201648\n",
      "train loss:0.11757814069259481\n",
      "train loss:0.051204235373786294\n",
      "train loss:0.10684660813671941\n",
      "train loss:0.21220056444529922\n",
      "train loss:0.05021956490558743\n",
      "train loss:0.08588064798713692\n",
      "train loss:0.14097270252972394\n",
      "train loss:0.14725500665547378\n",
      "train loss:0.14409289488819493\n",
      "train loss:0.08669631528629211\n",
      "train loss:0.11145897138680264\n",
      "train loss:0.0965384559193606\n",
      "train loss:0.18411166412980903\n",
      "train loss:0.18932018277532972\n",
      "train loss:0.24380044077996224\n",
      "train loss:0.15373072082892192\n",
      "train loss:0.13542038608841916\n",
      "train loss:0.09917688395762092\n",
      "train loss:0.13822240573728334\n",
      "train loss:0.20283682542544906\n",
      "train loss:0.0856714035625157\n",
      "train loss:0.18035398424234228\n",
      "train loss:0.16201964569191715\n",
      "train loss:0.11232265145064503\n",
      "train loss:0.1366488432272563\n",
      "train loss:0.1313235583445655\n",
      "train loss:0.22303568852743066\n",
      "train loss:0.07698185377624282\n",
      "train loss:0.16128448967419806\n",
      "train loss:0.2475988081755047\n",
      "train loss:0.13787534773879945\n",
      "train loss:0.0746847201061986\n",
      "train loss:0.0771863046896344\n",
      "train loss:0.15391644058190118\n",
      "train loss:0.16094376246915076\n",
      "train loss:0.21302263654057846\n",
      "train loss:0.15115763222262504\n",
      "train loss:0.25494837740147136\n",
      "train loss:0.16514423428915545\n",
      "train loss:0.11165365483593302\n",
      "train loss:0.18735719500035944\n",
      "train loss:0.10146960759571338\n",
      "train loss:0.18223013218606357\n",
      "train loss:0.10211846154709572\n",
      "train loss:0.13530336951138205\n",
      "train loss:0.09133503246915722\n",
      "train loss:0.16414982122355387\n",
      "train loss:0.07837872111818737\n",
      "train loss:0.10660486843690699\n",
      "train loss:0.09851694331069949\n",
      "train loss:0.0789393278993848\n",
      "train loss:0.22482375520537748\n",
      "train loss:0.16974940997539292\n",
      "train loss:0.09754656032673316\n",
      "train loss:0.04578585176948896\n",
      "train loss:0.1553446987018159\n",
      "train loss:0.14464036290846294\n",
      "train loss:0.17380553327368592\n",
      "train loss:0.1386035350795814\n",
      "train loss:0.10295003179435308\n",
      "train loss:0.17784232887198675\n",
      "train loss:0.17599242608767313\n",
      "train loss:0.13195705265755497\n",
      "train loss:0.14771127326942454\n",
      "train loss:0.18467846200242138\n",
      "train loss:0.0891365139275387\n",
      "train loss:0.11108699080469712\n",
      "train loss:0.09926243715047751\n",
      "train loss:0.2091593447846353\n",
      "train loss:0.1413249769190823\n",
      "train loss:0.07921002891681217\n",
      "train loss:0.14579886166500458\n",
      "train loss:0.11843459706639138\n",
      "train loss:0.23647244373167864\n",
      "train loss:0.13229829911732333\n",
      "train loss:0.12889869451723465\n",
      "train loss:0.07501447785071927\n",
      "train loss:0.07897553605598343\n",
      "train loss:0.16153848078558994\n",
      "train loss:0.12000723938924032\n",
      "train loss:0.13686893822640314\n",
      "train loss:0.18385328422068933\n",
      "train loss:0.2065067382327655\n",
      "train loss:0.09420385466600249\n",
      "train loss:0.1636517440367775\n",
      "train loss:0.07357035193208757\n",
      "train loss:0.1376127509998305\n",
      "train loss:0.09058076113027318\n",
      "train loss:0.1590919349686006\n",
      "train loss:0.1870247433281018\n",
      "train loss:0.1275228298222199\n",
      "train loss:0.11677504727242749\n",
      "train loss:0.11526011402591975\n",
      "train loss:0.15010395923452868\n",
      "train loss:0.051239057722214085\n",
      "train loss:0.11900244697817451\n",
      "train loss:0.17425933728980383\n",
      "train loss:0.07474021782792158\n",
      "train loss:0.13446387248608335\n",
      "train loss:0.20411403660709257\n",
      "train loss:0.11033877557607152\n",
      "train loss:0.14925525159088548\n",
      "train loss:0.16469602698995484\n",
      "train loss:0.12561350830593518\n",
      "train loss:0.1443047850512754\n",
      "train loss:0.06527863401899023\n",
      "train loss:0.17133430104789518\n",
      "train loss:0.05331104586669182\n",
      "train loss:0.16202542962697428\n",
      "train loss:0.2103092263898585\n",
      "train loss:0.17977762130511882\n",
      "train loss:0.1078189395170768\n",
      "train loss:0.1663029923389981\n",
      "train loss:0.12244232127580787\n",
      "train loss:0.26174954741789735\n",
      "train loss:0.2673170577327316\n",
      "train loss:0.16191018391721998\n",
      "train loss:0.07635990580889061\n",
      "train loss:0.14111483422555482\n",
      "train loss:0.20360636381144037\n",
      "train loss:0.17919209990466867\n",
      "train loss:0.11715236786491241\n",
      "train loss:0.22655198834482135\n",
      "train loss:0.15284394940810223\n",
      "train loss:0.1506837794519186\n",
      "train loss:0.1529344296490275\n",
      "train loss:0.10700999723084617\n",
      "train loss:0.12225058005675363\n",
      "train loss:0.19035011925325232\n",
      "train loss:0.10520330261137069\n",
      "train loss:0.13393392079568797\n",
      "train loss:0.10145857105319435\n",
      "train loss:0.20195895884559242\n",
      "train loss:0.08558324159928846\n",
      "train loss:0.19245415824362758\n",
      "train loss:0.20605498603993752\n",
      "train loss:0.1331502019432863\n",
      "train loss:0.13734824790450742\n",
      "train loss:0.15575885106690293\n",
      "train loss:0.10047339859183342\n",
      "train loss:0.11366046593011485\n",
      "train loss:0.1364856073610599\n",
      "train loss:0.25195147120871164\n",
      "train loss:0.17168111587622248\n",
      "train loss:0.1848802826679487\n",
      "train loss:0.11424941053781368\n",
      "train loss:0.08770618104626003\n",
      "train loss:0.1325696342034934\n",
      "train loss:0.09462878944072366\n",
      "train loss:0.11969672156534372\n",
      "train loss:0.1624461442821572\n",
      "train loss:0.17735254850787358\n",
      "train loss:0.10358619080254881\n",
      "train loss:0.21975077611710975\n",
      "train loss:0.1784867866513822\n",
      "train loss:0.09898495074623533\n",
      "train loss:0.17732516974103743\n",
      "train loss:0.07586076622498775\n",
      "train loss:0.10678451026251051\n",
      "train loss:0.13979097239676885\n",
      "train loss:0.18103846684420216\n",
      "train loss:0.08953376744561352\n",
      "train loss:0.14511956980817187\n",
      "train loss:0.053005162969666154\n",
      "train loss:0.23417064730428752\n",
      "train loss:0.1176616539951786\n",
      "train loss:0.09219019824231546\n",
      "train loss:0.11864100754770891\n",
      "train loss:0.1155734909500469\n",
      "train loss:0.08732714794529123\n",
      "train loss:0.13835256674052535\n",
      "train loss:0.1908928748267062\n",
      "train loss:0.10923012175434305\n",
      "train loss:0.22417456103952685\n",
      "train loss:0.15834647887108064\n",
      "train loss:0.09357935485875808\n",
      "train loss:0.15055616959939366\n",
      "train loss:0.1174593019184328\n",
      "train loss:0.14923690206628848\n",
      "train loss:0.08960260947919339\n",
      "train loss:0.20107891378432632\n",
      "train loss:0.06540935212327151\n",
      "train loss:0.06058057552598171\n",
      "train loss:0.1142463266526476\n",
      "train loss:0.23175582554574461\n",
      "train loss:0.11890779714272323\n",
      "train loss:0.1764791395916771\n",
      "train loss:0.13428775057516038\n",
      "train loss:0.08181701054151104\n",
      "train loss:0.07996142917648853\n",
      "train loss:0.10382747955871557\n",
      "train loss:0.06718281055518031\n",
      "train loss:0.13854824949843203\n",
      "train loss:0.16595435592869148\n",
      "train loss:0.1697589130128558\n",
      "train loss:0.11341548451726853\n",
      "train loss:0.10211531431251135\n",
      "train loss:0.21415506203534765\n",
      "train loss:0.035705379322372395\n",
      "train loss:0.1775346884638309\n",
      "train loss:0.09449144818736901\n",
      "train loss:0.10949785432980916\n",
      "train loss:0.13735576092889054\n",
      "train loss:0.13564332962420309\n",
      "train loss:0.1504359115971793\n",
      "train loss:0.12988387923847666\n",
      "train loss:0.13693426346804644\n",
      "train loss:0.09984703111624384\n",
      "train loss:0.12563603814202484\n",
      "train loss:0.12747696013240076\n",
      "train loss:0.18388241333805916\n",
      "train loss:0.15197821112263138\n",
      "train loss:0.15225502180418105\n",
      "train loss:0.0714699600809651\n",
      "train loss:0.19036661464564505\n",
      "train loss:0.2220465616716919\n",
      "train loss:0.12378978014813474\n",
      "train loss:0.14243080279452675\n",
      "train loss:0.19853407698800868\n",
      "train loss:0.14810234584507775\n",
      "train loss:0.07310827745699369\n",
      "train loss:0.12072563232515712\n",
      "train loss:0.20173861538556973\n",
      "train loss:0.1842977427929965\n",
      "train loss:0.16733076919035278\n",
      "train loss:0.13072275077437348\n",
      "train loss:0.12515397146879684\n",
      "train loss:0.09014979073742774\n",
      "train loss:0.21075977356058606\n",
      "train loss:0.23624601516247903\n",
      "train loss:0.1396431230575462\n",
      "train loss:0.22189075640627487\n",
      "train loss:0.17339296425597842\n",
      "train loss:0.127052861131012\n",
      "train loss:0.1116942222271608\n",
      "train loss:0.08871140625995108\n",
      "train loss:0.1520939075282952\n",
      "train loss:0.06153655029940563\n",
      "train loss:0.14508368307006939\n",
      "train loss:0.2361842502054582\n",
      "train loss:0.232926894069665\n",
      "train loss:0.19256987008124998\n",
      "train loss:0.16282555557326345\n",
      "train loss:0.10416611586613544\n",
      "train loss:0.09690685516880947\n",
      "train loss:0.14704612386357102\n",
      "train loss:0.18941201761539148\n",
      "train loss:0.1689040139848184\n",
      "train loss:0.08538795572512052\n",
      "train loss:0.14613935142575177\n",
      "train loss:0.15788851505643664\n",
      "train loss:0.09041794413359344\n",
      "train loss:0.0983120091946888\n",
      "train loss:0.1024365849669438\n",
      "train loss:0.170003290256839\n",
      "train loss:0.10276154657377118\n",
      "train loss:0.1429799818007764\n",
      "train loss:0.09357621229128772\n",
      "train loss:0.12346560641516682\n",
      "train loss:0.20379012098684296\n",
      "train loss:0.07150989751548308\n",
      "train loss:0.2208459545870649\n",
      "train loss:0.05563141262138327\n",
      "train loss:0.14065864639344836\n",
      "train loss:0.14872539974768806\n",
      "train loss:0.15566028843864194\n",
      "train loss:0.11057581804923323\n",
      "train loss:0.058362156378131545\n",
      "train loss:0.12388039591235847\n",
      "train loss:0.15224173562903145\n",
      "train loss:0.14847659622897527\n",
      "train loss:0.07158613658740685\n",
      "train loss:0.2646739538448281\n",
      "train loss:0.15028520089763187\n",
      "train loss:0.0645066599186328\n",
      "train loss:0.17592013527913525\n",
      "train loss:0.19497539859323634\n",
      "train loss:0.08601604153079365\n",
      "train loss:0.10414121137800465\n",
      "train loss:0.20949354644000961\n",
      "train loss:0.18781087873830585\n",
      "train loss:0.17614176181883784\n",
      "train loss:0.1994459923420998\n",
      "train loss:0.11380517184597627\n",
      "train loss:0.1175608214032745\n",
      "train loss:0.11949830438753413\n",
      "train loss:0.11073569867315083\n",
      "train loss:0.07663930405519916\n",
      "train loss:0.12874866106511704\n",
      "train loss:0.1687570408170846\n",
      "train loss:0.13687853433208902\n",
      "train loss:0.15420981249814714\n",
      "train loss:0.1866035117644983\n",
      "train loss:0.13209425291045712\n",
      "train loss:0.07431034788002408\n",
      "train loss:0.15632819008792864\n",
      "train loss:0.22926833371913335\n",
      "train loss:0.1366635084973473\n",
      "train loss:0.15003322055919335\n",
      "train loss:0.15058770469186478\n",
      "train loss:0.10128444910643869\n",
      "train loss:0.0590360882123025\n",
      "train loss:0.11187908331833865\n",
      "train loss:0.13340655856561376\n",
      "train loss:0.12672442780594625\n",
      "train loss:0.19335756012212243\n",
      "=== epoch:10, train acc:0.942, test acc:0.902 ===\n",
      "train loss:0.17099414424918524\n",
      "train loss:0.15047854490543677\n",
      "train loss:0.12102947865928489\n",
      "train loss:0.04512540106140741\n",
      "train loss:0.12218035318325518\n",
      "train loss:0.10787764208509505\n",
      "train loss:0.141507130472882\n",
      "train loss:0.10969743580315669\n",
      "train loss:0.1099978458890646\n",
      "train loss:0.18134809242055389\n",
      "train loss:0.09293267668657036\n",
      "train loss:0.22529370860647663\n",
      "train loss:0.11966217148031089\n",
      "train loss:0.14453155398769912\n",
      "train loss:0.12513289537760325\n",
      "train loss:0.11175037764777915\n",
      "train loss:0.26307060087563783\n",
      "train loss:0.1282264906528326\n",
      "train loss:0.18141898268943513\n",
      "train loss:0.19597951045482018\n",
      "train loss:0.09628242803896774\n",
      "train loss:0.17004567750790325\n",
      "train loss:0.1398342652096919\n",
      "train loss:0.19872969367827778\n",
      "train loss:0.12571262803404035\n",
      "train loss:0.11880057721119577\n",
      "train loss:0.2036419924230658\n",
      "train loss:0.1012240144389904\n",
      "train loss:0.15889132675638593\n",
      "train loss:0.1726954776230316\n",
      "train loss:0.19204983466899136\n",
      "train loss:0.13406608893207242\n",
      "train loss:0.1547208717997863\n",
      "train loss:0.14087796552738233\n",
      "train loss:0.12668621190900045\n",
      "train loss:0.06857003607577203\n",
      "train loss:0.1308201171880417\n",
      "train loss:0.20924369517345526\n",
      "train loss:0.21273290703331452\n",
      "train loss:0.13017970235893156\n",
      "train loss:0.09869625738194232\n",
      "train loss:0.12154053543197461\n",
      "train loss:0.10071183681774229\n",
      "train loss:0.11938237647647253\n",
      "train loss:0.1094924598021491\n",
      "train loss:0.14586450018766\n",
      "train loss:0.1147774726748866\n",
      "train loss:0.19965085577730762\n",
      "train loss:0.10438545156574586\n",
      "train loss:0.11457714963200287\n",
      "train loss:0.07461333621462564\n",
      "train loss:0.15386973865584871\n",
      "train loss:0.09125878469068661\n",
      "train loss:0.12079414980251318\n",
      "train loss:0.1788740174427231\n",
      "train loss:0.1616608615425746\n",
      "train loss:0.13874299435857662\n",
      "train loss:0.22425525126703977\n",
      "train loss:0.12145557187524822\n",
      "train loss:0.15588050132810047\n",
      "train loss:0.10669112664260749\n",
      "train loss:0.19642841720653478\n",
      "train loss:0.11394600686165283\n",
      "train loss:0.10639399856248065\n",
      "train loss:0.09578152086572202\n",
      "train loss:0.13632281235781707\n",
      "train loss:0.18131684582622065\n",
      "train loss:0.1511195321969526\n",
      "train loss:0.11561891979768182\n",
      "train loss:0.15260396363778253\n",
      "train loss:0.11140202514446544\n",
      "train loss:0.264248558207614\n",
      "train loss:0.09854169645684376\n",
      "train loss:0.08720523907685865\n",
      "train loss:0.09272328877589026\n",
      "train loss:0.07448864738329207\n",
      "train loss:0.11630759202940064\n",
      "train loss:0.08136459506324786\n",
      "train loss:0.17003601628511728\n",
      "train loss:0.13229092310660795\n",
      "train loss:0.06630096402348844\n",
      "train loss:0.12918841221784955\n",
      "train loss:0.1525570480404226\n",
      "train loss:0.1893579187583084\n",
      "train loss:0.06622845931716166\n",
      "train loss:0.12400577826774019\n",
      "train loss:0.14765823972622352\n",
      "train loss:0.13946484763980632\n",
      "train loss:0.10111319008549353\n",
      "train loss:0.07777493392079045\n",
      "train loss:0.13697810796326965\n",
      "train loss:0.12059268584712451\n",
      "train loss:0.16159809248395654\n",
      "train loss:0.10045363872673882\n",
      "train loss:0.1844032703381605\n",
      "train loss:0.12212373163537892\n",
      "train loss:0.12193994088516127\n",
      "train loss:0.15493926436852612\n",
      "train loss:0.08867988935543933\n",
      "train loss:0.09965789800537755\n",
      "train loss:0.1589047344944782\n",
      "train loss:0.09045859490746996\n",
      "train loss:0.09836944923438243\n",
      "train loss:0.07854459742268399\n",
      "train loss:0.21627890858669502\n",
      "train loss:0.122270789416365\n",
      "train loss:0.04987820670607786\n",
      "train loss:0.09512493217332574\n",
      "train loss:0.08154433453186724\n",
      "train loss:0.08318752742802608\n",
      "train loss:0.112842139228591\n",
      "train loss:0.18452860037819768\n",
      "train loss:0.09853831391827535\n",
      "train loss:0.10917235859012096\n",
      "train loss:0.11695818752777293\n",
      "train loss:0.10130254339955398\n",
      "train loss:0.0898616206890636\n",
      "train loss:0.07633195094467561\n",
      "train loss:0.13308300443442028\n",
      "train loss:0.0743667378457317\n",
      "train loss:0.1880191902636825\n",
      "train loss:0.07770780282569317\n",
      "train loss:0.07615594995124508\n",
      "train loss:0.07871470151861844\n",
      "train loss:0.12993908703689205\n",
      "train loss:0.07790709838905595\n",
      "train loss:0.11316646947517991\n",
      "train loss:0.14553925522346142\n",
      "train loss:0.12888048087037857\n",
      "train loss:0.09654613304184732\n",
      "train loss:0.06549063701679544\n",
      "train loss:0.14826272639652158\n",
      "train loss:0.10826167081029445\n",
      "train loss:0.18628666948984945\n",
      "train loss:0.12868667927929522\n",
      "train loss:0.13501008842651616\n",
      "train loss:0.21308282156123948\n",
      "train loss:0.14149994727123547\n",
      "train loss:0.21801959913466612\n",
      "train loss:0.21683391289009163\n",
      "train loss:0.14644891537141727\n",
      "train loss:0.1430787842971822\n",
      "train loss:0.11228480483389092\n",
      "train loss:0.08949126192960824\n",
      "train loss:0.14311298126061592\n",
      "train loss:0.09134857987907197\n",
      "train loss:0.14533451282635515\n",
      "train loss:0.14029836204246687\n",
      "train loss:0.09036651955877412\n",
      "train loss:0.11284869862347886\n",
      "train loss:0.048813208889290284\n",
      "train loss:0.10848903672091578\n",
      "train loss:0.16579626516654286\n",
      "train loss:0.08336001555928252\n",
      "train loss:0.12272899976115022\n",
      "train loss:0.10326776177605922\n",
      "train loss:0.2017475522167798\n",
      "train loss:0.09651031914258583\n",
      "train loss:0.06635115221995055\n",
      "train loss:0.13568249151204803\n",
      "train loss:0.043602671139882164\n",
      "train loss:0.22215937319762846\n",
      "train loss:0.10509635618059168\n",
      "train loss:0.1845002832314919\n",
      "train loss:0.3411433399140703\n",
      "train loss:0.1213454120820162\n",
      "train loss:0.0944068707318455\n",
      "train loss:0.23489767744045434\n",
      "train loss:0.08426018111681494\n",
      "train loss:0.05046315005077941\n",
      "train loss:0.1943858801142211\n",
      "train loss:0.06525100444331206\n",
      "train loss:0.19243074232769317\n",
      "train loss:0.1292714557022731\n",
      "train loss:0.1132265061149802\n",
      "train loss:0.1036511474380003\n",
      "train loss:0.13593415560932465\n",
      "train loss:0.14815998145902706\n",
      "train loss:0.13257711570562303\n",
      "train loss:0.08097341583238844\n",
      "train loss:0.17305147191863554\n",
      "train loss:0.09531157498740846\n",
      "train loss:0.12597495538406042\n",
      "train loss:0.06657798505657907\n",
      "train loss:0.1471458228432775\n",
      "train loss:0.16685068619186844\n",
      "train loss:0.1645204516131661\n",
      "train loss:0.12598590374604735\n",
      "train loss:0.08607029836590946\n",
      "train loss:0.10828114876463085\n",
      "train loss:0.13245365445023136\n",
      "train loss:0.10449715068363792\n",
      "train loss:0.11915256727695223\n",
      "train loss:0.06566158396074659\n",
      "train loss:0.09270124517390727\n",
      "train loss:0.18022029462033318\n",
      "train loss:0.08673695677268656\n",
      "train loss:0.18683724255540604\n",
      "train loss:0.12047595344127132\n",
      "train loss:0.14545499262040085\n",
      "train loss:0.08776274539631332\n",
      "train loss:0.16397691095897282\n",
      "train loss:0.06650598978108507\n",
      "train loss:0.13071864481792056\n",
      "train loss:0.12907894065957526\n",
      "train loss:0.08344679959925233\n",
      "train loss:0.19334989895837307\n",
      "train loss:0.18840619273407214\n",
      "train loss:0.1467333624818205\n",
      "train loss:0.16795395372881733\n",
      "train loss:0.15950122692895907\n",
      "train loss:0.10672278346021924\n",
      "train loss:0.1015345597569339\n",
      "train loss:0.11682146824191647\n",
      "train loss:0.194064416992393\n",
      "train loss:0.12738783915308727\n",
      "train loss:0.20682501255428562\n",
      "train loss:0.10035360481205448\n",
      "train loss:0.18488759693497067\n",
      "train loss:0.1380763370003478\n",
      "train loss:0.09675864467611828\n",
      "train loss:0.052646446689025135\n",
      "train loss:0.14942461717885278\n",
      "train loss:0.1507880784649456\n",
      "train loss:0.16070801984856403\n",
      "train loss:0.11047698742676464\n",
      "train loss:0.1513271314577851\n",
      "train loss:0.2172282524134075\n",
      "train loss:0.18248613992781976\n",
      "train loss:0.12255807322910908\n",
      "train loss:0.14402897175500623\n",
      "train loss:0.1310067854199743\n",
      "train loss:0.115574834621998\n",
      "train loss:0.1017414303455336\n",
      "train loss:0.09953354275564799\n",
      "train loss:0.1509280581904403\n",
      "train loss:0.11619038059522165\n",
      "train loss:0.0513878264972144\n",
      "train loss:0.12913332233582012\n",
      "train loss:0.10066196598642066\n",
      "train loss:0.19496659436164657\n",
      "train loss:0.07412325574110108\n",
      "train loss:0.06231148633359009\n",
      "train loss:0.12581882089248844\n",
      "train loss:0.1001092867877285\n",
      "train loss:0.2398732945897715\n",
      "train loss:0.13911468336675942\n",
      "train loss:0.1676127463156267\n",
      "train loss:0.1073918526141531\n",
      "train loss:0.044139807303949424\n",
      "train loss:0.1334251307632682\n",
      "train loss:0.0880997453095223\n",
      "train loss:0.10292074562596505\n",
      "train loss:0.16736618728316544\n",
      "train loss:0.07315795260884846\n",
      "train loss:0.06126131622918293\n",
      "train loss:0.08541171688530229\n",
      "train loss:0.08309598831648611\n",
      "train loss:0.10433669047277043\n",
      "train loss:0.1075370928323305\n",
      "train loss:0.1685084613090514\n",
      "train loss:0.16541215902282325\n",
      "train loss:0.13087524206740223\n",
      "train loss:0.1367935692385655\n",
      "train loss:0.16361582977157646\n",
      "train loss:0.08335616822329571\n",
      "train loss:0.23043468601654454\n",
      "train loss:0.10972122023120985\n",
      "train loss:0.1488184894775177\n",
      "train loss:0.05333739854687249\n",
      "train loss:0.2090450868242241\n",
      "train loss:0.2114895149141374\n",
      "train loss:0.12259547666848253\n",
      "train loss:0.10674996665106389\n",
      "train loss:0.07990165461489127\n",
      "train loss:0.18327374180636208\n",
      "train loss:0.12056242638956119\n",
      "train loss:0.11616546782680298\n",
      "train loss:0.16623770703584742\n",
      "train loss:0.1110464620529155\n",
      "train loss:0.0932795768059776\n",
      "train loss:0.0918066846620566\n",
      "train loss:0.09209360381077943\n",
      "train loss:0.09130159775599633\n",
      "train loss:0.15327994526989663\n",
      "train loss:0.0793772066389605\n",
      "train loss:0.1408959284116783\n",
      "train loss:0.10653784899439803\n",
      "train loss:0.09600421755509742\n",
      "train loss:0.08868441927977548\n",
      "train loss:0.11669217591886812\n",
      "train loss:0.16275714388105103\n",
      "train loss:0.17889046586444496\n",
      "train loss:0.09094984389399625\n",
      "train loss:0.1593204049460753\n",
      "train loss:0.12723907896491074\n",
      "train loss:0.12428589764381708\n",
      "train loss:0.10347449783614787\n",
      "train loss:0.2013831086756273\n",
      "train loss:0.09277622882175107\n",
      "train loss:0.18705158871444663\n",
      "train loss:0.14244200933926274\n",
      "train loss:0.10963621858241338\n",
      "train loss:0.10260141565162556\n",
      "train loss:0.2114888159796232\n",
      "train loss:0.09852965297329058\n",
      "train loss:0.09161771951147499\n",
      "train loss:0.22301471970746928\n",
      "train loss:0.18935573576625372\n",
      "train loss:0.06581758944503227\n",
      "train loss:0.17616156055807053\n",
      "train loss:0.1385508993917826\n",
      "train loss:0.10344898622520284\n",
      "train loss:0.18820415380885896\n",
      "train loss:0.19675234251584464\n",
      "train loss:0.1165254562221036\n",
      "train loss:0.10390081492683491\n",
      "train loss:0.12647337030348715\n",
      "train loss:0.10527783919288394\n",
      "train loss:0.12286578005625326\n",
      "train loss:0.1285410044520133\n",
      "train loss:0.12100867038437116\n",
      "train loss:0.1388428371806172\n",
      "train loss:0.09619666468348073\n",
      "train loss:0.2148737178199697\n",
      "train loss:0.1692859295514445\n",
      "train loss:0.08018861341753954\n",
      "train loss:0.13513565868141678\n",
      "train loss:0.15604599288208557\n",
      "train loss:0.10118027396707298\n",
      "train loss:0.1601902658518021\n",
      "train loss:0.20380498776564873\n",
      "train loss:0.08490134547768033\n",
      "train loss:0.06473151226272844\n",
      "train loss:0.0702338848122804\n",
      "train loss:0.05662541840318995\n",
      "train loss:0.09831036958187\n",
      "train loss:0.13448410476053646\n",
      "train loss:0.15259730844018815\n",
      "train loss:0.07569022456199284\n",
      "train loss:0.10823225766449499\n",
      "train loss:0.0975327891264761\n",
      "train loss:0.12768680361271403\n",
      "train loss:0.1212748053981378\n",
      "train loss:0.08649117222530772\n",
      "train loss:0.17055992632092384\n",
      "train loss:0.175987573955198\n",
      "train loss:0.07548079214388709\n",
      "train loss:0.19989796069468935\n",
      "train loss:0.1328845378679439\n",
      "train loss:0.13281500180033362\n",
      "train loss:0.12152196454715358\n",
      "train loss:0.1373266763179412\n",
      "train loss:0.11491307815234889\n",
      "train loss:0.1337843135436711\n",
      "train loss:0.25549893858004397\n",
      "train loss:0.21948576919865606\n",
      "train loss:0.10984469896045015\n",
      "train loss:0.2566008759129697\n",
      "train loss:0.10894157969047806\n",
      "train loss:0.09926647430483401\n",
      "train loss:0.15617587640419217\n",
      "train loss:0.12752113485873115\n",
      "train loss:0.14294285558414177\n",
      "train loss:0.16965711170696277\n",
      "train loss:0.13889515740168815\n",
      "train loss:0.06678275420912358\n",
      "train loss:0.1388128797435212\n",
      "train loss:0.13764350084225177\n",
      "train loss:0.15678246955427147\n",
      "train loss:0.1275854909251366\n",
      "train loss:0.1498146680627692\n",
      "train loss:0.17242440985622642\n",
      "train loss:0.0973063431200426\n",
      "train loss:0.10708033610061955\n",
      "train loss:0.10577870992046386\n",
      "train loss:0.08089283033237402\n",
      "train loss:0.1386675556001097\n",
      "train loss:0.09705664741219851\n",
      "train loss:0.1387892938058483\n",
      "train loss:0.1368945996753466\n",
      "train loss:0.14117588296006967\n",
      "train loss:0.265105651947723\n",
      "train loss:0.11360255484048659\n",
      "train loss:0.1565787491029317\n",
      "train loss:0.1430220455753547\n",
      "train loss:0.3218086292867126\n",
      "train loss:0.10753125309492312\n",
      "train loss:0.04960119522138513\n",
      "train loss:0.06403485458807384\n",
      "train loss:0.08379544067332628\n",
      "train loss:0.09180899115931686\n",
      "train loss:0.18091097303938727\n",
      "train loss:0.05774833791725973\n",
      "train loss:0.1513536684878195\n",
      "train loss:0.1130802751467921\n",
      "train loss:0.10981277630509478\n",
      "train loss:0.18594748781115097\n",
      "train loss:0.12676831404878786\n",
      "train loss:0.054348762178207714\n",
      "train loss:0.0943592664351479\n",
      "train loss:0.13371851788021583\n",
      "train loss:0.12681895750658873\n",
      "train loss:0.09343820571376579\n",
      "train loss:0.10291893034084286\n",
      "train loss:0.12579989746212997\n",
      "train loss:0.10474296530118636\n",
      "train loss:0.12059655242310617\n",
      "train loss:0.09551290414954394\n",
      "train loss:0.12715795802136756\n",
      "train loss:0.09470849469911018\n",
      "train loss:0.13325717745825977\n",
      "train loss:0.13959757521720348\n",
      "train loss:0.19883126112739563\n",
      "train loss:0.18930694500479173\n",
      "train loss:0.08443806272917322\n",
      "train loss:0.11878595497308028\n",
      "train loss:0.0705391247372822\n",
      "train loss:0.2045385658319338\n",
      "train loss:0.14336853431007446\n",
      "train loss:0.12539186544781397\n",
      "train loss:0.14374916900838275\n",
      "train loss:0.15631006001875128\n",
      "train loss:0.08321274064066925\n",
      "train loss:0.19305220529984526\n",
      "train loss:0.08514389387237316\n",
      "train loss:0.14981973319862513\n",
      "train loss:0.12503745009286796\n",
      "train loss:0.12384773385957301\n",
      "train loss:0.06713784274849377\n",
      "train loss:0.11229573724586871\n",
      "train loss:0.0982262252270281\n",
      "train loss:0.15607517071286742\n",
      "train loss:0.23800287382713894\n",
      "train loss:0.06586078732958979\n",
      "train loss:0.09945408409296658\n",
      "train loss:0.06144578577747804\n",
      "train loss:0.14675313947283852\n",
      "train loss:0.09260540752940713\n",
      "train loss:0.13058415496326709\n",
      "train loss:0.13175534267838337\n",
      "train loss:0.0993758367738787\n",
      "train loss:0.13714729690396252\n",
      "train loss:0.11828848833384993\n",
      "train loss:0.142767428806455\n",
      "train loss:0.12552162747675205\n",
      "train loss:0.11862718129166243\n",
      "train loss:0.10445428694421277\n",
      "train loss:0.08331358404308457\n",
      "train loss:0.13719681563757158\n",
      "train loss:0.08762359570649998\n",
      "train loss:0.13610158033489958\n",
      "train loss:0.12368031378151269\n",
      "train loss:0.1291341789467676\n",
      "train loss:0.18591524475900742\n",
      "train loss:0.1694908937578095\n",
      "train loss:0.08439544950506164\n",
      "train loss:0.10669329974082714\n",
      "train loss:0.233673896277413\n",
      "train loss:0.09661563519591432\n",
      "train loss:0.11914417648255446\n",
      "train loss:0.1652353580395989\n",
      "train loss:0.20054642959845384\n",
      "train loss:0.16259753412415637\n",
      "train loss:0.12319293109433811\n",
      "train loss:0.10565131478135326\n",
      "train loss:0.08264520841728422\n",
      "train loss:0.1318993764768228\n",
      "train loss:0.13805952411019462\n",
      "train loss:0.09437496394592974\n",
      "train loss:0.09816752209067085\n",
      "train loss:0.08648131397265642\n",
      "train loss:0.18945470641027495\n",
      "train loss:0.11443668122144197\n",
      "train loss:0.0669741619163764\n",
      "train loss:0.12781594821104933\n",
      "train loss:0.06691618692458912\n",
      "train loss:0.10022452600078084\n",
      "train loss:0.14682784597160053\n",
      "train loss:0.24668181308460457\n",
      "train loss:0.1781750033515035\n",
      "train loss:0.10856277932550881\n",
      "train loss:0.09054843149963034\n",
      "train loss:0.13929252043233034\n",
      "train loss:0.19386364391882066\n",
      "train loss:0.10934035051271149\n",
      "train loss:0.16140136970866795\n",
      "train loss:0.11927110953385636\n",
      "train loss:0.1890300150137145\n",
      "train loss:0.20443134937588486\n",
      "train loss:0.13675984934645877\n",
      "train loss:0.11017606536171001\n",
      "train loss:0.10812350416697043\n",
      "train loss:0.12346074953778365\n",
      "train loss:0.14402364373563523\n",
      "train loss:0.11455502178124187\n",
      "train loss:0.12619435249914676\n",
      "train loss:0.10862148962388408\n",
      "train loss:0.1115306332243529\n",
      "train loss:0.07896584244243461\n",
      "train loss:0.05777607427178241\n",
      "train loss:0.22023660541144138\n",
      "train loss:0.10131034464228378\n",
      "train loss:0.14752274622528527\n",
      "train loss:0.13815445046691222\n",
      "train loss:0.1279139072246989\n",
      "train loss:0.13521911767539194\n",
      "train loss:0.11930984465211494\n",
      "train loss:0.09255065071663396\n",
      "train loss:0.07197830726475303\n",
      "train loss:0.10402806321440909\n",
      "train loss:0.054696842057493325\n",
      "train loss:0.09934315228605455\n",
      "train loss:0.10070374179172806\n",
      "train loss:0.12200561631592417\n",
      "train loss:0.1326066631479002\n",
      "train loss:0.12267070155284308\n",
      "train loss:0.15404289911303334\n",
      "train loss:0.1755405058950917\n",
      "train loss:0.1402694176187457\n",
      "train loss:0.05379251451826548\n",
      "train loss:0.17309133514226027\n",
      "train loss:0.09930923317934813\n",
      "train loss:0.11995705946353231\n",
      "train loss:0.13746440599836046\n",
      "train loss:0.14164168913343486\n",
      "train loss:0.23028326011635117\n",
      "train loss:0.13607971794226764\n",
      "train loss:0.15337477427378998\n",
      "train loss:0.24633126732923677\n",
      "train loss:0.10379481854845234\n",
      "train loss:0.17511998089576056\n",
      "train loss:0.14844732882446793\n",
      "train loss:0.12463765232288605\n",
      "train loss:0.1428071094344771\n",
      "train loss:0.10677169999707452\n",
      "train loss:0.10775809283243869\n",
      "train loss:0.10162493556107412\n",
      "train loss:0.14463111548900756\n",
      "train loss:0.14235861117536872\n",
      "train loss:0.10554545211876912\n",
      "train loss:0.07111816654097544\n",
      "train loss:0.11728103174254388\n",
      "train loss:0.19516486429428553\n",
      "train loss:0.09193602281893871\n",
      "train loss:0.1318047629548455\n",
      "train loss:0.16544361899366142\n",
      "train loss:0.08656814453453553\n",
      "train loss:0.12178261888069346\n",
      "train loss:0.16014679618388503\n",
      "train loss:0.0919324837105587\n",
      "train loss:0.14368861728972038\n",
      "train loss:0.09134156613059656\n",
      "train loss:0.14244207000275433\n",
      "train loss:0.12245373943350737\n",
      "train loss:0.11234630559188963\n",
      "train loss:0.09278159011124197\n",
      "train loss:0.25666388558233755\n",
      "train loss:0.06556975189277219\n",
      "train loss:0.06495294537616922\n",
      "train loss:0.11394784037945263\n",
      "train loss:0.1275256479781827\n",
      "train loss:0.06290166494629945\n",
      "train loss:0.10087093036770511\n",
      "train loss:0.08106591417809464\n",
      "train loss:0.13723366574989126\n",
      "train loss:0.21377657653236037\n",
      "train loss:0.09564648960710014\n",
      "train loss:0.07896026014980563\n",
      "train loss:0.09621613235904596\n",
      "train loss:0.1938503426894843\n",
      "train loss:0.14784019003061638\n",
      "train loss:0.12185735439761493\n",
      "train loss:0.07738871918334338\n",
      "train loss:0.13490430522484012\n",
      "train loss:0.13283150361509033\n",
      "train loss:0.0851268167203265\n",
      "train loss:0.10557954713246431\n",
      "train loss:0.07207849953705424\n",
      "train loss:0.08316782721766099\n",
      "train loss:0.10579535420403445\n",
      "train loss:0.15702263183625764\n",
      "train loss:0.2137980923520083\n",
      "train loss:0.10602205363015413\n",
      "train loss:0.09812730046010641\n",
      "train loss:0.09971901641820455\n",
      "train loss:0.07922082823477601\n",
      "train loss:0.17682988739300004\n",
      "train loss:0.06423901455197917\n",
      "train loss:0.18083755427187523\n",
      "train loss:0.06878607702725267\n",
      "train loss:0.0919815299776696\n",
      "train loss:0.11559843440934463\n",
      "train loss:0.13703520714838968\n",
      "train loss:0.09432880201717653\n",
      "train loss:0.11512911404512247\n",
      "train loss:0.1627327914533079\n",
      "train loss:0.08101282509006412\n",
      "train loss:0.09109617932857422\n",
      "train loss:0.10894572740921593\n",
      "=== epoch:11, train acc:0.949, test acc:0.911 ===\n",
      "train loss:0.16225111692721975\n",
      "train loss:0.21939144552301737\n",
      "train loss:0.09524048622454544\n",
      "train loss:0.18763809524712222\n",
      "train loss:0.14683106503444743\n",
      "train loss:0.1106154250684241\n",
      "train loss:0.15565921351947837\n",
      "train loss:0.10695452151289718\n",
      "train loss:0.14126772382413322\n",
      "train loss:0.0885765058511802\n",
      "train loss:0.15072955139850114\n",
      "train loss:0.08731350242866016\n",
      "train loss:0.041969098176120594\n",
      "train loss:0.13759128867145443\n",
      "train loss:0.15875689048679867\n",
      "train loss:0.07619543315399763\n",
      "train loss:0.09273345936156618\n",
      "train loss:0.08942087067594344\n",
      "train loss:0.11516824034055145\n",
      "train loss:0.10826770918173052\n",
      "train loss:0.10058290888407902\n",
      "train loss:0.1729615591877255\n",
      "train loss:0.1256468264031199\n",
      "train loss:0.0613634297881849\n",
      "train loss:0.11952879968658933\n",
      "train loss:0.13732953163704786\n",
      "train loss:0.07647050329859037\n",
      "train loss:0.13663714865910892\n",
      "train loss:0.12152521590030407\n",
      "train loss:0.16244890675407983\n",
      "train loss:0.11779769842033355\n",
      "train loss:0.0781225447913522\n",
      "train loss:0.1365523550784119\n",
      "train loss:0.14600451620746402\n",
      "train loss:0.13254086889446212\n",
      "train loss:0.11767854763464512\n",
      "train loss:0.14263457066607363\n",
      "train loss:0.11438696765038289\n",
      "train loss:0.1226564623430912\n",
      "train loss:0.06538289930003152\n",
      "train loss:0.07779243736390576\n",
      "train loss:0.0733930375640841\n",
      "train loss:0.12917026055024636\n",
      "train loss:0.11411196772865327\n",
      "train loss:0.1610639593234504\n",
      "train loss:0.1023192593764015\n",
      "train loss:0.12501601660089506\n",
      "train loss:0.13241773352103076\n",
      "train loss:0.08495019461645541\n",
      "train loss:0.11999859185762517\n",
      "train loss:0.07417464404628739\n",
      "train loss:0.15943643882766076\n",
      "train loss:0.14346192247526346\n",
      "train loss:0.09316702454230477\n",
      "train loss:0.08395897469073804\n",
      "train loss:0.0920392689589776\n",
      "train loss:0.13580289297532272\n",
      "train loss:0.10329313512558516\n",
      "train loss:0.20776966491567322\n",
      "train loss:0.14864164725666862\n",
      "train loss:0.11074816284597924\n",
      "train loss:0.16851077789967062\n",
      "train loss:0.10702504766846341\n",
      "train loss:0.06077459604461748\n",
      "train loss:0.09310379140391024\n",
      "train loss:0.22212614051643478\n",
      "train loss:0.09469798515678125\n",
      "train loss:0.16967470144662056\n",
      "train loss:0.08708600944066706\n",
      "train loss:0.14988768314048045\n",
      "train loss:0.1290214691165946\n",
      "train loss:0.11230981747994137\n",
      "train loss:0.13184567857056034\n",
      "train loss:0.0690003539338279\n",
      "train loss:0.11099143228422927\n",
      "train loss:0.14497593135429143\n",
      "train loss:0.17144350452531906\n",
      "train loss:0.08799404648421222\n",
      "train loss:0.14391202908956294\n",
      "train loss:0.1385635407284877\n",
      "train loss:0.16832868494064324\n",
      "train loss:0.11373657275151614\n",
      "train loss:0.18012760304562503\n",
      "train loss:0.1693854975379131\n",
      "train loss:0.1262890955794431\n",
      "train loss:0.08668221302301654\n",
      "train loss:0.05879275108076887\n",
      "train loss:0.12004041028206251\n",
      "train loss:0.1739450747864086\n",
      "train loss:0.1319177532892018\n",
      "train loss:0.17065740466918014\n",
      "train loss:0.12246963770664006\n",
      "train loss:0.10405213462204957\n",
      "train loss:0.1569707884039525\n",
      "train loss:0.10616385755717944\n",
      "train loss:0.0757601310425487\n",
      "train loss:0.15674724185288577\n",
      "train loss:0.0581985167681361\n",
      "train loss:0.10792132512256622\n",
      "train loss:0.09481114868454826\n",
      "train loss:0.09750753361028883\n",
      "train loss:0.20384993412319427\n",
      "train loss:0.1639802549334458\n",
      "train loss:0.09174327696985582\n",
      "train loss:0.10946845839623535\n",
      "train loss:0.07762204676930602\n",
      "train loss:0.20783333378804272\n",
      "train loss:0.09545593477080974\n",
      "train loss:0.15865339578868584\n",
      "train loss:0.12441217788227049\n",
      "train loss:0.1051893951484292\n",
      "train loss:0.13693175001371155\n",
      "train loss:0.08281290974631089\n",
      "train loss:0.11351137453648513\n",
      "train loss:0.10717200555055363\n",
      "train loss:0.0686271045914196\n",
      "train loss:0.08695136177036857\n",
      "train loss:0.10851174116968926\n",
      "train loss:0.1269378517514286\n",
      "train loss:0.23201535704222714\n",
      "train loss:0.12442087336744993\n",
      "train loss:0.07142722359414008\n",
      "train loss:0.04621711782318225\n",
      "train loss:0.13644531003682006\n",
      "train loss:0.15188467155836033\n",
      "train loss:0.10218608806539344\n",
      "train loss:0.04617634414852563\n",
      "train loss:0.07701435869721278\n",
      "train loss:0.1903461782064514\n",
      "train loss:0.11355566847935217\n",
      "train loss:0.12403706355453706\n",
      "train loss:0.09869045480310301\n",
      "train loss:0.08320701766724543\n",
      "train loss:0.2135588400944802\n",
      "train loss:0.09428125699705836\n",
      "train loss:0.08396533363268732\n",
      "train loss:0.10752139971582318\n",
      "train loss:0.13906721540965353\n",
      "train loss:0.1631367825570324\n",
      "train loss:0.06802032859283524\n",
      "train loss:0.11588478705909182\n",
      "train loss:0.18729655056956382\n",
      "train loss:0.11077299519194372\n",
      "train loss:0.13204478310440998\n",
      "train loss:0.11899104322669674\n",
      "train loss:0.24799115383073939\n",
      "train loss:0.09796496320890327\n",
      "train loss:0.08819847123251424\n",
      "train loss:0.08882411513841312\n",
      "train loss:0.09475388210501663\n",
      "train loss:0.1323191295225858\n",
      "train loss:0.10486405362042422\n",
      "train loss:0.09243077939215581\n",
      "train loss:0.08255141183910901\n",
      "train loss:0.14297827372530253\n",
      "train loss:0.12155967191072929\n",
      "train loss:0.1044386256012473\n",
      "train loss:0.09396928726671072\n",
      "train loss:0.09520084110279839\n",
      "train loss:0.08718214558472516\n",
      "train loss:0.09910326395653019\n",
      "train loss:0.06541016267537861\n",
      "train loss:0.051441561482912526\n",
      "train loss:0.10578218964367173\n",
      "train loss:0.10684840646915973\n",
      "train loss:0.12313111160579661\n",
      "train loss:0.0927459801707587\n",
      "train loss:0.12911151531046808\n",
      "train loss:0.1306515625187704\n",
      "train loss:0.09060433361878616\n",
      "train loss:0.0748734712647872\n",
      "train loss:0.12953156101658425\n",
      "train loss:0.13588622793220545\n",
      "train loss:0.13715178370522085\n",
      "train loss:0.08255548950738449\n",
      "train loss:0.08760500973187778\n",
      "train loss:0.11523890886924272\n",
      "train loss:0.08930101198821772\n",
      "train loss:0.11117018578918318\n",
      "train loss:0.06906229144342162\n",
      "train loss:0.17347228732060124\n",
      "train loss:0.13722044337413375\n",
      "train loss:0.07470713094685767\n",
      "train loss:0.11191487524674072\n",
      "train loss:0.08397999104374994\n",
      "train loss:0.08483891911755181\n",
      "train loss:0.10546250268195166\n",
      "train loss:0.0942869719808062\n",
      "train loss:0.19509790338355934\n",
      "train loss:0.1436345972772952\n",
      "train loss:0.0945876278094254\n",
      "train loss:0.08461371120597193\n",
      "train loss:0.1406185818528216\n",
      "train loss:0.10674018468644925\n",
      "train loss:0.08667509074343395\n",
      "train loss:0.11408234303251082\n",
      "train loss:0.030531534757796318\n",
      "train loss:0.05798788041632215\n",
      "train loss:0.08763981384863564\n",
      "train loss:0.0805058465155927\n",
      "train loss:0.04129108829037023\n",
      "train loss:0.0867624177209673\n",
      "train loss:0.10620284077899075\n",
      "train loss:0.05110251240871363\n",
      "train loss:0.11139466370293256\n",
      "train loss:0.11076263378929856\n",
      "train loss:0.12200300493040521\n",
      "train loss:0.08598647227860053\n",
      "train loss:0.12909478642986946\n",
      "train loss:0.1422092240784184\n",
      "train loss:0.1121018606220858\n",
      "train loss:0.11808975970897853\n",
      "train loss:0.12251831042700326\n",
      "train loss:0.11041687050998301\n",
      "train loss:0.12877190952778983\n",
      "train loss:0.17775151453442106\n",
      "train loss:0.07244589911231271\n",
      "train loss:0.12234906291239288\n",
      "train loss:0.09832927762872792\n",
      "train loss:0.09013267099624579\n",
      "train loss:0.14166014758392878\n",
      "train loss:0.1669716975082504\n",
      "train loss:0.07046109176158294\n",
      "train loss:0.1336723603509909\n",
      "train loss:0.1683949273722841\n",
      "train loss:0.058693100666757855\n",
      "train loss:0.05971840798306894\n",
      "train loss:0.11323500589613805\n",
      "train loss:0.07228602109151579\n",
      "train loss:0.11399366594195\n",
      "train loss:0.06674462350312473\n",
      "train loss:0.08936109067983539\n",
      "train loss:0.09421609707150896\n",
      "train loss:0.09496805511781893\n",
      "train loss:0.12311826778737242\n",
      "train loss:0.15196378051578263\n",
      "train loss:0.06753509564639697\n",
      "train loss:0.07598819753431504\n",
      "train loss:0.17383864892142203\n",
      "train loss:0.1166529005264677\n",
      "train loss:0.06234649840194357\n",
      "train loss:0.09646372761287118\n",
      "train loss:0.1262373709546317\n",
      "train loss:0.07932560093385853\n",
      "train loss:0.3707346382329391\n",
      "train loss:0.10027517029339689\n",
      "train loss:0.12376117003795706\n",
      "train loss:0.11131487414988403\n",
      "train loss:0.20898474594125765\n",
      "train loss:0.08877071400010773\n",
      "train loss:0.09162878551250454\n",
      "train loss:0.06823957880925306\n",
      "train loss:0.08742032062438819\n",
      "train loss:0.1868762790905089\n",
      "train loss:0.08874915443078651\n",
      "train loss:0.12745168685663544\n",
      "train loss:0.11515083441976147\n",
      "train loss:0.11494731155847733\n",
      "train loss:0.17543723151984936\n",
      "train loss:0.08564387872578698\n",
      "train loss:0.07441352043955202\n",
      "train loss:0.1496384516789548\n",
      "train loss:0.13019853216910918\n",
      "train loss:0.1978020941873465\n",
      "train loss:0.14460557757056408\n",
      "train loss:0.04812480677488509\n",
      "train loss:0.1603429545858463\n",
      "train loss:0.12870374398817355\n",
      "train loss:0.11432549890308032\n",
      "train loss:0.14387274679937068\n",
      "train loss:0.11142301200499699\n",
      "train loss:0.08380449188548507\n",
      "train loss:0.1854783313468925\n",
      "train loss:0.09741531130685828\n",
      "train loss:0.06934885641391392\n",
      "train loss:0.08829843061454136\n",
      "train loss:0.13485805614519275\n",
      "train loss:0.174336511061288\n",
      "train loss:0.09377266208024845\n",
      "train loss:0.19891724885704062\n",
      "train loss:0.09560557358064545\n",
      "train loss:0.07851294842770354\n",
      "train loss:0.10182455629376155\n",
      "train loss:0.08890505840180145\n",
      "train loss:0.06874341464882346\n",
      "train loss:0.09038935083954044\n",
      "train loss:0.20471002286719503\n",
      "train loss:0.05315096266772067\n",
      "train loss:0.1563935399314715\n",
      "train loss:0.06862561230209885\n",
      "train loss:0.16609660298048254\n",
      "train loss:0.09461747240554709\n",
      "train loss:0.09545395412772997\n",
      "train loss:0.0979311880653778\n",
      "train loss:0.10011936365444767\n",
      "train loss:0.1344653205495649\n",
      "train loss:0.1686175396263744\n",
      "train loss:0.08933218553254346\n",
      "train loss:0.05071299315417968\n",
      "train loss:0.1319439923541795\n",
      "train loss:0.08435264944617439\n",
      "train loss:0.17926846523294734\n",
      "train loss:0.049923104903813964\n",
      "train loss:0.09634888681775122\n",
      "train loss:0.10101062503022527\n",
      "train loss:0.11902906247212366\n",
      "train loss:0.18997920284603448\n",
      "train loss:0.10404500747592524\n",
      "train loss:0.11663389095053374\n",
      "train loss:0.10558576913175573\n",
      "train loss:0.11264932225550706\n",
      "train loss:0.13263430443613597\n",
      "train loss:0.13380964473657475\n",
      "train loss:0.18383292633929682\n",
      "train loss:0.0845902918565551\n",
      "train loss:0.128203149001046\n",
      "train loss:0.06882681090813296\n",
      "train loss:0.16223147245067282\n",
      "train loss:0.10174242226865529\n",
      "train loss:0.09331817635004183\n",
      "train loss:0.1685967795926121\n",
      "train loss:0.10719220262802316\n",
      "train loss:0.14593040939590637\n",
      "train loss:0.10704388794194263\n",
      "train loss:0.0655188077987583\n",
      "train loss:0.09261734992097845\n",
      "train loss:0.08050308246172554\n",
      "train loss:0.11732269777389215\n",
      "train loss:0.09465432167715206\n",
      "train loss:0.08668003742260934\n",
      "train loss:0.10556645490660126\n",
      "train loss:0.1135251493280319\n",
      "train loss:0.11461796567317752\n",
      "train loss:0.17332990615219793\n",
      "train loss:0.17172926060645985\n",
      "train loss:0.11560911521925395\n",
      "train loss:0.1369682843653192\n",
      "train loss:0.14318339305847996\n",
      "train loss:0.1020722279076187\n",
      "train loss:0.10162156527303857\n",
      "train loss:0.21491521005034467\n",
      "train loss:0.14461178493578655\n",
      "train loss:0.0877360382301382\n",
      "train loss:0.1324797566568616\n",
      "train loss:0.0948025989827732\n",
      "train loss:0.05511157169002146\n",
      "train loss:0.10584847023046573\n",
      "train loss:0.16261850241193415\n",
      "train loss:0.12817088012823025\n",
      "train loss:0.1370437534087105\n",
      "train loss:0.10530674841436732\n",
      "train loss:0.16340633384831432\n",
      "train loss:0.13812693369227383\n",
      "train loss:0.11307912832714027\n",
      "train loss:0.12848371805925704\n",
      "train loss:0.1043843719656734\n",
      "train loss:0.1613167334349264\n",
      "train loss:0.15769706313437598\n",
      "train loss:0.16219287224364515\n",
      "train loss:0.14071270735377403\n",
      "train loss:0.10301686129873815\n",
      "train loss:0.08851667254958734\n",
      "train loss:0.09588031148745005\n",
      "train loss:0.1457980938697132\n",
      "train loss:0.05703658847598257\n",
      "train loss:0.0732775946611189\n",
      "train loss:0.06444400225041617\n",
      "train loss:0.13911258119283668\n",
      "train loss:0.08764391984028094\n",
      "train loss:0.06336173345707347\n",
      "train loss:0.1080700947014966\n",
      "train loss:0.15290739449105492\n",
      "train loss:0.04823765408983788\n",
      "train loss:0.05507219398571928\n",
      "train loss:0.0587706123495562\n",
      "train loss:0.08813423594990599\n",
      "train loss:0.07998189622501446\n",
      "train loss:0.11280702311109461\n",
      "train loss:0.11163140919105148\n",
      "train loss:0.06894682105857491\n",
      "train loss:0.057961992075799176\n",
      "train loss:0.08830772211147828\n",
      "train loss:0.16019127720549586\n",
      "train loss:0.08960003681894708\n",
      "train loss:0.1399827831589615\n",
      "train loss:0.15653420116436836\n",
      "train loss:0.13290406183071427\n",
      "train loss:0.09385500928975153\n",
      "train loss:0.10549327719381124\n",
      "train loss:0.1602917528011028\n",
      "train loss:0.05815370790097654\n",
      "train loss:0.20056581431769874\n",
      "train loss:0.12743586468044246\n",
      "train loss:0.056716413694160334\n",
      "train loss:0.18825694988195127\n",
      "train loss:0.12040743274964003\n",
      "train loss:0.09611600260561437\n",
      "train loss:0.11886160658616353\n",
      "train loss:0.05745850791267355\n",
      "train loss:0.0864650375169998\n",
      "train loss:0.06170969731124599\n",
      "train loss:0.08569162891034551\n",
      "train loss:0.07321613164289292\n",
      "train loss:0.0900716396581169\n",
      "train loss:0.10676718398712469\n",
      "train loss:0.07985486566625283\n",
      "train loss:0.12896815569044706\n",
      "train loss:0.09437407494753608\n",
      "train loss:0.2348288409037107\n",
      "train loss:0.14626029011011826\n",
      "train loss:0.054842345179521586\n",
      "train loss:0.16900144809030784\n",
      "train loss:0.16226123774903226\n",
      "train loss:0.05926084582194341\n",
      "train loss:0.18156483558491904\n",
      "train loss:0.08309933635153179\n",
      "train loss:0.15281984282651467\n",
      "train loss:0.09783527032159696\n",
      "train loss:0.08664262224025827\n",
      "train loss:0.11076209030167532\n",
      "train loss:0.12773459601378284\n",
      "train loss:0.03126138635023335\n",
      "train loss:0.13202791645650136\n",
      "train loss:0.15829939909083476\n",
      "train loss:0.08297686355519371\n",
      "train loss:0.07839099983189869\n",
      "train loss:0.06676557664049788\n",
      "train loss:0.12792815060385726\n",
      "train loss:0.0870045535313183\n",
      "train loss:0.13016901347770132\n",
      "train loss:0.06418627167935427\n",
      "train loss:0.10527577681422712\n",
      "train loss:0.14401195943536568\n",
      "train loss:0.07073197847493967\n",
      "train loss:0.10223416283402623\n",
      "train loss:0.15161746853141206\n",
      "train loss:0.11741025769318934\n",
      "train loss:0.2040948071609931\n",
      "train loss:0.06897083984704488\n",
      "train loss:0.14432019950233013\n",
      "train loss:0.10374624888626123\n",
      "train loss:0.10571320670722092\n",
      "train loss:0.10822865380728448\n",
      "train loss:0.10530635241728292\n",
      "train loss:0.06550939514935687\n",
      "train loss:0.11579214172310101\n",
      "train loss:0.1259496212549833\n",
      "train loss:0.14267806208176506\n",
      "train loss:0.07474880910991309\n",
      "train loss:0.06838433462238591\n",
      "train loss:0.13821814890054418\n",
      "train loss:0.08487315664887403\n",
      "train loss:0.1210743460852892\n",
      "train loss:0.06687381844557894\n",
      "train loss:0.09733645630740902\n",
      "train loss:0.06503817575901255\n",
      "train loss:0.12900192799002377\n",
      "train loss:0.0959807960645788\n",
      "train loss:0.14231674255782598\n",
      "train loss:0.10816359067429163\n",
      "train loss:0.09414039763293568\n",
      "train loss:0.07870113393590089\n",
      "train loss:0.15048016803791117\n",
      "train loss:0.045208139189857006\n",
      "train loss:0.1557213452400151\n",
      "train loss:0.09741724930683052\n",
      "train loss:0.138038939044641\n",
      "train loss:0.08143168042741097\n",
      "train loss:0.07511247709250951\n",
      "train loss:0.0696308920345794\n",
      "train loss:0.16134862381232712\n",
      "train loss:0.13565638567154453\n",
      "train loss:0.11058027972339678\n",
      "train loss:0.07791966324392158\n",
      "train loss:0.08760193291964131\n",
      "train loss:0.11990229232474701\n",
      "train loss:0.0833618384338834\n",
      "train loss:0.0824783913542583\n",
      "train loss:0.13674327927055555\n",
      "train loss:0.1597128936962807\n",
      "train loss:0.08967487588341436\n",
      "train loss:0.11266896015119167\n",
      "train loss:0.14064397906539455\n",
      "train loss:0.11250635295805753\n",
      "train loss:0.123970259140726\n",
      "train loss:0.0908774498320968\n",
      "train loss:0.08688263844299485\n",
      "train loss:0.13926557078364502\n",
      "train loss:0.13332089093168611\n",
      "train loss:0.0637481625998345\n",
      "train loss:0.13429637170392916\n",
      "train loss:0.0658949719712452\n",
      "train loss:0.06758298726861882\n",
      "train loss:0.11073240994450619\n",
      "train loss:0.11517511753784668\n",
      "train loss:0.10403019024864964\n",
      "train loss:0.17482358889097455\n",
      "train loss:0.16443369182908055\n",
      "train loss:0.13030983713297017\n",
      "train loss:0.08951094027107175\n",
      "train loss:0.07716075634651859\n",
      "train loss:0.08433608611818669\n",
      "train loss:0.1798230427753121\n",
      "train loss:0.16095506558822156\n",
      "train loss:0.19001091851431642\n",
      "train loss:0.07356359592729964\n",
      "train loss:0.06810025068238558\n",
      "train loss:0.06745403653572205\n",
      "train loss:0.07713019867553973\n",
      "train loss:0.08729251115509928\n",
      "train loss:0.07896602246333088\n",
      "train loss:0.17554503369370683\n",
      "train loss:0.10318394707764846\n",
      "train loss:0.17635919488430904\n",
      "train loss:0.07508616947258413\n",
      "train loss:0.0604876429552034\n",
      "train loss:0.14880902880868802\n",
      "train loss:0.11550062661450738\n",
      "train loss:0.199904782009905\n",
      "train loss:0.14248991031643166\n",
      "train loss:0.09478475658710328\n",
      "train loss:0.10319663850410984\n",
      "train loss:0.08244791976354376\n",
      "train loss:0.10288781227612087\n",
      "train loss:0.19783665410333376\n",
      "train loss:0.10779531742740442\n",
      "train loss:0.12736713883167922\n",
      "train loss:0.060919891385707615\n",
      "train loss:0.14029515326436687\n",
      "train loss:0.13738558327277198\n",
      "train loss:0.0782487439663288\n",
      "train loss:0.1301490247767246\n",
      "train loss:0.1362639776896936\n",
      "train loss:0.10321834790640493\n",
      "train loss:0.068408147295245\n",
      "train loss:0.11553988342081377\n",
      "train loss:0.031589779477738424\n",
      "train loss:0.09566643040474755\n",
      "train loss:0.08757464846134978\n",
      "train loss:0.10142504087434989\n",
      "train loss:0.12023658829543366\n",
      "train loss:0.09979769277201418\n",
      "train loss:0.11090871269704322\n",
      "train loss:0.12973794820143908\n",
      "train loss:0.09368605137400221\n",
      "train loss:0.10808872372524661\n",
      "train loss:0.18737364591589376\n",
      "train loss:0.17786824739409154\n",
      "train loss:0.15212934420720198\n",
      "train loss:0.13641738162770461\n",
      "train loss:0.10075149963367665\n",
      "train loss:0.07678907638125568\n",
      "train loss:0.087822241753474\n",
      "train loss:0.11128957988140087\n",
      "train loss:0.13931401842792607\n",
      "train loss:0.10383398160807693\n",
      "train loss:0.15887048396423673\n",
      "train loss:0.11332645450834868\n",
      "train loss:0.0956456577000176\n",
      "train loss:0.07110587759603186\n",
      "train loss:0.12972854531244166\n",
      "train loss:0.1728863250796295\n",
      "train loss:0.1023005437795052\n",
      "train loss:0.17865026448323715\n",
      "train loss:0.11133621577881303\n",
      "train loss:0.12628784225570086\n",
      "train loss:0.046521037659137086\n",
      "train loss:0.19362577477944418\n",
      "train loss:0.1012722342681454\n",
      "train loss:0.11377461082240765\n",
      "train loss:0.05551936850246952\n",
      "train loss:0.16591421613082197\n",
      "train loss:0.10140391618484808\n",
      "train loss:0.06896742608786047\n",
      "train loss:0.10906656576848112\n",
      "train loss:0.07605969976359334\n",
      "train loss:0.09151954242138466\n",
      "train loss:0.1040787794580158\n",
      "train loss:0.17609260284225478\n",
      "train loss:0.10553765538814756\n",
      "train loss:0.10329399634805869\n",
      "train loss:0.08229602660842884\n",
      "train loss:0.11671991200092383\n",
      "train loss:0.13381931839751482\n",
      "train loss:0.033888111452462864\n",
      "train loss:0.036875749107139644\n",
      "train loss:0.08098333263300797\n",
      "train loss:0.07053771437698368\n",
      "train loss:0.18658820269125134\n",
      "train loss:0.14075756942541623\n",
      "train loss:0.07329676418212158\n",
      "train loss:0.12542872000518215\n",
      "train loss:0.1657385519154215\n",
      "train loss:0.17559637437153022\n",
      "train loss:0.11075717514548229\n",
      "train loss:0.1312450762054885\n",
      "train loss:0.06410937914310784\n",
      "train loss:0.07242997276791598\n",
      "train loss:0.12864949674263287\n",
      "train loss:0.14260101387006383\n",
      "=== epoch:12, train acc:0.959, test acc:0.908 ===\n",
      "train loss:0.06604272547765529\n",
      "train loss:0.11193635469651199\n",
      "train loss:0.07047788709029526\n",
      "train loss:0.03084319855498928\n",
      "train loss:0.038961002810623466\n",
      "train loss:0.12847843746967053\n",
      "train loss:0.0752102469770875\n",
      "train loss:0.1425264778440558\n",
      "train loss:0.1396281662889834\n",
      "train loss:0.07195185811574663\n",
      "train loss:0.2852769958085056\n",
      "train loss:0.20594926835658992\n",
      "train loss:0.030604697320663204\n",
      "train loss:0.10254837222916866\n",
      "train loss:0.1575743468870231\n",
      "train loss:0.1184582813934395\n",
      "train loss:0.10834244978960665\n",
      "train loss:0.05972134781609903\n",
      "train loss:0.13591594829356113\n",
      "train loss:0.08527198944388208\n",
      "train loss:0.07671875085618368\n",
      "train loss:0.08156229006258436\n",
      "train loss:0.16567030505513813\n",
      "train loss:0.10233585868492115\n",
      "train loss:0.15435444313527627\n",
      "train loss:0.1130402507510931\n",
      "train loss:0.18501458510344992\n",
      "train loss:0.08039959065701481\n",
      "train loss:0.10622105628508173\n",
      "train loss:0.12539413395286866\n",
      "train loss:0.12126367476535925\n",
      "train loss:0.10988723791075432\n",
      "train loss:0.12205574375791098\n",
      "train loss:0.2277754072729316\n",
      "train loss:0.1571754751617015\n",
      "train loss:0.16026858950561376\n",
      "train loss:0.11667185636856033\n",
      "train loss:0.12161331049782406\n",
      "train loss:0.08359682421762489\n",
      "train loss:0.03477341378782062\n",
      "train loss:0.09277502394950755\n",
      "train loss:0.11754473684239537\n",
      "train loss:0.20734207480172018\n",
      "train loss:0.08499643511181856\n",
      "train loss:0.2224873693089532\n",
      "train loss:0.13656989118100749\n",
      "train loss:0.15383388603089718\n",
      "train loss:0.12078015048489839\n",
      "train loss:0.1165064104684703\n",
      "train loss:0.09733578782913993\n",
      "train loss:0.08576174783285374\n",
      "train loss:0.1490199256467382\n",
      "train loss:0.12712258235827525\n",
      "train loss:0.12821114134647535\n",
      "train loss:0.15465474797970324\n",
      "train loss:0.11566220044680421\n",
      "train loss:0.21046778943515507\n",
      "train loss:0.18876266005620018\n",
      "train loss:0.049807976343011075\n",
      "train loss:0.07777551483351088\n",
      "train loss:0.11731513164978359\n",
      "train loss:0.19777612069780404\n",
      "train loss:0.07575472990383161\n",
      "train loss:0.16952369569057485\n",
      "train loss:0.1407139266675997\n",
      "train loss:0.14044965228210832\n",
      "train loss:0.04827336382644146\n",
      "train loss:0.07697131107522122\n",
      "train loss:0.15946841227291114\n",
      "train loss:0.12959016302387094\n",
      "train loss:0.1299281404077835\n",
      "train loss:0.16245343506372031\n",
      "train loss:0.10677598562878114\n",
      "train loss:0.06793059458526407\n",
      "train loss:0.09921881752122079\n",
      "train loss:0.1377437457832494\n",
      "train loss:0.12223631241120049\n",
      "train loss:0.12857493662242614\n",
      "train loss:0.13840422160349986\n",
      "train loss:0.1335912081321254\n",
      "train loss:0.09761210143004316\n",
      "train loss:0.12909329933541425\n",
      "train loss:0.10715052274419336\n",
      "train loss:0.06062180624487969\n",
      "train loss:0.17437499002218002\n",
      "train loss:0.10352878927321767\n",
      "train loss:0.16450853390202747\n",
      "train loss:0.1384773357063321\n",
      "train loss:0.07126634999049446\n",
      "train loss:0.047714810784760024\n",
      "train loss:0.08280023803960891\n",
      "train loss:0.11626020922028828\n",
      "train loss:0.056031806336141014\n",
      "train loss:0.11775465863809663\n",
      "train loss:0.10850412330538038\n",
      "train loss:0.17402042914604607\n",
      "train loss:0.15105243081522415\n",
      "train loss:0.08115991788330121\n",
      "train loss:0.15042611933716046\n",
      "train loss:0.10915693133871843\n",
      "train loss:0.07150422933629681\n",
      "train loss:0.05813530784911164\n",
      "train loss:0.08851855921690432\n",
      "train loss:0.11832135971840517\n",
      "train loss:0.13407316701650154\n",
      "train loss:0.0702913895437436\n",
      "train loss:0.08762217827851916\n",
      "train loss:0.044767419778319315\n",
      "train loss:0.11115857268755411\n",
      "train loss:0.07025280523160733\n",
      "train loss:0.12261536410666707\n",
      "train loss:0.13483317531781705\n",
      "train loss:0.1290314738713395\n",
      "train loss:0.05283887549706562\n",
      "train loss:0.09991808585556285\n",
      "train loss:0.04639283626271214\n",
      "train loss:0.15313101799027204\n",
      "train loss:0.09143102157261848\n",
      "train loss:0.10757746640553584\n",
      "train loss:0.07784812998741925\n",
      "train loss:0.10699585807108411\n",
      "train loss:0.08975100577369728\n",
      "train loss:0.10973105969102911\n",
      "train loss:0.09940580791461429\n",
      "train loss:0.10199146874226388\n",
      "train loss:0.07603867819848599\n",
      "train loss:0.12422889015603722\n",
      "train loss:0.08821256087450462\n",
      "train loss:0.08875811074701186\n",
      "train loss:0.16563667131997867\n",
      "train loss:0.10283867548246463\n",
      "train loss:0.12169220163810177\n",
      "train loss:0.0767284159168683\n",
      "train loss:0.07609784301307246\n",
      "train loss:0.07565857772281326\n",
      "train loss:0.0863715523198748\n",
      "train loss:0.049406446577357724\n",
      "train loss:0.13792096333403284\n",
      "train loss:0.10471335836145176\n",
      "train loss:0.0872968540740643\n",
      "train loss:0.053474479883538886\n",
      "train loss:0.059038263799021384\n",
      "train loss:0.05124902184600035\n",
      "train loss:0.11274248314386819\n",
      "train loss:0.09884097412944087\n",
      "train loss:0.15826044191701932\n",
      "train loss:0.11122433958127387\n",
      "train loss:0.0940648015304727\n",
      "train loss:0.08099145960533455\n",
      "train loss:0.12887363155975265\n",
      "train loss:0.106309059738248\n",
      "train loss:0.08076788143435902\n",
      "train loss:0.15376038224620592\n",
      "train loss:0.11181824063429369\n",
      "train loss:0.06356973270970183\n",
      "train loss:0.09967146603815533\n",
      "train loss:0.08774126224607574\n",
      "train loss:0.19423718200048423\n",
      "train loss:0.11308875082204156\n",
      "train loss:0.11967816182745389\n",
      "train loss:0.10505647246764943\n",
      "train loss:0.11323781801537809\n",
      "train loss:0.06197209269721988\n",
      "train loss:0.12334430292123665\n",
      "train loss:0.11203124082815247\n",
      "train loss:0.09812309035257093\n",
      "train loss:0.12307575373997745\n",
      "train loss:0.10383087065186825\n",
      "train loss:0.08790732117589052\n",
      "train loss:0.10233123424931533\n",
      "train loss:0.09275505334240604\n",
      "train loss:0.16204121787902562\n",
      "train loss:0.10494327460822844\n",
      "train loss:0.12057363536076642\n",
      "train loss:0.12246378802951273\n",
      "train loss:0.09577976200405301\n",
      "train loss:0.08690062910084866\n",
      "train loss:0.04546805880897217\n",
      "train loss:0.08924312562301853\n",
      "train loss:0.05752281339527184\n",
      "train loss:0.12144146332011696\n",
      "train loss:0.1478336778687482\n",
      "train loss:0.04300286259616281\n",
      "train loss:0.08767480310732959\n",
      "train loss:0.10154177380866952\n",
      "train loss:0.12357385012985468\n",
      "train loss:0.05685007435354427\n",
      "train loss:0.08216447340265581\n",
      "train loss:0.1391145290621635\n",
      "train loss:0.08020858449459749\n",
      "train loss:0.06736930751347048\n",
      "train loss:0.10714803320903087\n",
      "train loss:0.04117221987444374\n",
      "train loss:0.09310114316721696\n",
      "train loss:0.10061407934270852\n",
      "train loss:0.13818932941826909\n",
      "train loss:0.09132862830960349\n",
      "train loss:0.1309592883022812\n",
      "train loss:0.19051351995555763\n",
      "train loss:0.09189038473705628\n",
      "train loss:0.07183882725155848\n",
      "train loss:0.12595874573889015\n",
      "train loss:0.07191873623332987\n",
      "train loss:0.12295159602371028\n",
      "train loss:0.08988947240013694\n",
      "train loss:0.1620966104290957\n",
      "train loss:0.10696850826277458\n",
      "train loss:0.10883995911083383\n",
      "train loss:0.13937900427860167\n",
      "train loss:0.08314675641472019\n",
      "train loss:0.061841446734600736\n",
      "train loss:0.10060810243996389\n",
      "train loss:0.10042648398375123\n",
      "train loss:0.13454060154492029\n",
      "train loss:0.07915571855179294\n",
      "train loss:0.15460631379805467\n",
      "train loss:0.11214554521147106\n",
      "train loss:0.11115661172395339\n",
      "train loss:0.1909089631350539\n",
      "train loss:0.05009776012640673\n",
      "train loss:0.06601791945378782\n",
      "train loss:0.06586087710830886\n",
      "train loss:0.1161301230338803\n",
      "train loss:0.0536021631852827\n",
      "train loss:0.10445335701374413\n",
      "train loss:0.0447397664528888\n",
      "train loss:0.05917546307677902\n",
      "train loss:0.10327939614289372\n",
      "train loss:0.059044126941545275\n",
      "train loss:0.12513327408368682\n",
      "train loss:0.12481418474409456\n",
      "train loss:0.09088780678814214\n",
      "train loss:0.08058143706206283\n",
      "train loss:0.11960299422324884\n",
      "train loss:0.06602535882680222\n",
      "train loss:0.07056363076816362\n",
      "train loss:0.06522652947844332\n",
      "train loss:0.06902193806393285\n",
      "train loss:0.06324456660052999\n",
      "train loss:0.1337766118270807\n",
      "train loss:0.10191813680690562\n",
      "train loss:0.07460400069532552\n",
      "train loss:0.13330842940095086\n",
      "train loss:0.04501922987986101\n",
      "train loss:0.22779922832231128\n",
      "train loss:0.09829355950841424\n",
      "train loss:0.22637033353634062\n",
      "train loss:0.0975983308210464\n",
      "train loss:0.11148396163140284\n",
      "train loss:0.10570382078383664\n",
      "train loss:0.10027605956031835\n",
      "train loss:0.13954218606969465\n",
      "train loss:0.12398302214100461\n",
      "train loss:0.12102504885672075\n",
      "train loss:0.0942397076725058\n",
      "train loss:0.12363030262711476\n",
      "train loss:0.09474962709180003\n",
      "train loss:0.088231981611797\n",
      "train loss:0.09278377425711459\n",
      "train loss:0.09141654990729192\n",
      "train loss:0.09056885711895815\n",
      "train loss:0.17234489308092057\n",
      "train loss:0.11397625259454397\n",
      "train loss:0.10620246019881874\n",
      "train loss:0.07642581528287173\n",
      "train loss:0.1523835746463499\n",
      "train loss:0.09973814019476211\n",
      "train loss:0.12238816936824223\n",
      "train loss:0.1368963084754821\n",
      "train loss:0.10098574880140426\n",
      "train loss:0.055310296577900146\n",
      "train loss:0.1930582281358782\n",
      "train loss:0.12208762640818609\n",
      "train loss:0.1083968723074468\n",
      "train loss:0.08843062661911945\n",
      "train loss:0.057408627751993596\n",
      "train loss:0.06133325200064608\n",
      "train loss:0.0659835362275984\n",
      "train loss:0.1250510029868504\n",
      "train loss:0.07752233344927953\n",
      "train loss:0.08928366538003357\n",
      "train loss:0.12270232681039184\n",
      "train loss:0.0739291050504823\n",
      "train loss:0.12376068621237632\n",
      "train loss:0.15291502030224247\n",
      "train loss:0.09724969709099476\n",
      "train loss:0.11677712813750402\n",
      "train loss:0.0707909325401286\n",
      "train loss:0.09697341291188223\n",
      "train loss:0.10916542885719265\n",
      "train loss:0.12101093353944183\n",
      "train loss:0.11448377114394961\n",
      "train loss:0.15207945399574455\n",
      "train loss:0.08031052347817923\n",
      "train loss:0.08120551981205364\n",
      "train loss:0.050755827122518325\n",
      "train loss:0.07270459291661123\n",
      "train loss:0.26225562408539527\n",
      "train loss:0.12283393466696813\n",
      "train loss:0.06521086441828503\n",
      "train loss:0.17116957686612674\n",
      "train loss:0.0598709432355068\n",
      "train loss:0.08707980358166832\n",
      "train loss:0.1071807029013185\n",
      "train loss:0.06681901094450952\n",
      "train loss:0.11104973397531953\n",
      "train loss:0.09556582790427162\n",
      "train loss:0.09233959864242035\n",
      "train loss:0.08854063585568228\n",
      "train loss:0.08243185177632797\n",
      "train loss:0.055337178458675966\n",
      "train loss:0.06993811948463566\n",
      "train loss:0.18348115750097663\n",
      "train loss:0.03651592237839224\n",
      "train loss:0.14833957641757473\n",
      "train loss:0.0752398832530878\n",
      "train loss:0.06883619323862067\n",
      "train loss:0.06755515603219728\n",
      "train loss:0.0806780927283218\n",
      "train loss:0.06278747443056988\n",
      "train loss:0.17974488643356615\n",
      "train loss:0.07063881148778885\n",
      "train loss:0.12395584741604353\n",
      "train loss:0.07525399193954402\n",
      "train loss:0.08208821813489221\n",
      "train loss:0.08106996840796149\n",
      "train loss:0.1136952046843746\n",
      "train loss:0.08485030655649675\n",
      "train loss:0.09621384714511136\n",
      "train loss:0.09450483642389174\n",
      "train loss:0.07833748811893891\n",
      "train loss:0.055404938668338406\n",
      "train loss:0.06297266132410882\n",
      "train loss:0.05509911506483033\n",
      "train loss:0.0810869591097703\n",
      "train loss:0.046770010063415315\n",
      "train loss:0.11114583854460275\n",
      "train loss:0.11727321634563326\n",
      "train loss:0.13598016428595602\n",
      "train loss:0.09743456168263942\n",
      "train loss:0.04580341469680734\n",
      "train loss:0.12775822783594645\n",
      "train loss:0.07622350647353464\n",
      "train loss:0.07670221425370274\n",
      "train loss:0.07486987852105306\n",
      "train loss:0.07951814566728775\n",
      "train loss:0.09433010042613502\n",
      "train loss:0.08750314656388342\n",
      "train loss:0.09691983981723956\n",
      "train loss:0.05247750120843167\n",
      "train loss:0.08868513936699855\n",
      "train loss:0.11813120228074869\n",
      "train loss:0.08648771324070281\n",
      "train loss:0.10279304349171861\n",
      "train loss:0.07015301334264466\n",
      "train loss:0.10412664016184352\n",
      "train loss:0.10975430640154313\n",
      "train loss:0.06599186243486183\n",
      "train loss:0.15307474879487468\n",
      "train loss:0.13578830635182057\n",
      "train loss:0.09239402173497588\n",
      "train loss:0.07106828700603791\n",
      "train loss:0.05436661043463799\n",
      "train loss:0.23656115198267547\n",
      "train loss:0.12114840132646437\n",
      "train loss:0.030934045834704386\n",
      "train loss:0.14603390407518016\n",
      "train loss:0.09430944534844465\n",
      "train loss:0.09461102518917056\n",
      "train loss:0.08357906988860725\n",
      "train loss:0.09602423973516115\n",
      "train loss:0.23312295735151556\n",
      "train loss:0.07503411798240757\n",
      "train loss:0.10639691807101523\n",
      "train loss:0.13285645807451435\n",
      "train loss:0.17755801837970556\n",
      "train loss:0.12371490172570258\n",
      "train loss:0.1022617986589318\n",
      "train loss:0.08778054255270666\n",
      "train loss:0.09920452222128835\n",
      "train loss:0.07975692312269711\n",
      "train loss:0.10094546728574352\n",
      "train loss:0.1036293935352768\n",
      "train loss:0.11846261728150682\n",
      "train loss:0.08742878533273638\n",
      "train loss:0.07650801504351697\n",
      "train loss:0.1017450042568794\n",
      "train loss:0.08803200581295431\n",
      "train loss:0.164191170114398\n",
      "train loss:0.12875352593025685\n",
      "train loss:0.16437996829422763\n",
      "train loss:0.05565557151361235\n",
      "train loss:0.10629017782413396\n",
      "train loss:0.10529936614535357\n",
      "train loss:0.09100365861305872\n",
      "train loss:0.22797478768140292\n",
      "train loss:0.13525559151785363\n",
      "train loss:0.06471481937858048\n",
      "train loss:0.07077673144433952\n",
      "train loss:0.0581910136447955\n",
      "train loss:0.05850779267116546\n",
      "train loss:0.1525045407923889\n",
      "train loss:0.057174991606445784\n",
      "train loss:0.08343484255921212\n",
      "train loss:0.07224094352329741\n",
      "train loss:0.16531415632128735\n",
      "train loss:0.09641176548988424\n",
      "train loss:0.06638674344026084\n",
      "train loss:0.027684773438008597\n",
      "train loss:0.038130141561958236\n",
      "train loss:0.08162258450806849\n",
      "train loss:0.09598384342991277\n",
      "train loss:0.043218450124397505\n",
      "train loss:0.11178158547194071\n",
      "train loss:0.09966133703260541\n",
      "train loss:0.05284439835729041\n",
      "train loss:0.08400521336919194\n",
      "train loss:0.09558795515029164\n",
      "train loss:0.10135918354662503\n",
      "train loss:0.03710929892462525\n",
      "train loss:0.062294780645471864\n",
      "train loss:0.12156633815983951\n",
      "train loss:0.06963796374178903\n",
      "train loss:0.09838677221362932\n",
      "train loss:0.12737214513845982\n",
      "train loss:0.033854275017159326\n",
      "train loss:0.21145349647552233\n",
      "train loss:0.061710123305193015\n",
      "train loss:0.03863374678442907\n",
      "train loss:0.09057879811458502\n",
      "train loss:0.05036518326424368\n",
      "train loss:0.0627932696732143\n",
      "train loss:0.1302187296942258\n",
      "train loss:0.152418440854837\n",
      "train loss:0.08312758670763362\n",
      "train loss:0.059627770843855836\n",
      "train loss:0.11317359440496226\n",
      "train loss:0.09516683271748962\n",
      "train loss:0.11160753779115826\n",
      "train loss:0.11038233370917581\n",
      "train loss:0.10974951964021866\n",
      "train loss:0.07652705037914241\n",
      "train loss:0.05705996558308759\n",
      "train loss:0.07269201473968986\n",
      "train loss:0.1409964607269552\n",
      "train loss:0.11078124632959177\n",
      "train loss:0.1892366212765893\n",
      "train loss:0.19800676947585244\n",
      "train loss:0.07110812293633591\n",
      "train loss:0.11349920902459665\n",
      "train loss:0.06606933672290285\n",
      "train loss:0.0353762960475885\n",
      "train loss:0.09812598972022774\n",
      "train loss:0.09564514949485138\n",
      "train loss:0.0847604044648961\n",
      "train loss:0.11811286018640586\n",
      "train loss:0.14408597940126439\n",
      "train loss:0.07542661057077357\n",
      "train loss:0.09420930361060476\n",
      "train loss:0.02992249829012542\n",
      "train loss:0.04208479296693934\n",
      "train loss:0.1151315253330924\n",
      "train loss:0.15523877588841078\n",
      "train loss:0.110340533827262\n",
      "train loss:0.16838735078014366\n",
      "train loss:0.13537066995703287\n",
      "train loss:0.10717063916451973\n",
      "train loss:0.0714220717338443\n",
      "train loss:0.10526032713321076\n",
      "train loss:0.0896549755820749\n",
      "train loss:0.1657055207124097\n",
      "train loss:0.057222570310907335\n",
      "train loss:0.07408253795038956\n",
      "train loss:0.06915866867582716\n",
      "train loss:0.07524499368305505\n",
      "train loss:0.06193126827378553\n",
      "train loss:0.05812931175205209\n",
      "train loss:0.1849294267698578\n",
      "train loss:0.09557170727039502\n",
      "train loss:0.05093083956213313\n",
      "train loss:0.08550976475967383\n",
      "train loss:0.13195110025518159\n",
      "train loss:0.2085782447510785\n",
      "train loss:0.1213921155264204\n",
      "train loss:0.15887847447190753\n",
      "train loss:0.11711989927403019\n",
      "train loss:0.10661558236541355\n",
      "train loss:0.05335839239179133\n",
      "train loss:0.12107698323904346\n",
      "train loss:0.12539071572852184\n",
      "train loss:0.10083796860386852\n",
      "train loss:0.1113332784346924\n",
      "train loss:0.03252553839995246\n",
      "train loss:0.045357902549321746\n",
      "train loss:0.08202617224801054\n",
      "train loss:0.11709463375310745\n",
      "train loss:0.04908232936766221\n",
      "train loss:0.12090452610543824\n",
      "train loss:0.08670610597383732\n",
      "train loss:0.1250907765078003\n",
      "train loss:0.12688481234995178\n",
      "train loss:0.1613978784284889\n",
      "train loss:0.06647479371823001\n",
      "train loss:0.12199421476705666\n",
      "train loss:0.1307220828396417\n",
      "train loss:0.21630044690964223\n",
      "train loss:0.09791604557005157\n",
      "train loss:0.12881428661903788\n",
      "train loss:0.10711992079135993\n",
      "train loss:0.1230056388195198\n",
      "train loss:0.09773709098844878\n",
      "train loss:0.08303217226016407\n",
      "train loss:0.06938070970589755\n",
      "train loss:0.06078994795999138\n",
      "train loss:0.07913721691336159\n",
      "train loss:0.10021245782982331\n",
      "train loss:0.1279476778928434\n",
      "train loss:0.1385343574356283\n",
      "train loss:0.06366144795223232\n",
      "train loss:0.1314903182418061\n",
      "train loss:0.1686956107363992\n",
      "train loss:0.1380587819336313\n",
      "train loss:0.06938737326527193\n",
      "train loss:0.13960785654477903\n",
      "train loss:0.03137693491678361\n",
      "train loss:0.07351328047520993\n",
      "train loss:0.09108405607457998\n",
      "train loss:0.1831941540057125\n",
      "train loss:0.07429239841420805\n",
      "train loss:0.08661364161558405\n",
      "train loss:0.09765800006222639\n",
      "train loss:0.10903556995306203\n",
      "train loss:0.09224360316817487\n",
      "train loss:0.055032839839919856\n",
      "train loss:0.12970950601850373\n",
      "train loss:0.09068574871097244\n",
      "train loss:0.15307773246532277\n",
      "train loss:0.10253510335803231\n",
      "train loss:0.14106898701433757\n",
      "train loss:0.10080986705141014\n",
      "train loss:0.13045903848206533\n",
      "train loss:0.13249683543607593\n",
      "train loss:0.0698717980179993\n",
      "train loss:0.06365486793364189\n",
      "train loss:0.08455398865990314\n",
      "train loss:0.11739931388986088\n",
      "train loss:0.09724836022249404\n",
      "train loss:0.08924341300885195\n",
      "train loss:0.1263558098663395\n",
      "train loss:0.10242333035735429\n",
      "train loss:0.06739008852346232\n",
      "train loss:0.093811651186177\n",
      "train loss:0.11141772540668093\n",
      "train loss:0.12065648143970176\n",
      "train loss:0.13250279713621302\n",
      "train loss:0.10221546572009804\n",
      "train loss:0.08283388034057744\n",
      "train loss:0.10159199489552666\n",
      "train loss:0.0445613801076078\n",
      "train loss:0.10363991398191395\n",
      "train loss:0.044456931141234834\n",
      "train loss:0.16016766200200888\n",
      "train loss:0.08342242087935899\n",
      "train loss:0.07594915768184186\n",
      "train loss:0.08732593095462539\n",
      "train loss:0.05949173593098644\n",
      "train loss:0.08699383778385837\n",
      "train loss:0.17092304025012162\n",
      "train loss:0.1501459603512767\n",
      "train loss:0.06909820001824447\n",
      "train loss:0.14980844547113822\n",
      "train loss:0.08596060208208754\n",
      "train loss:0.10680056762035013\n",
      "train loss:0.1080035990823075\n",
      "train loss:0.05494948152255951\n",
      "train loss:0.11996501045334039\n",
      "train loss:0.11205756144478758\n",
      "train loss:0.05862718534868164\n",
      "train loss:0.06148926334106216\n",
      "train loss:0.0885569488482853\n",
      "train loss:0.060618484874636384\n",
      "train loss:0.1298736080248521\n",
      "train loss:0.09574625075047073\n",
      "train loss:0.05595360297112478\n",
      "train loss:0.09932831639376323\n",
      "train loss:0.09668450619080345\n",
      "train loss:0.07915044864233368\n",
      "train loss:0.09221982151144587\n",
      "train loss:0.08812398719874627\n",
      "train loss:0.05656562357907444\n",
      "train loss:0.15260740789050017\n",
      "train loss:0.039237775041052386\n",
      "train loss:0.19648239511041596\n",
      "train loss:0.037018704583167\n",
      "train loss:0.03217938033794963\n",
      "train loss:0.05268288605340958\n",
      "train loss:0.12046814633389306\n",
      "train loss:0.0726116652816457\n",
      "train loss:0.10849372756023469\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9183\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.9590\n",
      "Final Test Accuracy: 0.9080\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fashion.fashion_mnist import load_fashion_mnist\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from common.trainer import Trainer\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"\n",
    "    다음과 같은 CNN을 구성한다.\n",
    "    → Conv → ReLU → Pooling → Affine → ReLU → Affine → Softmax →\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param={'filter_num': 30, 'filter_size': 5,\n",
    "                             'pad': 0, 'stride': 1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / \\\n",
    "            filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) *\n",
    "                               (conv_output_size/2))\n",
    "\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'],\n",
    "                                           self.params['b1'],\n",
    "                                           conv_param['stride'],\n",
    "                                           conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"추론을 수행\"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실함수 값 계산\"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1:\n",
    "            t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"오차역전파법으로 기울기를 구함\"\"\"\n",
    "        self.loss(x, t)\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_fashion_mnist(flatten=False)\n",
    "\n",
    "max_epochs = 12\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1, 28, 28),\n",
    "                        conv_param={'filter_num': 60, 'filter_size': 5, 'pad': 1, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# 최종 테스트 정확도 및 학습 정확도 출력\n",
    "print(f\"Final Train Accuracy: {trainer.train_acc_list[-1]:.4f}\")\n",
    "print(f\"Final Test Accuracy: {trainer.test_acc_list[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e488721-6392-445a-93c8-e83c2870898c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbc852-229f-408f-90b7-e227e72edaa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
